{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data Proprocessing and Traffic Gan.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNofffOXSaKa2oFR3sfQiAw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ae30369c45aa40bb83e72b4333d2f893":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b568b9ce61b44f258cb058ef75f37bdb","IPY_MODEL_c95e5c973d4a4b188b31ac6a69d311ca","IPY_MODEL_9eb322d44e7c4721bd904a3636ff5223"],"layout":"IPY_MODEL_4cc6178cb1444bf08ffb73fc73063937","tabbable":null,"tooltip":null}},"b568b9ce61b44f258cb058ef75f37bdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d22cbd43fd564a7d99fabdbd0b4a9615","placeholder":"​","style":"IPY_MODEL_c19071a150af4f82b46abc70d535e12d","tabbable":null,"tooltip":null,"value":"100%"}},"c95e5c973d4a4b188b31ac6a69d311ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_3ea45dc3ebdd4b7a8b2c5a4d95c87ec0","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c574ecdfc9f4440b9197ad19ac888130","tabbable":null,"tooltip":null,"value":1000}},"9eb322d44e7c4721bd904a3636ff5223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c3922e11a7634063a4c9569f68b51d69","placeholder":"​","style":"IPY_MODEL_6b37b639a8994bca9e1883d3c172c7fb","tabbable":null,"tooltip":null,"value":" 1000/1000 [06:59&lt;00:00,  2.62it/s]"}},"4cc6178cb1444bf08ffb73fc73063937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d22cbd43fd564a7d99fabdbd0b4a9615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c19071a150af4f82b46abc70d535e12d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3ea45dc3ebdd4b7a8b2c5a4d95c87ec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c574ecdfc9f4440b9197ad19ac888130":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3922e11a7634063a4c9569f68b51d69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b37b639a8994bca9e1883d3c172c7fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5648ebecf5cc4d95b6e27a8e53d6836b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03e0e92e4ade49c18c59ed1836bc4e34","IPY_MODEL_7f5856ba8fbc417b92225144b2928808","IPY_MODEL_b1e6524d0549477eb97f474161c44d36"],"layout":"IPY_MODEL_03cd8fdaf25045b79dc6bdd4ae9b8de9","tabbable":null,"tooltip":null}},"03e0e92e4ade49c18c59ed1836bc4e34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3fe7876a5a7d44ad8349fe6114fd3893","placeholder":"​","style":"IPY_MODEL_a68b3451953d4ece9b31d1317849301c","tabbable":null,"tooltip":null,"value":"100%"}},"7f5856ba8fbc417b92225144b2928808":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_54e8c52fb13e492eac0d31b342bf1c44","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_892474f4e6994456bd4363effd49c62f","tabbable":null,"tooltip":null,"value":1000}},"b1e6524d0549477eb97f474161c44d36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2eeee8ca2f4242788f36d8cfaa3da0e2","placeholder":"​","style":"IPY_MODEL_e16372e921934e68ae2b4aef1572586d","tabbable":null,"tooltip":null,"value":" 1000/1000 [08:20&lt;00:00,  2.12it/s]"}},"03cd8fdaf25045b79dc6bdd4ae9b8de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe7876a5a7d44ad8349fe6114fd3893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a68b3451953d4ece9b31d1317849301c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"54e8c52fb13e492eac0d31b342bf1c44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"892474f4e6994456bd4363effd49c62f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2eeee8ca2f4242788f36d8cfaa3da0e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e16372e921934e68ae2b4aef1572586d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5c89dceade5041c4a34a94bd0ae7ff2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdbf436f106a48998d068ac87f27573b","IPY_MODEL_dd5e54ab6780419ea8382d9759921852","IPY_MODEL_39c52ff617294765a370b3418a6c529d"],"layout":"IPY_MODEL_05f46b466d284136b27c3f91cff98c7e","tabbable":null,"tooltip":null}},"fdbf436f106a48998d068ac87f27573b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_444e15748de94d8e8e3c17947cc26c9b","placeholder":"​","style":"IPY_MODEL_d666a07d2fed4a19b752120c605df381","tabbable":null,"tooltip":null,"value":"100%"}},"dd5e54ab6780419ea8382d9759921852":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_cccc02302d6641ed8e32d106ae535172","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c82233f30944cd2a6abc9ca09375fb3","tabbable":null,"tooltip":null,"value":1000}},"39c52ff617294765a370b3418a6c529d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0969f7cd943a4a58bf0182507b90d2d4","placeholder":"​","style":"IPY_MODEL_134d00fd82df4c1f984db033b19d0883","tabbable":null,"tooltip":null,"value":" 1000/1000 [07:37&lt;00:00,  2.28it/s]"}},"05f46b466d284136b27c3f91cff98c7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"444e15748de94d8e8e3c17947cc26c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d666a07d2fed4a19b752120c605df381":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cccc02302d6641ed8e32d106ae535172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c82233f30944cd2a6abc9ca09375fb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0969f7cd943a4a58bf0182507b90d2d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"134d00fd82df4c1f984db033b19d0883":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"124ffe1f9c4d452e956f0688ede67b9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57ab8e1b4f9a4d0dafca068e860cdc91","IPY_MODEL_650484bf2815451a8a8243fdbd8f86c0","IPY_MODEL_efe8c1ad340b4476954f5ac1e2564341"],"layout":"IPY_MODEL_a2a2552593a04307b157078f0a52df9c","tabbable":null,"tooltip":null}},"57ab8e1b4f9a4d0dafca068e860cdc91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2a95dee0a47348ce8bde3107072953a1","placeholder":"​","style":"IPY_MODEL_561afc96194a43a883c50b2767b4bd6b","tabbable":null,"tooltip":null,"value":"100%"}},"650484bf2815451a8a8243fdbd8f86c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_6a733f2274ca42419eaec596d6e3313a","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a1eb3cfda51416e96b21631244dd5fb","tabbable":null,"tooltip":null,"value":1000}},"efe8c1ad340b4476954f5ac1e2564341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6ed71de301464558bc5f9519f1eb03de","placeholder":"​","style":"IPY_MODEL_ca17199815bb4380946f1b09065d666a","tabbable":null,"tooltip":null,"value":" 1000/1000 [08:03&lt;00:00,  2.15it/s]"}},"a2a2552593a04307b157078f0a52df9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a95dee0a47348ce8bde3107072953a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"561afc96194a43a883c50b2767b4bd6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6a733f2274ca42419eaec596d6e3313a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a1eb3cfda51416e96b21631244dd5fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ed71de301464558bc5f9519f1eb03de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca17199815bb4380946f1b09065d666a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3nfUJxknjI4I","executionInfo":{"status":"ok","timestamp":1661191204526,"user_tz":240,"elapsed":21617,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"5aa78d91-286a-4d42-c210-927f350a108a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import math\n","import matplotlib.pyplot as plt\n","from datetime import datetime, timedelta\n","import statsmodels.api as sm\n","from statsmodels.tsa.stattools import adfuller\n","pd.set_option('display.max_columns',100)\n","from google.colab import drive\n","from scipy.stats import pearsonr\n","import torch\n","from torch.nn.modules.module import Module\n","from torch.autograd import Variable\n","from torch.nn.parameter import Parameter\n","import torch.utils as utils\n","from torch import nn\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm_notebook\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","import torch.optim as optim\n","drive.mount('/content/drive')\n","root_dir = \"/content/drive/MyDrive/Colab Notebooks/Public Folder: SafeGraph Group /Safegraph Data/Summary\"\n","os.chdir(f\"{root_dir}\")"]},{"cell_type":"markdown","source":["# 1. Data Preprocessing"],"metadata":{"id":"1cOQi8Mq6Q-s"}},{"cell_type":"code","source":["data = pd.read_csv('Safeguard_Data.csv')\n","data = data.sort_values(by=['date_range_start'])\n","data = data[~data.distance_from_home.isna()]\n","data = data.sort_values(by=['date_range_start'])\n","data['date_range_start'] = data['date_range_start'].str[0:10]\n","data['date_range_start'] = data['date_range_start'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n","data['date_range_start'] = data['date_range_start'].dt.date\n","data['date_range_end'] = data['date_range_end'].str[0:10]\n","data['date_range_end'] = data['date_range_end'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n","data['date_range_end'] = data['date_range_end'].dt.date"],"metadata":{"id":"_fSScyczjW6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.date_range_start.value_counts(sort=False).plot.bar(figsize=(30,5), rot=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"ZINXgFGkllwn","executionInfo":{"status":"ok","timestamp":1660956424163,"user_tz":240,"elapsed":623,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"ba909b54-239c-480a-a331-9106e39515fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fd580efa950>"]},"metadata":{},"execution_count":3},{"output_type":"display_data","data":{"text/plain":["<Figure size 2160x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Get Visited list and Placekey list: "],"metadata":{"id":"ZMxhXoVtnp4d"}},{"cell_type":"code","source":["df_visited = data.groupby(['date_range_end','poi_cbg']).sum()['raw_visit_counts'].reset_index()\n","df_poi = data.groupby(['date_range_end','poi_cbg']).count()['placekey'].reset_index()\n","df = df_visited.merge(df_poi,left_on=['date_range_end','poi_cbg'],right_on=['date_range_end','poi_cbg'])"],"metadata":{"id":"dE3fjtABo_Yw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Conduct Data Cleaning on demographic csv file and merge it with visited and poi data file:"],"metadata":{"id":"Vi1HqvTvpC4M"}},{"cell_type":"code","source":["demographic_cbg = pd.read_csv(\"demographic_cbg_with_coordinates.csv\")\n","demographic_cbg.cbgid = demographic_cbg.cbgid.str[9:].astype('int')\n","demographic_cbg = demographic_cbg.loc[demographic_cbg.cbgid.isin(np.unique(df.poi_cbg)),:]\n","demographic_cbg = demographic_cbg.loc[(demographic_cbg.Median_Household_Income!='-')&(demographic_cbg.Margin_of_Error_Income!='**')&\\\n","            (demographic_cbg.Margin_of_Error_Income!='***'),:]\n","# For those income lower than 2500, we just make it as 2500\n","demographic_cbg.loc[demographic_cbg.Median_Household_Income=='2,500-','Median_Household_Income'] = 2500\n","# For those income larger than 250000, we just make it as 250000\n","demographic_cbg.loc[demographic_cbg.Median_Household_Income=='250,000','Median_Household_Income'] = 250000\n","demographic_cbg.Median_Household_Income = demographic_cbg.Median_Household_Income.astype('int')\n","demographic_cbg.Margin_of_Error_Income = demographic_cbg.Margin_of_Error_Income.astype('int')\n","demographic_cbg.geo_location = (demographic_cbg.LATITUDE,demographic_cbg.LONGITUDE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9R769EupBAw","executionInfo":{"status":"ok","timestamp":1661107838916,"user_tz":240,"elapsed":12,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"a981b095-2797-42aa-b18f-6799cc28187d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","  if sys.path[0] == '':\n"]}]},{"cell_type":"code","source":["df = df.merge(demographic_cbg,left_on='poi_cbg',right_on='cbgid')\n","df = df.drop(columns=['cbgid'])\n","df.poi_cbg = df.poi_cbg.astype('int')\n","postal_to_cbg = data[['postal_code','poi_cbg']]\n","df.merge(postal_to_cbg, left_on = 'poi_cbg', right_on = 'poi_cbg')\n","#df.to_csv(\"overall_cbgdata.csv\")\n","Time_Series_Data = df[['date_range_end','poi_cbg','placekey','Total_Population','Median_Household_Income']]"],"metadata":{"id":"bjf_YzN-niBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["postal_to_cbg = data[['postal_code','poi_cbg']]\n","df = df.merge(postal_to_cbg, left_on = 'poi_cbg', right_on = 'poi_cbg')"],"metadata":{"id":"BzMG1hRcs5np"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Merge Diagonised Case Rate into df:"],"metadata":{"id":"oI3UCwHSuufV"}},{"cell_type":"code","source":["cases = pd.read_csv('cases.csv')\n","df.date_range_end = pd.to_datetime(df.date_range_end, format = '%Y-%m-%d')\n","cases.date_range_end = pd.to_datetime(cases.date_range_end, format = '%Y-%m-%d')\n","df = df.merge(cases, left_on = ['date_range_end','poi_cbg'], right_on = ['date_range_end','poi_cbg'])"],"metadata":{"id":"m6rZYVe_u4Iy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","cases = pd.read_csv('overall_cbg.csv')\n","cases = cases[['date_range_end', 'poi_cbg', 'case_rate']]\n","cases.to_csv('cases.csv', index = False)\n","\"\"\""],"metadata":{"id":"WDJCeuLaskYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","cases=pd.read_csv(\"cases.csv\")\n","cases['week_ending'] = cases['week_ending'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))\n","cases['week_ending'] = cases['week_ending'].dt.date\n","#Make the week of the case rate and the df to be same\n","cases['week_ending'] = cases['week_ending'] + timedelta(days=2)\n","for i in df.postal_code.value_counts()[:200].index:\n","  for day in df.date_range_end:\n","    try:\n","      df.loc[(df.date_range_end==day)&(df.postal_code==i),'case_rate']=cases.loc[cases.week_ending==day,str(i)].values[0]\n","    except:\n","      continue\n","\n","\"\"\""],"metadata":{"id":"SOW-MB4FuiZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df.to_csv(\"overall_cbgdata.csv\", index = False)\n","Time_Series_Data = df[['date_range_end','poi_cbg','placekey','Total_Population','Median_Household_Income','case_rate','raw_visit_counts']]\n","Time_Series_Data = Time_Series_Data.drop_duplicates()\n","Time_Series_Data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"dRqdzCWhwBSa","executionInfo":{"status":"ok","timestamp":1661107844123,"user_tz":240,"elapsed":1821,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"0b165e97-0bff-4357-d69f-baa27798f635"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        date_range_end       poi_cbg  placekey  Total_Population  \\\n","0           2022-01-10  360050002002         1              1542   \n","30          2022-01-17  360050002002         2              1542   \n","60          2022-01-24  360050002002         2              1542   \n","90          2022-01-31  360050002002         2              1542   \n","120         2022-02-07  360050002002         2              1542   \n","...                ...           ...       ...               ...   \n","5370977     2022-05-16  360810379002         1              3037   \n","5370980     2022-05-23  360810379002         1              3037   \n","5370983     2022-05-09  360850112012         1              2037   \n","5370987     2022-05-16  360850112012         1              2037   \n","5370991     2022-05-23  360850112012         2              2037   \n","\n","         Median_Household_Income  case_rate  raw_visit_counts  \n","0                          74050    3853.80                11  \n","30                         74050    1590.24                36  \n","60                         74050     622.56                22  \n","90                         74050     260.53                13  \n","120                        74050     123.50                18  \n","...                          ...        ...               ...  \n","5370977                    71726     187.55                45  \n","5370980                    71726     212.92                54  \n","5370983                    78026     473.42                 5  \n","5370987                    78026     503.72                 5  \n","5370991                    78026     560.53                15  \n","\n","[35536 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-9cb4dbba-7144-4f0e-a52f-1857d7324e67\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_range_end</th>\n","      <th>poi_cbg</th>\n","      <th>placekey</th>\n","      <th>Total_Population</th>\n","      <th>Median_Household_Income</th>\n","      <th>case_rate</th>\n","      <th>raw_visit_counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-10</td>\n","      <td>360050002002</td>\n","      <td>1</td>\n","      <td>1542</td>\n","      <td>74050</td>\n","      <td>3853.80</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>2022-01-17</td>\n","      <td>360050002002</td>\n","      <td>2</td>\n","      <td>1542</td>\n","      <td>74050</td>\n","      <td>1590.24</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>2022-01-24</td>\n","      <td>360050002002</td>\n","      <td>2</td>\n","      <td>1542</td>\n","      <td>74050</td>\n","      <td>622.56</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>2022-01-31</td>\n","      <td>360050002002</td>\n","      <td>2</td>\n","      <td>1542</td>\n","      <td>74050</td>\n","      <td>260.53</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>2022-02-07</td>\n","      <td>360050002002</td>\n","      <td>2</td>\n","      <td>1542</td>\n","      <td>74050</td>\n","      <td>123.50</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5370977</th>\n","      <td>2022-05-16</td>\n","      <td>360810379002</td>\n","      <td>1</td>\n","      <td>3037</td>\n","      <td>71726</td>\n","      <td>187.55</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>5370980</th>\n","      <td>2022-05-23</td>\n","      <td>360810379002</td>\n","      <td>1</td>\n","      <td>3037</td>\n","      <td>71726</td>\n","      <td>212.92</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>5370983</th>\n","      <td>2022-05-09</td>\n","      <td>360850112012</td>\n","      <td>1</td>\n","      <td>2037</td>\n","      <td>78026</td>\n","      <td>473.42</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5370987</th>\n","      <td>2022-05-16</td>\n","      <td>360850112012</td>\n","      <td>1</td>\n","      <td>2037</td>\n","      <td>78026</td>\n","      <td>503.72</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5370991</th>\n","      <td>2022-05-23</td>\n","      <td>360850112012</td>\n","      <td>2</td>\n","      <td>2037</td>\n","      <td>78026</td>\n","      <td>560.53</td>\n","      <td>15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>35536 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cb4dbba-7144-4f0e-a52f-1857d7324e67')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9cb4dbba-7144-4f0e-a52f-1857d7324e67 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9cb4dbba-7144-4f0e-a52f-1857d7324e67');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["Create Feature Matrix and Correlation Matrix:"],"metadata":{"id":"eDCChzTlryWt"}},{"cell_type":"code","source":["droplist = []\n","Time_Series_Data = Time_Series_Data.drop_duplicates()\n","Time_Series_Data = Time_Series_Data.dropna(how ='any') \n","for i in np.unique(Time_Series_Data.poi_cbg):\n","  if len(Time_Series_Data.loc[Time_Series_Data.poi_cbg == i,:]) < 20:\n","    droplist.append(i)\n","Time_Series_Data = Time_Series_Data.loc[~df.poi_cbg.isin(droplist)]\n","cbgs, length = np.unique(Time_Series_Data.poi_cbg),len(np.unique(Time_Series_Data.poi_cbg))\n"],"metadata":{"id":"GYeE3d0YvFIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save('cbg.npy', cbgs)"],"metadata":{"id":"7qozZi3LvlJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dicts_cbg_index = {i:j for i, j in zip(range(length),np.unique(Time_Series_Data.poi_cbg))}\n","dicts_cbg_index_reverse = {j:i for i, j in zip(range(length),np.unique(Time_Series_Data.poi_cbg))}\n","Time_Series_Data.poi_cbg = Time_Series_Data.poi_cbg.map(dicts_cbg_index_reverse)\n","Time_Series_Data = Time_Series_Data[['date_range_end','poi_cbg','placekey','Median_Household_Income','Total_Population','case_rate','raw_visit_counts']]\n","date, poi = np.unique(Time_Series_Data.date_range_end), np.unique(Time_Series_Data.poi_cbg)\n","feature_matrix = np.zeros((len(np.unique(Time_Series_Data.date_range_end)),length,len(Time_Series_Data.columns)-2))\n","for i in range(len(np.unique(Time_Series_Data.date_range_end))):\n","  for j in range(length): \n","      feature_matrix[i,j,:] = Time_Series_Data.loc[(Time_Series_Data.date_range_end==date[i])&(Time_Series_Data.poi_cbg==poi[j]),:].values.flatten()[2:]"],"metadata":{"id":"yXJdLz6ItcmM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Features: 'placekey', 'Median_Household_Income', 'Total_Population', 'case_rate', 'raw_visit_counts'"],"metadata":{"id":"e4ichxc_X4wb"}},{"cell_type":"code","source":["np.save('feature_matrix.npy',feature_matrix)"],"metadata":{"id":"fD9XnFdstcos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correlation = np.zeros((length,length))\n","for i in range(length):\n","  series_i = Time_Series_Data.loc[Time_Series_Data.poi_cbg==i,'raw_visit_counts']\n","  correlation[i,i] = 1\n","  for j in range(i+1,length):\n","    series_j = Time_Series_Data.loc[Time_Series_Data.poi_cbg==j,'raw_visit_counts']\n","    corr = pearsonr(series_i,series_j)[0]\n","    correlation[i,j] = pearsonr(series_i,series_j)[0]\n","    correlation[j,i] = pearsonr(series_i,series_j)[0]"],"metadata":{"id":"iguY4SWwxoqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save('correlation.npy',correlation)"],"metadata":{"id":"crhCF9kYzSSO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Realize the traffic Gan"],"metadata":{"id":"rLk0HALx6Z5E"}},{"cell_type":"markdown","source":["We consider to use the traffic gan model to fit on the safegraph data. Besides, we try to use different corrlation method to make comparison: \n","Correlation.npy --> time series correlation between different cbg data \n"," "],"metadata":{"id":"r2Le47KF4lvB"}},{"cell_type":"markdown","source":["Using Traffic Gan network with MSE loss and time series correlation matrix: "],"metadata":{"id":"OZlVacCF3ze4"}},{"cell_type":"code","source":["class MLP(torch.nn.Module):\n","    def __init__(self, n_i, n_h, n_o):\n","        super(MLP, self).__init__()\n","        self.linear1 = nn.Linear(n_i, n_h)\n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(n_h, n_o)\n","    def forward(self, input):\n","        input = self.linear1(input)\n","        input = self.relu(input)\n","        input = self.linear2(input)\n","        return input\n","class GraphConvolution(Module):\n","    def __init__(self, in_features, out_features, bias=True):\n","        super(GraphConvolution, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n","        if bias:\n","            self.bias = Parameter(torch.FloatTensor(out_features))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / math.sqrt(self.weight.size(1))\n","        self.weight.data.uniform_(-stdv, stdv)\n","        #print(self.weight)\n","        if self.bias is not None:\n","            self.bias.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, input, adjs):\n","        support = torch.matmul(input, self.weight)\n","        output = torch.matmul(adjs, support)\n","        if self.bias is not None:\n","            return output + self.bias\n","        else:\n","            return output\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + ' (' \\\n","            + str(self.in_features) + ' -> ' \\\n","            + str(self.out_features) + ')'\n","\n","class Generator(nn.Module):\n","    def __init__(self, infeat, hid, outfeat):\n","        super(Generator, self).__init__()\n","        # infeat = init_dimension + condition_num\n","        # outfeat = 1\n","        self.gconv1 = GraphConvolution(infeat, 64)\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.gconv2 = GraphConvolution(64, 32)\n","        self.bn2 = nn.BatchNorm1d(32)\n","        self.gconv3 = GraphConvolution(32, 16)\n","        self.mlp1 = MLP(16,8,1)\n","\n","\n","    def forward(self, x, adj):\n","        # input noise x <- (batch_size, pixel_num, init_dimension)\n","        # input adjacency matrix <- (batch_size, region_width * region_length, region_width * region_length)\n","        x = F.relu(self.bn1(self.gconv1(x, adj)))\n","        x = F.relu(self.bn2(self.gconv2(x, adj)))\n","        x = self.gconv3(x, adj)\n","        x = self.mlp1(x)\n","        #x = F.relu(self.bn4(self.gconv4(x, adj)))\n","        #x = x.view(list(x.size())[0], -1)\n","        #x = torch.tanh(self.fc5(x))\n","        #x = x.view(list(x.size())[0], -1, 1)\n","        return x"],"metadata":{"id":"_9P6SbQv37TA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = StandardScaler()\n","def normalization(feature_matrix,weight=2):\n","  feature_mat = np.zeros((feature_matrix.shape[0],feature_matrix.shape[1],feature_matrix.shape[2]))\n","  target = np.zeros((feature_matrix.shape[0],feature_matrix.shape[1]))\n","  for i in range(feature_matrix.shape[0]):\n","    feature_vector = feature_matrix[i]\n","    f1 = scaler.fit_transform(feature_vector[:,0].reshape(-1,1)).reshape(-1,1)\n","    f2 = scaler.fit_transform(feature_vector[:,1].reshape(-1,1)).reshape(-1,1)\n","    f3 = scaler.fit_transform(feature_vector[:,2].reshape(-1,1)).reshape(-1,1)\n","    f4 = scaler.fit_transform(feature_vector[:,3].reshape(-1,1)).reshape(-1,1)\n","    visit_nums = scaler.fit_transform(feature_vector[:,4].reshape(-1,1)).reshape(-1,1)\n","    feature_vector = np.stack([f1,f2,f3,f4,weight*visit_nums],axis=1).reshape(feature_matrix.shape[1],feature_matrix.shape[2])\n","    feature_mat[i] = feature_vector\n","    target[i] = visit_nums.flatten()\n","  return feature_mat, target"],"metadata":{"id":"BZez-jb-37VU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_matrix = np.load('feature_matrix.npy')\n","corrlation = np.load('correlation.npy').astype(np.float32)\n","feature_matrix,target = normalization(feature_matrix)\n","feature_matrix = torch.tensor(feature_matrix.astype(np.float32))\n","adj = torch.tensor(corrlation)\n","target = torch.tensor(target.astype(np.float32))"],"metadata":{"id":"KAIysrYo4HLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_features(time_step, feature_matrix):\n","  features = np.zeros((20-time_step,feature_matrix.shape[1],feature_matrix.shape[2]*time_step))\n","  results = np.zeros((20-time_step,feature_matrix.shape[1],1))\n","  for i in range(20-time_step):\n","    for j in range(feature_matrix.shape[1]):\n","      features[i,j,:] = feature_matrix[i:i+time_step,j,:].flatten()\n","      results[i,j,:] = feature_matrix[i+time_step,j,-1]\n","  features = torch.tensor(features.astype(np.float32))\n","  results = torch.tensor(results.astype(np.float32))\n","  return features, results\n","time_step = 5\n","features, results = get_features(time_step, feature_matrix)\n","train_idx=int(0.8*features.shape[0])\n","train_feature, train_result=features[:train_idx,:,:],results[:train_idx,:,:]\n","test_feature, test_result=features[train_idx:,:,:],results[train_idx:,:,:]"],"metadata":{"id":"quPNQrf84HNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_val_loss = np.inf\n","epochs = 1000\n","train_mean, test_mean = np.zeros((epochs,1)), np.zeros((epochs,1))\n","model = Generator(time_step*5+50, 32, 1).to(device)#time_step*5: feature nums, 32: hid layer, 1:output\n","loss = nn.MSELoss()\n","optimizer = optim.AdamW(model.parameters(),lr=0.001)\n","for epoch in tqdm_notebook(range(1,epochs + 1)):\n","    train_mean_loss, test_mean_loss, n, n1 = np.zeros((train_feature.shape[0],1)), np.zeros((test_feature.shape[0],1)), train_feature.shape[0], test_feature.shape[0]\n","    for i in range(n):\n","      #train_loss\n","      noise = torch.randn(train_feature.shape[1], 50)\n","      noise = torch.concat([noise, train_feature[i]], dim = 1) \n","      train = model(noise, adj)\n","      train_loss = loss(train, train_result[i])\n","      optimizer.zero_grad()\n","      train_loss.backward()\n","      optimizer.step()\n","      train_mean_loss[i] = train_loss.detach().numpy()\n","    for i in range(n1):\n","      noise2 = torch.randn(test_feature.shape[1], 50)\n","      noise2 = torch.concat([noise2, test_feature[i]], dim = 1)\n","      test = model(noise2, adj)\n","      test_loss = loss(test, test_result[i])\n","      test_mean_loss[i] = test_loss.detach().numpy()\n","    train_mean[epoch - 1], test_mean[epoch - 1] = train_mean_loss.mean(), test_mean_loss.mean()\n","    if mean_loss.mean() < min_val_loss:\n","      min_val_loss = mean_loss.mean()\n","    print('Epoch: {:03d} | Lr: {:.20f} |Train loss: {:.8f}|Test loss: {:.8f}'.\\\n","          format(epoch, optimizer.param_groups[0]['lr'], train_mean_loss.mean(), test_mean_loss.mean()))\n","print('\\nTraining finished.\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ae30369c45aa40bb83e72b4333d2f893","b568b9ce61b44f258cb058ef75f37bdb","c95e5c973d4a4b188b31ac6a69d311ca","9eb322d44e7c4721bd904a3636ff5223","4cc6178cb1444bf08ffb73fc73063937","d22cbd43fd564a7d99fabdbd0b4a9615","c19071a150af4f82b46abc70d535e12d","3ea45dc3ebdd4b7a8b2c5a4d95c87ec0","c574ecdfc9f4440b9197ad19ac888130","c3922e11a7634063a4c9569f68b51d69","6b37b639a8994bca9e1883d3c172c7fb"]},"id":"bAY8Kwve45Le","outputId":"f50a5ffd-fae6-4692-a369-27f178054b4b","executionInfo":{"status":"ok","timestamp":1661110787020,"user_tz":240,"elapsed":419948,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae30369c45aa40bb83e72b4333d2f893"},"application/json":{"n":0,"total":1000,"elapsed":0.16964507102966309,"ncols":null,"nrows":null,"prefix":"","ascii":false,"unit":"it","unit_scale":false,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1000,"initial":0,"colour":null}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 99.43942547|Test loss: 31.76049169\n","Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 39.65911627|Test loss: 35.30692164\n","Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 20.53309695|Test loss: 18.14222177\n","Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 9.64450860|Test loss: 13.78166946\n","Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 8.07128894|Test loss: 11.95709324\n","Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 9.12281446|Test loss: 6.58923546\n","Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 7.55629388|Test loss: 8.74494664\n","Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 6.75945576|Test loss: 8.13903284\n","Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 8.25517845|Test loss: 6.49590731\n","Epoch: 010 | Lr: 0.00100000000000000002 |Train loss: 6.28071014|Test loss: 6.68143956\n","Epoch: 011 | Lr: 0.00100000000000000002 |Train loss: 5.96178961|Test loss: 6.37758700\n","Epoch: 012 | Lr: 0.00100000000000000002 |Train loss: 5.45552401|Test loss: 7.17375040\n","Epoch: 013 | Lr: 0.00100000000000000002 |Train loss: 5.14820913|Test loss: 5.22211536\n","Epoch: 014 | Lr: 0.00100000000000000002 |Train loss: 5.55872643|Test loss: 5.97499196\n","Epoch: 015 | Lr: 0.00100000000000000002 |Train loss: 5.50678448|Test loss: 5.81910451\n","Epoch: 016 | Lr: 0.00100000000000000002 |Train loss: 4.95835185|Test loss: 5.08773931\n","Epoch: 017 | Lr: 0.00100000000000000002 |Train loss: 5.09383611|Test loss: 5.47024028\n","Epoch: 018 | Lr: 0.00100000000000000002 |Train loss: 5.32893395|Test loss: 5.78784641\n","Epoch: 019 | Lr: 0.00100000000000000002 |Train loss: 5.03567155|Test loss: 7.17599678\n","Epoch: 020 | Lr: 0.00100000000000000002 |Train loss: 4.74591720|Test loss: 6.59059191\n","Epoch: 021 | Lr: 0.00100000000000000002 |Train loss: 4.61542292|Test loss: 5.50883134\n","Epoch: 022 | Lr: 0.00100000000000000002 |Train loss: 4.63040340|Test loss: 5.53015232\n","Epoch: 023 | Lr: 0.00100000000000000002 |Train loss: 4.57940785|Test loss: 5.38535372\n","Epoch: 024 | Lr: 0.00100000000000000002 |Train loss: 4.70911614|Test loss: 6.43967899\n","Epoch: 025 | Lr: 0.00100000000000000002 |Train loss: 4.44290535|Test loss: 5.82384777\n","Epoch: 026 | Lr: 0.00100000000000000002 |Train loss: 4.60976867|Test loss: 5.26802492\n","Epoch: 027 | Lr: 0.00100000000000000002 |Train loss: 4.44498380|Test loss: 5.35019223\n","Epoch: 028 | Lr: 0.00100000000000000002 |Train loss: 4.33185732|Test loss: 4.91153336\n","Epoch: 029 | Lr: 0.00100000000000000002 |Train loss: 4.37533621|Test loss: 4.60634597\n","Epoch: 030 | Lr: 0.00100000000000000002 |Train loss: 4.44757509|Test loss: 4.43791262\n","Epoch: 031 | Lr: 0.00100000000000000002 |Train loss: 4.57391592|Test loss: 4.49136527\n","Epoch: 032 | Lr: 0.00100000000000000002 |Train loss: 4.63757698|Test loss: 5.26284075\n","Epoch: 033 | Lr: 0.00100000000000000002 |Train loss: 4.61170888|Test loss: 5.70936553\n","Epoch: 034 | Lr: 0.00100000000000000002 |Train loss: 4.56880816|Test loss: 5.35088412\n","Epoch: 035 | Lr: 0.00100000000000000002 |Train loss: 4.36077487|Test loss: 4.75362873\n","Epoch: 036 | Lr: 0.00100000000000000002 |Train loss: 4.27362506|Test loss: 4.69126240\n","Epoch: 037 | Lr: 0.00100000000000000002 |Train loss: 4.38074040|Test loss: 5.85669661\n","Epoch: 038 | Lr: 0.00100000000000000002 |Train loss: 4.21448735|Test loss: 4.73142163\n","Epoch: 039 | Lr: 0.00100000000000000002 |Train loss: 4.53608310|Test loss: 4.57914575\n","Epoch: 040 | Lr: 0.00100000000000000002 |Train loss: 4.23679956|Test loss: 4.23747301\n","Epoch: 041 | Lr: 0.00100000000000000002 |Train loss: 4.23922813|Test loss: 4.22569942\n","Epoch: 042 | Lr: 0.00100000000000000002 |Train loss: 4.21946061|Test loss: 4.51419608\n","Epoch: 043 | Lr: 0.00100000000000000002 |Train loss: 4.15727854|Test loss: 5.31050110\n","Epoch: 044 | Lr: 0.00100000000000000002 |Train loss: 4.50224837|Test loss: 4.42613093\n","Epoch: 045 | Lr: 0.00100000000000000002 |Train loss: 4.51300685|Test loss: 5.73660294\n","Epoch: 046 | Lr: 0.00100000000000000002 |Train loss: 4.21378521|Test loss: 5.88960679\n","Epoch: 047 | Lr: 0.00100000000000000002 |Train loss: 4.10845260|Test loss: 4.39491733\n","Epoch: 048 | Lr: 0.00100000000000000002 |Train loss: 4.06737965|Test loss: 4.64059703\n","Epoch: 049 | Lr: 0.00100000000000000002 |Train loss: 4.04899685|Test loss: 5.47844315\n","Epoch: 050 | Lr: 0.00100000000000000002 |Train loss: 4.20129031|Test loss: 4.22253593\n","Epoch: 051 | Lr: 0.00100000000000000002 |Train loss: 4.09923178|Test loss: 4.61984825\n","Epoch: 052 | Lr: 0.00100000000000000002 |Train loss: 4.05637830|Test loss: 4.39815617\n","Epoch: 053 | Lr: 0.00100000000000000002 |Train loss: 4.06980944|Test loss: 4.32136345\n","Epoch: 054 | Lr: 0.00100000000000000002 |Train loss: 4.00608659|Test loss: 4.55333233\n","Epoch: 055 | Lr: 0.00100000000000000002 |Train loss: 4.05049717|Test loss: 4.33558989\n","Epoch: 056 | Lr: 0.00100000000000000002 |Train loss: 4.04927194|Test loss: 4.75213639\n","Epoch: 057 | Lr: 0.00100000000000000002 |Train loss: 4.02937253|Test loss: 4.68333085\n","Epoch: 058 | Lr: 0.00100000000000000002 |Train loss: 3.96877001|Test loss: 4.18237813\n","Epoch: 059 | Lr: 0.00100000000000000002 |Train loss: 4.02372537|Test loss: 4.34135866\n","Epoch: 060 | Lr: 0.00100000000000000002 |Train loss: 4.00466090|Test loss: 4.29426511\n","Epoch: 061 | Lr: 0.00100000000000000002 |Train loss: 4.00418154|Test loss: 4.36392816\n","Epoch: 062 | Lr: 0.00100000000000000002 |Train loss: 3.97785016|Test loss: 5.10743491\n","Epoch: 063 | Lr: 0.00100000000000000002 |Train loss: 4.07975799|Test loss: 4.16270367\n","Epoch: 064 | Lr: 0.00100000000000000002 |Train loss: 3.99753702|Test loss: 4.40672159\n","Epoch: 065 | Lr: 0.00100000000000000002 |Train loss: 4.06303267|Test loss: 5.20963653\n","Epoch: 066 | Lr: 0.00100000000000000002 |Train loss: 3.94086023|Test loss: 4.59627215\n","Epoch: 067 | Lr: 0.00100000000000000002 |Train loss: 4.06317337|Test loss: 4.06717936\n","Epoch: 068 | Lr: 0.00100000000000000002 |Train loss: 4.00257297|Test loss: 4.33994786\n","Epoch: 069 | Lr: 0.00100000000000000002 |Train loss: 4.00198042|Test loss: 4.84753863\n","Epoch: 070 | Lr: 0.00100000000000000002 |Train loss: 3.99596612|Test loss: 4.34808604\n","Epoch: 071 | Lr: 0.00100000000000000002 |Train loss: 4.01519720|Test loss: 4.47302818\n","Epoch: 072 | Lr: 0.00100000000000000002 |Train loss: 4.00221672|Test loss: 4.29489056\n","Epoch: 073 | Lr: 0.00100000000000000002 |Train loss: 4.03890185|Test loss: 4.54538504\n","Epoch: 074 | Lr: 0.00100000000000000002 |Train loss: 3.97305224|Test loss: 4.37999598\n","Epoch: 075 | Lr: 0.00100000000000000002 |Train loss: 3.97704057|Test loss: 4.52146308\n","Epoch: 076 | Lr: 0.00100000000000000002 |Train loss: 3.93845012|Test loss: 4.75117985\n","Epoch: 077 | Lr: 0.00100000000000000002 |Train loss: 3.92854971|Test loss: 4.34489536\n","Epoch: 078 | Lr: 0.00100000000000000002 |Train loss: 3.90241965|Test loss: 4.55313412\n","Epoch: 079 | Lr: 0.00100000000000000002 |Train loss: 3.86460485|Test loss: 4.55606206\n","Epoch: 080 | Lr: 0.00100000000000000002 |Train loss: 3.88253903|Test loss: 5.05180407\n","Epoch: 081 | Lr: 0.00100000000000000002 |Train loss: 3.92174633|Test loss: 4.33495967\n","Epoch: 082 | Lr: 0.00100000000000000002 |Train loss: 3.92251074|Test loss: 4.31020912\n","Epoch: 083 | Lr: 0.00100000000000000002 |Train loss: 3.91544475|Test loss: 4.25422541\n","Epoch: 084 | Lr: 0.00100000000000000002 |Train loss: 3.92892357|Test loss: 4.26590554\n","Epoch: 085 | Lr: 0.00100000000000000002 |Train loss: 3.89297529|Test loss: 4.29720147\n","Epoch: 086 | Lr: 0.00100000000000000002 |Train loss: 3.92486284|Test loss: 4.20426210\n","Epoch: 087 | Lr: 0.00100000000000000002 |Train loss: 3.93292459|Test loss: 4.49590143\n","Epoch: 088 | Lr: 0.00100000000000000002 |Train loss: 3.89055713|Test loss: 4.13612882\n","Epoch: 089 | Lr: 0.00100000000000000002 |Train loss: 3.89222582|Test loss: 4.14794946\n","Epoch: 090 | Lr: 0.00100000000000000002 |Train loss: 3.89195430|Test loss: 4.33295234\n","Epoch: 091 | Lr: 0.00100000000000000002 |Train loss: 3.88348246|Test loss: 4.32454681\n","Epoch: 092 | Lr: 0.00100000000000000002 |Train loss: 3.88698129|Test loss: 4.18952195\n","Epoch: 093 | Lr: 0.00100000000000000002 |Train loss: 3.87567786|Test loss: 4.18354249\n","Epoch: 094 | Lr: 0.00100000000000000002 |Train loss: 3.82698466|Test loss: 4.52808634\n","Epoch: 095 | Lr: 0.00100000000000000002 |Train loss: 3.87136149|Test loss: 4.24662113\n","Epoch: 096 | Lr: 0.00100000000000000002 |Train loss: 3.86073033|Test loss: 4.18436225\n","Epoch: 097 | Lr: 0.00100000000000000002 |Train loss: 3.87234781|Test loss: 4.37226121\n","Epoch: 098 | Lr: 0.00100000000000000002 |Train loss: 3.87637214|Test loss: 4.38070337\n","Epoch: 099 | Lr: 0.00100000000000000002 |Train loss: 3.88419819|Test loss: 4.17331409\n","Epoch: 100 | Lr: 0.00100000000000000002 |Train loss: 3.85256777|Test loss: 4.10485442\n","Epoch: 101 | Lr: 0.00100000000000000002 |Train loss: 3.85726072|Test loss: 4.29887740\n","Epoch: 102 | Lr: 0.00100000000000000002 |Train loss: 3.87716943|Test loss: 4.32205486\n","Epoch: 103 | Lr: 0.00100000000000000002 |Train loss: 3.85849671|Test loss: 4.23178323\n","Epoch: 104 | Lr: 0.00100000000000000002 |Train loss: 3.87401352|Test loss: 4.40190331\n","Epoch: 105 | Lr: 0.00100000000000000002 |Train loss: 3.88584870|Test loss: 4.24749740\n","Epoch: 106 | Lr: 0.00100000000000000002 |Train loss: 3.88746788|Test loss: 4.15743272\n","Epoch: 107 | Lr: 0.00100000000000000002 |Train loss: 3.90395770|Test loss: 4.19360018\n","Epoch: 108 | Lr: 0.00100000000000000002 |Train loss: 3.88323043|Test loss: 4.54861927\n","Epoch: 109 | Lr: 0.00100000000000000002 |Train loss: 3.85744933|Test loss: 4.11849769\n","Epoch: 110 | Lr: 0.00100000000000000002 |Train loss: 3.84540204|Test loss: 4.32037401\n","Epoch: 111 | Lr: 0.00100000000000000002 |Train loss: 3.85834579|Test loss: 4.06432939\n","Epoch: 112 | Lr: 0.00100000000000000002 |Train loss: 3.86918157|Test loss: 4.11977919\n","Epoch: 113 | Lr: 0.00100000000000000002 |Train loss: 3.86105206|Test loss: 4.02343210\n","Epoch: 114 | Lr: 0.00100000000000000002 |Train loss: 3.84026613|Test loss: 4.36256679\n","Epoch: 115 | Lr: 0.00100000000000000002 |Train loss: 3.84348579|Test loss: 4.20251576\n","Epoch: 116 | Lr: 0.00100000000000000002 |Train loss: 3.87115099|Test loss: 4.20427020\n","Epoch: 117 | Lr: 0.00100000000000000002 |Train loss: 3.85416947|Test loss: 4.15218592\n","Epoch: 118 | Lr: 0.00100000000000000002 |Train loss: 3.86246689|Test loss: 4.16846752\n","Epoch: 119 | Lr: 0.00100000000000000002 |Train loss: 3.83596315|Test loss: 4.13903300\n","Epoch: 120 | Lr: 0.00100000000000000002 |Train loss: 3.83586939|Test loss: 4.22230943\n","Epoch: 121 | Lr: 0.00100000000000000002 |Train loss: 3.84418253|Test loss: 4.09206184\n","Epoch: 122 | Lr: 0.00100000000000000002 |Train loss: 3.83336693|Test loss: 4.17492978\n","Epoch: 123 | Lr: 0.00100000000000000002 |Train loss: 3.82165684|Test loss: 4.29555019\n","Epoch: 124 | Lr: 0.00100000000000000002 |Train loss: 3.83689670|Test loss: 4.17959166\n","Epoch: 125 | Lr: 0.00100000000000000002 |Train loss: 3.81643826|Test loss: 4.10769153\n","Epoch: 126 | Lr: 0.00100000000000000002 |Train loss: 3.84102537|Test loss: 4.09246397\n","Epoch: 127 | Lr: 0.00100000000000000002 |Train loss: 3.84070792|Test loss: 4.06036139\n","Epoch: 128 | Lr: 0.00100000000000000002 |Train loss: 3.81099278|Test loss: 4.38123480\n","Epoch: 129 | Lr: 0.00100000000000000002 |Train loss: 3.82400084|Test loss: 4.41167863\n","Epoch: 130 | Lr: 0.00100000000000000002 |Train loss: 3.85478226|Test loss: 4.28482183\n","Epoch: 131 | Lr: 0.00100000000000000002 |Train loss: 3.83565738|Test loss: 4.19242207\n","Epoch: 132 | Lr: 0.00100000000000000002 |Train loss: 3.81384961|Test loss: 4.71570555\n","Epoch: 133 | Lr: 0.00100000000000000002 |Train loss: 3.81226895|Test loss: 4.29192352\n","Epoch: 134 | Lr: 0.00100000000000000002 |Train loss: 3.79977008|Test loss: 4.23937043\n","Epoch: 135 | Lr: 0.00100000000000000002 |Train loss: 3.79638813|Test loss: 4.05039207\n","Epoch: 136 | Lr: 0.00100000000000000002 |Train loss: 3.82337262|Test loss: 4.48394998\n","Epoch: 137 | Lr: 0.00100000000000000002 |Train loss: 3.80490734|Test loss: 4.13868777\n","Epoch: 138 | Lr: 0.00100000000000000002 |Train loss: 3.81857816|Test loss: 4.01077787\n","Epoch: 139 | Lr: 0.00100000000000000002 |Train loss: 3.81431635|Test loss: 4.07977152\n","Epoch: 140 | Lr: 0.00100000000000000002 |Train loss: 3.83020043|Test loss: 4.05322170\n","Epoch: 141 | Lr: 0.00100000000000000002 |Train loss: 3.81794850|Test loss: 4.20443328\n","Epoch: 142 | Lr: 0.00100000000000000002 |Train loss: 3.80648402|Test loss: 4.21975104\n","Epoch: 143 | Lr: 0.00100000000000000002 |Train loss: 3.80035015|Test loss: 3.98605100\n","Epoch: 144 | Lr: 0.00100000000000000002 |Train loss: 3.79538790|Test loss: 4.20219851\n","Epoch: 145 | Lr: 0.00100000000000000002 |Train loss: 3.80263595|Test loss: 4.16569074\n","Epoch: 146 | Lr: 0.00100000000000000002 |Train loss: 3.78521125|Test loss: 4.03628810\n","Epoch: 147 | Lr: 0.00100000000000000002 |Train loss: 3.84285084|Test loss: 4.10371574\n","Epoch: 148 | Lr: 0.00100000000000000002 |Train loss: 3.80578909|Test loss: 4.08611377\n","Epoch: 149 | Lr: 0.00100000000000000002 |Train loss: 3.83297509|Test loss: 4.18179003\n","Epoch: 150 | Lr: 0.00100000000000000002 |Train loss: 3.80615656|Test loss: 4.21806153\n","Epoch: 151 | Lr: 0.00100000000000000002 |Train loss: 3.77038831|Test loss: 4.15212027\n","Epoch: 152 | Lr: 0.00100000000000000002 |Train loss: 3.79661838|Test loss: 4.15133095\n","Epoch: 153 | Lr: 0.00100000000000000002 |Train loss: 3.79101576|Test loss: 4.09372767\n","Epoch: 154 | Lr: 0.00100000000000000002 |Train loss: 3.78932834|Test loss: 4.08956567\n","Epoch: 155 | Lr: 0.00100000000000000002 |Train loss: 3.80337975|Test loss: 4.01428382\n","Epoch: 156 | Lr: 0.00100000000000000002 |Train loss: 3.78615743|Test loss: 4.08773851\n","Epoch: 157 | Lr: 0.00100000000000000002 |Train loss: 3.80292813|Test loss: 4.15234462\n","Epoch: 158 | Lr: 0.00100000000000000002 |Train loss: 3.78008682|Test loss: 4.24475392\n","Epoch: 159 | Lr: 0.00100000000000000002 |Train loss: 3.77378126|Test loss: 4.08583713\n","Epoch: 160 | Lr: 0.00100000000000000002 |Train loss: 3.77362414|Test loss: 4.04279844\n","Epoch: 161 | Lr: 0.00100000000000000002 |Train loss: 3.78251559|Test loss: 4.20391369\n","Epoch: 162 | Lr: 0.00100000000000000002 |Train loss: 3.77719736|Test loss: 4.17804503\n","Epoch: 163 | Lr: 0.00100000000000000002 |Train loss: 3.84744654|Test loss: 4.17371337\n","Epoch: 164 | Lr: 0.00100000000000000002 |Train loss: 3.78597105|Test loss: 4.17075761\n","Epoch: 165 | Lr: 0.00100000000000000002 |Train loss: 3.77218376|Test loss: 4.05482252\n","Epoch: 166 | Lr: 0.00100000000000000002 |Train loss: 3.78079398|Test loss: 4.11478376\n","Epoch: 167 | Lr: 0.00100000000000000002 |Train loss: 3.77278646|Test loss: 4.06715886\n","Epoch: 168 | Lr: 0.00100000000000000002 |Train loss: 3.74730233|Test loss: 4.11505302\n","Epoch: 169 | Lr: 0.00100000000000000002 |Train loss: 3.74515267|Test loss: 4.42124128\n","Epoch: 170 | Lr: 0.00100000000000000002 |Train loss: 3.76906437|Test loss: 4.38268137\n","Epoch: 171 | Lr: 0.00100000000000000002 |Train loss: 3.79082040|Test loss: 4.19212937\n","Epoch: 172 | Lr: 0.00100000000000000002 |Train loss: 3.78558111|Test loss: 4.23447657\n","Epoch: 173 | Lr: 0.00100000000000000002 |Train loss: 3.76216215|Test loss: 4.17661929\n","Epoch: 174 | Lr: 0.00100000000000000002 |Train loss: 3.77417401|Test loss: 4.14208937\n","Epoch: 175 | Lr: 0.00100000000000000002 |Train loss: 3.77529168|Test loss: 4.22013744\n","Epoch: 176 | Lr: 0.00100000000000000002 |Train loss: 3.77609700|Test loss: 4.15903298\n","Epoch: 177 | Lr: 0.00100000000000000002 |Train loss: 3.78986671|Test loss: 4.20337073\n","Epoch: 178 | Lr: 0.00100000000000000002 |Train loss: 3.77615674|Test loss: 4.27343766\n","Epoch: 179 | Lr: 0.00100000000000000002 |Train loss: 3.77524132|Test loss: 4.19381277\n","Epoch: 180 | Lr: 0.00100000000000000002 |Train loss: 3.78277250|Test loss: 4.15060965\n","Epoch: 181 | Lr: 0.00100000000000000002 |Train loss: 3.78839501|Test loss: 4.44711717\n","Epoch: 182 | Lr: 0.00100000000000000002 |Train loss: 3.76452972|Test loss: 4.02776202\n","Epoch: 183 | Lr: 0.00100000000000000002 |Train loss: 3.73884648|Test loss: 4.04307969\n","Epoch: 184 | Lr: 0.00100000000000000002 |Train loss: 3.73417207|Test loss: 4.18216054\n","Epoch: 185 | Lr: 0.00100000000000000002 |Train loss: 3.75223323|Test loss: 4.07598591\n","Epoch: 186 | Lr: 0.00100000000000000002 |Train loss: 3.74051756|Test loss: 4.21416831\n","Epoch: 187 | Lr: 0.00100000000000000002 |Train loss: 3.71919584|Test loss: 4.04888264\n","Epoch: 188 | Lr: 0.00100000000000000002 |Train loss: 3.74403594|Test loss: 4.43211730\n","Epoch: 189 | Lr: 0.00100000000000000002 |Train loss: 3.73089755|Test loss: 4.38089959\n","Epoch: 190 | Lr: 0.00100000000000000002 |Train loss: 3.74910154|Test loss: 4.32008497\n","Epoch: 191 | Lr: 0.00100000000000000002 |Train loss: 3.77578712|Test loss: 4.23770428\n","Epoch: 192 | Lr: 0.00100000000000000002 |Train loss: 3.74779626|Test loss: 4.11613480\n","Epoch: 193 | Lr: 0.00100000000000000002 |Train loss: 3.73877311|Test loss: 4.00451318\n","Epoch: 194 | Lr: 0.00100000000000000002 |Train loss: 3.72515245|Test loss: 4.10836244\n","Epoch: 195 | Lr: 0.00100000000000000002 |Train loss: 3.74566764|Test loss: 4.06933475\n","Epoch: 196 | Lr: 0.00100000000000000002 |Train loss: 3.73323782|Test loss: 4.12287259\n","Epoch: 197 | Lr: 0.00100000000000000002 |Train loss: 3.75464843|Test loss: 4.31069342\n","Epoch: 198 | Lr: 0.00100000000000000002 |Train loss: 3.72860881|Test loss: 4.28189341\n","Epoch: 199 | Lr: 0.00100000000000000002 |Train loss: 3.73225158|Test loss: 4.09273473\n","Epoch: 200 | Lr: 0.00100000000000000002 |Train loss: 3.73471085|Test loss: 4.20653375\n","Epoch: 201 | Lr: 0.00100000000000000002 |Train loss: 3.74223620|Test loss: 3.96834993\n","Epoch: 202 | Lr: 0.00100000000000000002 |Train loss: 3.72825938|Test loss: 4.19413042\n","Epoch: 203 | Lr: 0.00100000000000000002 |Train loss: 3.71152673|Test loss: 4.09217000\n","Epoch: 204 | Lr: 0.00100000000000000002 |Train loss: 3.71281662|Test loss: 4.06896098\n","Epoch: 205 | Lr: 0.00100000000000000002 |Train loss: 3.70642171|Test loss: 4.14381584\n","Epoch: 206 | Lr: 0.00100000000000000002 |Train loss: 3.72683511|Test loss: 4.03927851\n","Epoch: 207 | Lr: 0.00100000000000000002 |Train loss: 3.72406969|Test loss: 4.04059887\n","Epoch: 208 | Lr: 0.00100000000000000002 |Train loss: 3.72310346|Test loss: 4.05298066\n","Epoch: 209 | Lr: 0.00100000000000000002 |Train loss: 3.73999953|Test loss: 4.02204657\n","Epoch: 210 | Lr: 0.00100000000000000002 |Train loss: 3.73864122|Test loss: 4.24431880\n","Epoch: 211 | Lr: 0.00100000000000000002 |Train loss: 3.72773808|Test loss: 4.01936229\n","Epoch: 212 | Lr: 0.00100000000000000002 |Train loss: 3.72510990|Test loss: 3.98711491\n","Epoch: 213 | Lr: 0.00100000000000000002 |Train loss: 3.74221041|Test loss: 3.97795296\n","Epoch: 214 | Lr: 0.00100000000000000002 |Train loss: 3.74780766|Test loss: 4.01889149\n","Epoch: 215 | Lr: 0.00100000000000000002 |Train loss: 3.75623379|Test loss: 4.03392434\n","Epoch: 216 | Lr: 0.00100000000000000002 |Train loss: 3.77591298|Test loss: 4.27204641\n","Epoch: 217 | Lr: 0.00100000000000000002 |Train loss: 3.77310648|Test loss: 4.07044133\n","Epoch: 218 | Lr: 0.00100000000000000002 |Train loss: 3.76697189|Test loss: 4.01231654\n","Epoch: 219 | Lr: 0.00100000000000000002 |Train loss: 3.73298868|Test loss: 4.13798173\n","Epoch: 220 | Lr: 0.00100000000000000002 |Train loss: 3.75817355|Test loss: 4.03219239\n","Epoch: 221 | Lr: 0.00100000000000000002 |Train loss: 3.73273126|Test loss: 4.14077663\n","Epoch: 222 | Lr: 0.00100000000000000002 |Train loss: 3.71369735|Test loss: 3.99631317\n","Epoch: 223 | Lr: 0.00100000000000000002 |Train loss: 3.74506058|Test loss: 4.04729438\n","Epoch: 224 | Lr: 0.00100000000000000002 |Train loss: 3.72589813|Test loss: 3.98390683\n","Epoch: 225 | Lr: 0.00100000000000000002 |Train loss: 3.75401386|Test loss: 4.05257169\n","Epoch: 226 | Lr: 0.00100000000000000002 |Train loss: 3.72307231|Test loss: 4.05373144\n","Epoch: 227 | Lr: 0.00100000000000000002 |Train loss: 3.72157562|Test loss: 4.03108358\n","Epoch: 228 | Lr: 0.00100000000000000002 |Train loss: 3.69732742|Test loss: 4.07938854\n","Epoch: 229 | Lr: 0.00100000000000000002 |Train loss: 3.70395062|Test loss: 4.04659224\n","Epoch: 230 | Lr: 0.00100000000000000002 |Train loss: 3.75482933|Test loss: 4.02036659\n","Epoch: 231 | Lr: 0.00100000000000000002 |Train loss: 3.71079189|Test loss: 4.00620588\n","Epoch: 232 | Lr: 0.00100000000000000002 |Train loss: 3.70421853|Test loss: 4.04388881\n","Epoch: 233 | Lr: 0.00100000000000000002 |Train loss: 3.70370807|Test loss: 4.17191648\n","Epoch: 234 | Lr: 0.00100000000000000002 |Train loss: 3.72501848|Test loss: 4.12549114\n","Epoch: 235 | Lr: 0.00100000000000000002 |Train loss: 3.69535182|Test loss: 4.12603792\n","Epoch: 236 | Lr: 0.00100000000000000002 |Train loss: 3.69341127|Test loss: 4.02266320\n","Epoch: 237 | Lr: 0.00100000000000000002 |Train loss: 3.69819009|Test loss: 4.02736457\n","Epoch: 238 | Lr: 0.00100000000000000002 |Train loss: 3.68220615|Test loss: 3.96159101\n","Epoch: 239 | Lr: 0.00100000000000000002 |Train loss: 3.69823897|Test loss: 3.98824040\n","Epoch: 240 | Lr: 0.00100000000000000002 |Train loss: 3.67401089|Test loss: 4.00495172\n","Epoch: 241 | Lr: 0.00100000000000000002 |Train loss: 3.67625298|Test loss: 4.01376041\n","Epoch: 242 | Lr: 0.00100000000000000002 |Train loss: 3.68504862|Test loss: 3.99144006\n","Epoch: 243 | Lr: 0.00100000000000000002 |Train loss: 3.66016428|Test loss: 4.01551151\n","Epoch: 244 | Lr: 0.00100000000000000002 |Train loss: 3.70272036|Test loss: 4.03377334\n","Epoch: 245 | Lr: 0.00100000000000000002 |Train loss: 3.70401206|Test loss: 3.96574465\n","Epoch: 246 | Lr: 0.00100000000000000002 |Train loss: 3.71944996|Test loss: 3.93886288\n","Epoch: 247 | Lr: 0.00100000000000000002 |Train loss: 3.73603936|Test loss: 4.06348149\n","Epoch: 248 | Lr: 0.00100000000000000002 |Train loss: 3.69604282|Test loss: 4.29505038\n","Epoch: 249 | Lr: 0.00100000000000000002 |Train loss: 3.68444735|Test loss: 4.09376359\n","Epoch: 250 | Lr: 0.00100000000000000002 |Train loss: 3.66564979|Test loss: 4.04788502\n","Epoch: 251 | Lr: 0.00100000000000000002 |Train loss: 3.67562660|Test loss: 4.27196646\n","Epoch: 252 | Lr: 0.00100000000000000002 |Train loss: 3.69687066|Test loss: 4.21688000\n","Epoch: 253 | Lr: 0.00100000000000000002 |Train loss: 3.70859239|Test loss: 4.14469560\n","Epoch: 254 | Lr: 0.00100000000000000002 |Train loss: 3.70017481|Test loss: 4.09441996\n","Epoch: 255 | Lr: 0.00100000000000000002 |Train loss: 3.66865697|Test loss: 4.04897451\n","Epoch: 256 | Lr: 0.00100000000000000002 |Train loss: 3.65542293|Test loss: 4.17598160\n","Epoch: 257 | Lr: 0.00100000000000000002 |Train loss: 3.66495057|Test loss: 4.08137194\n","Epoch: 258 | Lr: 0.00100000000000000002 |Train loss: 3.67452228|Test loss: 4.15803583\n","Epoch: 259 | Lr: 0.00100000000000000002 |Train loss: 3.64313658|Test loss: 4.06239820\n","Epoch: 260 | Lr: 0.00100000000000000002 |Train loss: 3.67424633|Test loss: 4.08401378\n","Epoch: 261 | Lr: 0.00100000000000000002 |Train loss: 3.68206016|Test loss: 4.09812347\n","Epoch: 262 | Lr: 0.00100000000000000002 |Train loss: 3.65347799|Test loss: 3.96940581\n","Epoch: 263 | Lr: 0.00100000000000000002 |Train loss: 3.65641610|Test loss: 4.34788879\n","Epoch: 264 | Lr: 0.00100000000000000002 |Train loss: 3.69308676|Test loss: 4.02982314\n","Epoch: 265 | Lr: 0.00100000000000000002 |Train loss: 3.65527976|Test loss: 4.21406110\n","Epoch: 266 | Lr: 0.00100000000000000002 |Train loss: 3.65283062|Test loss: 4.20739667\n","Epoch: 267 | Lr: 0.00100000000000000002 |Train loss: 3.66988643|Test loss: 4.10901554\n","Epoch: 268 | Lr: 0.00100000000000000002 |Train loss: 3.64008935|Test loss: 4.10691770\n","Epoch: 269 | Lr: 0.00100000000000000002 |Train loss: 3.66879956|Test loss: 4.09767421\n","Epoch: 270 | Lr: 0.00100000000000000002 |Train loss: 3.65501799|Test loss: 4.20094021\n","Epoch: 271 | Lr: 0.00100000000000000002 |Train loss: 3.68016754|Test loss: 4.17757781\n","Epoch: 272 | Lr: 0.00100000000000000002 |Train loss: 3.69204553|Test loss: 4.08581360\n","Epoch: 273 | Lr: 0.00100000000000000002 |Train loss: 3.70539570|Test loss: 4.00712657\n","Epoch: 274 | Lr: 0.00100000000000000002 |Train loss: 3.68608208|Test loss: 4.27914111\n","Epoch: 275 | Lr: 0.00100000000000000002 |Train loss: 3.67257484|Test loss: 4.17709732\n","Epoch: 276 | Lr: 0.00100000000000000002 |Train loss: 3.65640497|Test loss: 4.11000554\n","Epoch: 277 | Lr: 0.00100000000000000002 |Train loss: 3.69370047|Test loss: 4.30274248\n","Epoch: 278 | Lr: 0.00100000000000000002 |Train loss: 3.66250656|Test loss: 4.16977604\n","Epoch: 279 | Lr: 0.00100000000000000002 |Train loss: 3.67895379|Test loss: 4.19719712\n","Epoch: 280 | Lr: 0.00100000000000000002 |Train loss: 3.68697768|Test loss: 4.10596593\n","Epoch: 281 | Lr: 0.00100000000000000002 |Train loss: 3.65617160|Test loss: 4.04329364\n","Epoch: 282 | Lr: 0.00100000000000000002 |Train loss: 3.70045996|Test loss: 4.07752268\n","Epoch: 283 | Lr: 0.00100000000000000002 |Train loss: 3.67955768|Test loss: 4.04918265\n","Epoch: 284 | Lr: 0.00100000000000000002 |Train loss: 3.70501886|Test loss: 4.33785709\n","Epoch: 285 | Lr: 0.00100000000000000002 |Train loss: 3.76481915|Test loss: 3.96374393\n","Epoch: 286 | Lr: 0.00100000000000000002 |Train loss: 3.66159679|Test loss: 3.99770713\n","Epoch: 287 | Lr: 0.00100000000000000002 |Train loss: 3.68789848|Test loss: 4.10635026\n","Epoch: 288 | Lr: 0.00100000000000000002 |Train loss: 3.72299095|Test loss: 4.24352853\n","Epoch: 289 | Lr: 0.00100000000000000002 |Train loss: 3.68852719|Test loss: 4.06560787\n","Epoch: 290 | Lr: 0.00100000000000000002 |Train loss: 3.72326521|Test loss: 4.07404749\n","Epoch: 291 | Lr: 0.00100000000000000002 |Train loss: 3.72113287|Test loss: 4.20460367\n","Epoch: 292 | Lr: 0.00100000000000000002 |Train loss: 3.65684954|Test loss: 4.06379930\n","Epoch: 293 | Lr: 0.00100000000000000002 |Train loss: 3.64835533|Test loss: 4.07227755\n","Epoch: 294 | Lr: 0.00100000000000000002 |Train loss: 3.73813349|Test loss: 4.06853278\n","Epoch: 295 | Lr: 0.00100000000000000002 |Train loss: 3.73579478|Test loss: 4.02926048\n","Epoch: 296 | Lr: 0.00100000000000000002 |Train loss: 3.68917213|Test loss: 4.13007371\n","Epoch: 297 | Lr: 0.00100000000000000002 |Train loss: 3.73932683|Test loss: 4.11659193\n","Epoch: 298 | Lr: 0.00100000000000000002 |Train loss: 3.71416875|Test loss: 4.10335581\n","Epoch: 299 | Lr: 0.00100000000000000002 |Train loss: 3.69408027|Test loss: 4.14317290\n","Epoch: 300 | Lr: 0.00100000000000000002 |Train loss: 3.69012215|Test loss: 4.01341565\n","Epoch: 301 | Lr: 0.00100000000000000002 |Train loss: 3.70736667|Test loss: 4.18649689\n","Epoch: 302 | Lr: 0.00100000000000000002 |Train loss: 3.69537944|Test loss: 4.01449800\n","Epoch: 303 | Lr: 0.00100000000000000002 |Train loss: 3.69517771|Test loss: 3.93758305\n","Epoch: 304 | Lr: 0.00100000000000000002 |Train loss: 3.68385206|Test loss: 4.06872789\n","Epoch: 305 | Lr: 0.00100000000000000002 |Train loss: 3.66132065|Test loss: 4.01477885\n","Epoch: 306 | Lr: 0.00100000000000000002 |Train loss: 3.63531695|Test loss: 4.00793099\n","Epoch: 307 | Lr: 0.00100000000000000002 |Train loss: 3.63748801|Test loss: 4.12671542\n","Epoch: 308 | Lr: 0.00100000000000000002 |Train loss: 3.65184087|Test loss: 4.10026375\n","Epoch: 309 | Lr: 0.00100000000000000002 |Train loss: 3.65232223|Test loss: 4.14722037\n","Epoch: 310 | Lr: 0.00100000000000000002 |Train loss: 3.66296617|Test loss: 4.12616014\n","Epoch: 311 | Lr: 0.00100000000000000002 |Train loss: 3.68192679|Test loss: 3.96663849\n","Epoch: 312 | Lr: 0.00100000000000000002 |Train loss: 3.69923798|Test loss: 4.06133970\n","Epoch: 313 | Lr: 0.00100000000000000002 |Train loss: 3.64657428|Test loss: 4.07996941\n","Epoch: 314 | Lr: 0.00100000000000000002 |Train loss: 3.62623576|Test loss: 4.02518376\n","Epoch: 315 | Lr: 0.00100000000000000002 |Train loss: 3.67586722|Test loss: 4.13863778\n","Epoch: 316 | Lr: 0.00100000000000000002 |Train loss: 3.65440575|Test loss: 4.05808576\n","Epoch: 317 | Lr: 0.00100000000000000002 |Train loss: 3.68329322|Test loss: 4.06551520\n","Epoch: 318 | Lr: 0.00100000000000000002 |Train loss: 3.65392743|Test loss: 4.00633915\n","Epoch: 319 | Lr: 0.00100000000000000002 |Train loss: 3.66904630|Test loss: 3.94515546\n","Epoch: 320 | Lr: 0.00100000000000000002 |Train loss: 3.67381994|Test loss: 3.93304189\n","Epoch: 321 | Lr: 0.00100000000000000002 |Train loss: 3.69441011|Test loss: 3.98721782\n","Epoch: 322 | Lr: 0.00100000000000000002 |Train loss: 3.66508194|Test loss: 3.94540850\n","Epoch: 323 | Lr: 0.00100000000000000002 |Train loss: 3.63819319|Test loss: 3.97170901\n","Epoch: 324 | Lr: 0.00100000000000000002 |Train loss: 3.64918476|Test loss: 4.10461760\n","Epoch: 325 | Lr: 0.00100000000000000002 |Train loss: 3.67219641|Test loss: 3.94856922\n","Epoch: 326 | Lr: 0.00100000000000000002 |Train loss: 3.68511166|Test loss: 4.13493888\n","Epoch: 327 | Lr: 0.00100000000000000002 |Train loss: 3.66291791|Test loss: 3.99234271\n","Epoch: 328 | Lr: 0.00100000000000000002 |Train loss: 3.61468063|Test loss: 4.13878266\n","Epoch: 329 | Lr: 0.00100000000000000002 |Train loss: 3.64951887|Test loss: 3.92817378\n","Epoch: 330 | Lr: 0.00100000000000000002 |Train loss: 3.66761039|Test loss: 3.98934484\n","Epoch: 331 | Lr: 0.00100000000000000002 |Train loss: 3.66816264|Test loss: 3.90456931\n","Epoch: 332 | Lr: 0.00100000000000000002 |Train loss: 3.63971118|Test loss: 3.96837584\n","Epoch: 333 | Lr: 0.00100000000000000002 |Train loss: 3.64538370|Test loss: 3.89304773\n","Epoch: 334 | Lr: 0.00100000000000000002 |Train loss: 3.61514181|Test loss: 3.98878503\n","Epoch: 335 | Lr: 0.00100000000000000002 |Train loss: 3.62613072|Test loss: 3.93734829\n","Epoch: 336 | Lr: 0.00100000000000000002 |Train loss: 3.65505097|Test loss: 3.90640720\n","Epoch: 337 | Lr: 0.00100000000000000002 |Train loss: 3.68270163|Test loss: 4.17698018\n","Epoch: 338 | Lr: 0.00100000000000000002 |Train loss: 3.64300098|Test loss: 3.98682777\n","Epoch: 339 | Lr: 0.00100000000000000002 |Train loss: 3.67998395|Test loss: 4.04026405\n","Epoch: 340 | Lr: 0.00100000000000000002 |Train loss: 3.64321043|Test loss: 4.01794926\n","Epoch: 341 | Lr: 0.00100000000000000002 |Train loss: 3.64276282|Test loss: 3.97999779\n","Epoch: 342 | Lr: 0.00100000000000000002 |Train loss: 3.61221292|Test loss: 3.93003194\n","Epoch: 343 | Lr: 0.00100000000000000002 |Train loss: 3.65834586|Test loss: 3.97546196\n","Epoch: 344 | Lr: 0.00100000000000000002 |Train loss: 3.61309755|Test loss: 3.95714959\n","Epoch: 345 | Lr: 0.00100000000000000002 |Train loss: 3.63663246|Test loss: 3.93046411\n","Epoch: 346 | Lr: 0.00100000000000000002 |Train loss: 3.73453987|Test loss: 4.06051135\n","Epoch: 347 | Lr: 0.00100000000000000002 |Train loss: 3.65436276|Test loss: 4.04733356\n","Epoch: 348 | Lr: 0.00100000000000000002 |Train loss: 3.68421016|Test loss: 4.07158724\n","Epoch: 349 | Lr: 0.00100000000000000002 |Train loss: 3.64743896|Test loss: 3.96469291\n","Epoch: 350 | Lr: 0.00100000000000000002 |Train loss: 3.66970519|Test loss: 4.16533073\n","Epoch: 351 | Lr: 0.00100000000000000002 |Train loss: 3.63111365|Test loss: 4.05679576\n","Epoch: 352 | Lr: 0.00100000000000000002 |Train loss: 3.62386862|Test loss: 3.96766853\n","Epoch: 353 | Lr: 0.00100000000000000002 |Train loss: 3.62154977|Test loss: 4.05137308\n","Epoch: 354 | Lr: 0.00100000000000000002 |Train loss: 3.67024201|Test loss: 4.20770065\n","Epoch: 355 | Lr: 0.00100000000000000002 |Train loss: 3.65691721|Test loss: 3.99110866\n","Epoch: 356 | Lr: 0.00100000000000000002 |Train loss: 3.63516849|Test loss: 4.04153919\n","Epoch: 357 | Lr: 0.00100000000000000002 |Train loss: 3.62514744|Test loss: 4.04129799\n","Epoch: 358 | Lr: 0.00100000000000000002 |Train loss: 3.60190769|Test loss: 4.04099011\n","Epoch: 359 | Lr: 0.00100000000000000002 |Train loss: 3.62259825|Test loss: 3.89195704\n","Epoch: 360 | Lr: 0.00100000000000000002 |Train loss: 3.62923054|Test loss: 3.95969605\n","Epoch: 361 | Lr: 0.00100000000000000002 |Train loss: 3.59840135|Test loss: 4.08757305\n","Epoch: 362 | Lr: 0.00100000000000000002 |Train loss: 3.62688003|Test loss: 3.98274040\n","Epoch: 363 | Lr: 0.00100000000000000002 |Train loss: 3.65325300|Test loss: 4.20450950\n","Epoch: 364 | Lr: 0.00100000000000000002 |Train loss: 3.59200458|Test loss: 4.00160122\n","Epoch: 365 | Lr: 0.00100000000000000002 |Train loss: 3.60573445|Test loss: 4.01276342\n","Epoch: 366 | Lr: 0.00100000000000000002 |Train loss: 3.63061965|Test loss: 4.14576062\n","Epoch: 367 | Lr: 0.00100000000000000002 |Train loss: 3.60643280|Test loss: 4.13263806\n","Epoch: 368 | Lr: 0.00100000000000000002 |Train loss: 3.63797243|Test loss: 4.14456550\n","Epoch: 369 | Lr: 0.00100000000000000002 |Train loss: 3.68739599|Test loss: 4.18747663\n","Epoch: 370 | Lr: 0.00100000000000000002 |Train loss: 3.73667983|Test loss: 4.14679138\n","Epoch: 371 | Lr: 0.00100000000000000002 |Train loss: 3.71917385|Test loss: 4.09496228\n","Epoch: 372 | Lr: 0.00100000000000000002 |Train loss: 3.74375121|Test loss: 3.93880900\n","Epoch: 373 | Lr: 0.00100000000000000002 |Train loss: 3.72245755|Test loss: 4.04936179\n","Epoch: 374 | Lr: 0.00100000000000000002 |Train loss: 3.68886024|Test loss: 3.89605753\n","Epoch: 375 | Lr: 0.00100000000000000002 |Train loss: 3.61534423|Test loss: 3.87664890\n","Epoch: 376 | Lr: 0.00100000000000000002 |Train loss: 3.62601511|Test loss: 3.87250996\n","Epoch: 377 | Lr: 0.00100000000000000002 |Train loss: 3.61285190|Test loss: 3.95326312\n","Epoch: 378 | Lr: 0.00100000000000000002 |Train loss: 3.59102420|Test loss: 3.95489049\n","Epoch: 379 | Lr: 0.00100000000000000002 |Train loss: 3.59718694|Test loss: 3.99177122\n","Epoch: 380 | Lr: 0.00100000000000000002 |Train loss: 3.58031217|Test loss: 3.93974447\n","Epoch: 381 | Lr: 0.00100000000000000002 |Train loss: 3.59227693|Test loss: 3.97735095\n","Epoch: 382 | Lr: 0.00100000000000000002 |Train loss: 3.58376356|Test loss: 4.07601945\n","Epoch: 383 | Lr: 0.00100000000000000002 |Train loss: 3.61761967|Test loss: 3.93455466\n","Epoch: 384 | Lr: 0.00100000000000000002 |Train loss: 3.59522746|Test loss: 3.98564855\n","Epoch: 385 | Lr: 0.00100000000000000002 |Train loss: 3.62329493|Test loss: 3.94811114\n","Epoch: 386 | Lr: 0.00100000000000000002 |Train loss: 3.59807901|Test loss: 4.04116742\n","Epoch: 387 | Lr: 0.00100000000000000002 |Train loss: 3.63312109|Test loss: 4.00930770\n","Epoch: 388 | Lr: 0.00100000000000000002 |Train loss: 3.59909302|Test loss: 3.99271019\n","Epoch: 389 | Lr: 0.00100000000000000002 |Train loss: 3.59155478|Test loss: 4.02486777\n","Epoch: 390 | Lr: 0.00100000000000000002 |Train loss: 3.57923742|Test loss: 3.99750233\n","Epoch: 391 | Lr: 0.00100000000000000002 |Train loss: 3.56094553|Test loss: 4.06466293\n","Epoch: 392 | Lr: 0.00100000000000000002 |Train loss: 3.59775285|Test loss: 4.10143423\n","Epoch: 393 | Lr: 0.00100000000000000002 |Train loss: 3.60111978|Test loss: 4.06199590\n","Epoch: 394 | Lr: 0.00100000000000000002 |Train loss: 3.58279969|Test loss: 4.04978140\n","Epoch: 395 | Lr: 0.00100000000000000002 |Train loss: 3.57392168|Test loss: 3.93202710\n","Epoch: 396 | Lr: 0.00100000000000000002 |Train loss: 3.64295071|Test loss: 3.97025371\n","Epoch: 397 | Lr: 0.00100000000000000002 |Train loss: 3.61776817|Test loss: 4.01660864\n","Epoch: 398 | Lr: 0.00100000000000000002 |Train loss: 3.61167073|Test loss: 4.11504952\n","Epoch: 399 | Lr: 0.00100000000000000002 |Train loss: 3.61077340|Test loss: 4.00822401\n","Epoch: 400 | Lr: 0.00100000000000000002 |Train loss: 3.60600402|Test loss: 4.02395209\n","Epoch: 401 | Lr: 0.00100000000000000002 |Train loss: 3.58655699|Test loss: 3.99978352\n","Epoch: 402 | Lr: 0.00100000000000000002 |Train loss: 3.64641295|Test loss: 4.07447433\n","Epoch: 403 | Lr: 0.00100000000000000002 |Train loss: 3.64562647|Test loss: 3.98284070\n","Epoch: 404 | Lr: 0.00100000000000000002 |Train loss: 3.64758211|Test loss: 4.17593265\n","Epoch: 405 | Lr: 0.00100000000000000002 |Train loss: 3.65214994|Test loss: 4.07252328\n","Epoch: 406 | Lr: 0.00100000000000000002 |Train loss: 3.63815500|Test loss: 4.05922429\n","Epoch: 407 | Lr: 0.00100000000000000002 |Train loss: 3.69393063|Test loss: 4.16049639\n","Epoch: 408 | Lr: 0.00100000000000000002 |Train loss: 3.66769580|Test loss: 4.12499126\n","Epoch: 409 | Lr: 0.00100000000000000002 |Train loss: 3.67585834|Test loss: 3.96878036\n","Epoch: 410 | Lr: 0.00100000000000000002 |Train loss: 3.66575380|Test loss: 3.98536913\n","Epoch: 411 | Lr: 0.00100000000000000002 |Train loss: 3.69771528|Test loss: 4.02714396\n","Epoch: 412 | Lr: 0.00100000000000000002 |Train loss: 3.67691986|Test loss: 3.98535848\n","Epoch: 413 | Lr: 0.00100000000000000002 |Train loss: 3.65922362|Test loss: 4.10530273\n","Epoch: 414 | Lr: 0.00100000000000000002 |Train loss: 3.62766320|Test loss: 4.09887640\n","Epoch: 415 | Lr: 0.00100000000000000002 |Train loss: 3.64880671|Test loss: 4.06229973\n","Epoch: 416 | Lr: 0.00100000000000000002 |Train loss: 3.59654780|Test loss: 3.85412216\n","Epoch: 417 | Lr: 0.00100000000000000002 |Train loss: 3.58088396|Test loss: 3.99572428\n","Epoch: 418 | Lr: 0.00100000000000000002 |Train loss: 3.59863732|Test loss: 3.95739865\n","Epoch: 419 | Lr: 0.00100000000000000002 |Train loss: 3.57343354|Test loss: 4.04339083\n","Epoch: 420 | Lr: 0.00100000000000000002 |Train loss: 3.55586455|Test loss: 4.02160557\n","Epoch: 421 | Lr: 0.00100000000000000002 |Train loss: 3.58230835|Test loss: 4.06156230\n","Epoch: 422 | Lr: 0.00100000000000000002 |Train loss: 3.59459448|Test loss: 4.01530965\n","Epoch: 423 | Lr: 0.00100000000000000002 |Train loss: 3.57905579|Test loss: 4.03933247\n","Epoch: 424 | Lr: 0.00100000000000000002 |Train loss: 3.58510911|Test loss: 4.03821007\n","Epoch: 425 | Lr: 0.00100000000000000002 |Train loss: 3.56858589|Test loss: 3.95516133\n","Epoch: 426 | Lr: 0.00100000000000000002 |Train loss: 3.55114836|Test loss: 4.25309881\n","Epoch: 427 | Lr: 0.00100000000000000002 |Train loss: 3.58878710|Test loss: 4.01701021\n","Epoch: 428 | Lr: 0.00100000000000000002 |Train loss: 3.60822203|Test loss: 3.96275854\n","Epoch: 429 | Lr: 0.00100000000000000002 |Train loss: 3.58141758|Test loss: 3.98187749\n","Epoch: 430 | Lr: 0.00100000000000000002 |Train loss: 3.57382806|Test loss: 3.90960519\n","Epoch: 431 | Lr: 0.00100000000000000002 |Train loss: 3.59604142|Test loss: 4.11878188\n","Epoch: 432 | Lr: 0.00100000000000000002 |Train loss: 3.60827531|Test loss: 4.10304332\n","Epoch: 433 | Lr: 0.00100000000000000002 |Train loss: 3.63346233|Test loss: 4.12468004\n","Epoch: 434 | Lr: 0.00100000000000000002 |Train loss: 3.61107339|Test loss: 4.47241100\n","Epoch: 435 | Lr: 0.00100000000000000002 |Train loss: 3.62868675|Test loss: 4.12540762\n","Epoch: 436 | Lr: 0.00100000000000000002 |Train loss: 3.63163845|Test loss: 4.09408696\n","Epoch: 437 | Lr: 0.00100000000000000002 |Train loss: 3.59468083|Test loss: 4.17741505\n","Epoch: 438 | Lr: 0.00100000000000000002 |Train loss: 3.57541933|Test loss: 4.14407341\n","Epoch: 439 | Lr: 0.00100000000000000002 |Train loss: 3.65050238|Test loss: 4.44181601\n","Epoch: 440 | Lr: 0.00100000000000000002 |Train loss: 3.62210433|Test loss: 4.38729922\n","Epoch: 441 | Lr: 0.00100000000000000002 |Train loss: 3.68321826|Test loss: 4.27708904\n","Epoch: 442 | Lr: 0.00100000000000000002 |Train loss: 3.66801322|Test loss: 4.19474808\n","Epoch: 443 | Lr: 0.00100000000000000002 |Train loss: 3.62769854|Test loss: 3.91431324\n","Epoch: 444 | Lr: 0.00100000000000000002 |Train loss: 3.59914567|Test loss: 4.02975456\n","Epoch: 445 | Lr: 0.00100000000000000002 |Train loss: 3.58168560|Test loss: 4.02742648\n","Epoch: 446 | Lr: 0.00100000000000000002 |Train loss: 3.55406175|Test loss: 4.07175271\n","Epoch: 447 | Lr: 0.00100000000000000002 |Train loss: 3.55967832|Test loss: 4.17927647\n","Epoch: 448 | Lr: 0.00100000000000000002 |Train loss: 3.59716562|Test loss: 3.95270149\n","Epoch: 449 | Lr: 0.00100000000000000002 |Train loss: 3.57944385|Test loss: 4.12894424\n","Epoch: 450 | Lr: 0.00100000000000000002 |Train loss: 3.56389993|Test loss: 3.96201166\n","Epoch: 451 | Lr: 0.00100000000000000002 |Train loss: 3.56766679|Test loss: 4.11744936\n","Epoch: 452 | Lr: 0.00100000000000000002 |Train loss: 3.54504277|Test loss: 4.18191719\n","Epoch: 453 | Lr: 0.00100000000000000002 |Train loss: 3.54426386|Test loss: 3.92340541\n","Epoch: 454 | Lr: 0.00100000000000000002 |Train loss: 3.53822152|Test loss: 3.99514691\n","Epoch: 455 | Lr: 0.00100000000000000002 |Train loss: 3.54263804|Test loss: 4.15122255\n","Epoch: 456 | Lr: 0.00100000000000000002 |Train loss: 3.53131711|Test loss: 4.08515541\n","Epoch: 457 | Lr: 0.00100000000000000002 |Train loss: 3.55650097|Test loss: 4.26873366\n","Epoch: 458 | Lr: 0.00100000000000000002 |Train loss: 3.53626035|Test loss: 4.21301548\n","Epoch: 459 | Lr: 0.00100000000000000002 |Train loss: 3.52828864|Test loss: 4.18720134\n","Epoch: 460 | Lr: 0.00100000000000000002 |Train loss: 3.53702716|Test loss: 4.18827788\n","Epoch: 461 | Lr: 0.00100000000000000002 |Train loss: 3.53246359|Test loss: 4.15315239\n","Epoch: 462 | Lr: 0.00100000000000000002 |Train loss: 3.53668380|Test loss: 4.18839677\n","Epoch: 463 | Lr: 0.00100000000000000002 |Train loss: 3.53665000|Test loss: 3.94838325\n","Epoch: 464 | Lr: 0.00100000000000000002 |Train loss: 3.51483226|Test loss: 3.97014189\n","Epoch: 465 | Lr: 0.00100000000000000002 |Train loss: 3.53507759|Test loss: 4.16028547\n","Epoch: 466 | Lr: 0.00100000000000000002 |Train loss: 3.51358412|Test loss: 4.07416455\n","Epoch: 467 | Lr: 0.00100000000000000002 |Train loss: 3.52980153|Test loss: 4.09571234\n","Epoch: 468 | Lr: 0.00100000000000000002 |Train loss: 3.52884132|Test loss: 4.09702190\n","Epoch: 469 | Lr: 0.00100000000000000002 |Train loss: 3.52674067|Test loss: 4.25029874\n","Epoch: 470 | Lr: 0.00100000000000000002 |Train loss: 3.54765143|Test loss: 4.32685685\n","Epoch: 471 | Lr: 0.00100000000000000002 |Train loss: 3.51936513|Test loss: 4.43467514\n","Epoch: 472 | Lr: 0.00100000000000000002 |Train loss: 3.56833462|Test loss: 4.30389309\n","Epoch: 473 | Lr: 0.00100000000000000002 |Train loss: 3.60269713|Test loss: 4.60387166\n","Epoch: 474 | Lr: 0.00100000000000000002 |Train loss: 3.58159840|Test loss: 4.26422103\n","Epoch: 475 | Lr: 0.00100000000000000002 |Train loss: 3.60429829|Test loss: 4.57631318\n","Epoch: 476 | Lr: 0.00100000000000000002 |Train loss: 3.57345631|Test loss: 4.31617308\n","Epoch: 477 | Lr: 0.00100000000000000002 |Train loss: 3.56319551|Test loss: 4.34515627\n","Epoch: 478 | Lr: 0.00100000000000000002 |Train loss: 3.56892882|Test loss: 4.19269872\n","Epoch: 479 | Lr: 0.00100000000000000002 |Train loss: 3.59947119|Test loss: 4.12416402\n","Epoch: 480 | Lr: 0.00100000000000000002 |Train loss: 3.67444475|Test loss: 4.49227754\n","Epoch: 481 | Lr: 0.00100000000000000002 |Train loss: 3.65544736|Test loss: 4.52623280\n","Epoch: 482 | Lr: 0.00100000000000000002 |Train loss: 3.56521181|Test loss: 4.31467446\n","Epoch: 483 | Lr: 0.00100000000000000002 |Train loss: 3.62619052|Test loss: 4.27496656\n","Epoch: 484 | Lr: 0.00100000000000000002 |Train loss: 3.59693203|Test loss: 4.18268649\n","Epoch: 485 | Lr: 0.00100000000000000002 |Train loss: 3.57448705|Test loss: 4.06687347\n","Epoch: 486 | Lr: 0.00100000000000000002 |Train loss: 3.56128504|Test loss: 4.05529348\n","Epoch: 487 | Lr: 0.00100000000000000002 |Train loss: 3.59833984|Test loss: 3.96162836\n","Epoch: 488 | Lr: 0.00100000000000000002 |Train loss: 3.60120106|Test loss: 4.28376118\n","Epoch: 489 | Lr: 0.00100000000000000002 |Train loss: 3.59120500|Test loss: 4.45793621\n","Epoch: 490 | Lr: 0.00100000000000000002 |Train loss: 3.57018383|Test loss: 4.19665543\n","Epoch: 491 | Lr: 0.00100000000000000002 |Train loss: 3.62464192|Test loss: 4.15261157\n","Epoch: 492 | Lr: 0.00100000000000000002 |Train loss: 3.56030436|Test loss: 3.94644046\n","Epoch: 493 | Lr: 0.00100000000000000002 |Train loss: 3.55422149|Test loss: 4.17007812\n","Epoch: 494 | Lr: 0.00100000000000000002 |Train loss: 3.57811238|Test loss: 4.32263931\n","Epoch: 495 | Lr: 0.00100000000000000002 |Train loss: 3.56392322|Test loss: 4.21469339\n","Epoch: 496 | Lr: 0.00100000000000000002 |Train loss: 3.54248931|Test loss: 4.05538527\n","Epoch: 497 | Lr: 0.00100000000000000002 |Train loss: 3.53298118|Test loss: 4.00103752\n","Epoch: 498 | Lr: 0.00100000000000000002 |Train loss: 3.56023123|Test loss: 4.07281534\n","Epoch: 499 | Lr: 0.00100000000000000002 |Train loss: 3.54415768|Test loss: 3.96086152\n","Epoch: 500 | Lr: 0.00100000000000000002 |Train loss: 3.59766849|Test loss: 4.44562300\n","Epoch: 501 | Lr: 0.00100000000000000002 |Train loss: 3.56738585|Test loss: 4.44842021\n","Epoch: 502 | Lr: 0.00100000000000000002 |Train loss: 3.55648895|Test loss: 4.16352018\n","Epoch: 503 | Lr: 0.00100000000000000002 |Train loss: 3.59722517|Test loss: 4.09839161\n","Epoch: 504 | Lr: 0.00100000000000000002 |Train loss: 3.54987987|Test loss: 3.94438346\n","Epoch: 505 | Lr: 0.00100000000000000002 |Train loss: 3.59977597|Test loss: 3.95223880\n","Epoch: 506 | Lr: 0.00100000000000000002 |Train loss: 3.60502704|Test loss: 4.12619495\n","Epoch: 507 | Lr: 0.00100000000000000002 |Train loss: 3.60637516|Test loss: 4.39790757\n","Epoch: 508 | Lr: 0.00100000000000000002 |Train loss: 3.61565979|Test loss: 4.28980851\n","Epoch: 509 | Lr: 0.00100000000000000002 |Train loss: 3.70445341|Test loss: 4.16923555\n","Epoch: 510 | Lr: 0.00100000000000000002 |Train loss: 3.66520935|Test loss: 4.15264789\n","Epoch: 511 | Lr: 0.00100000000000000002 |Train loss: 3.71060805|Test loss: 4.27461958\n","Epoch: 512 | Lr: 0.00100000000000000002 |Train loss: 3.74150203|Test loss: 4.62874142\n","Epoch: 513 | Lr: 0.00100000000000000002 |Train loss: 3.63837886|Test loss: 4.29586124\n","Epoch: 514 | Lr: 0.00100000000000000002 |Train loss: 3.71137005|Test loss: 4.28044399\n","Epoch: 515 | Lr: 0.00100000000000000002 |Train loss: 3.68440938|Test loss: 4.37105044\n","Epoch: 516 | Lr: 0.00100000000000000002 |Train loss: 3.69680649|Test loss: 4.49920082\n","Epoch: 517 | Lr: 0.00100000000000000002 |Train loss: 3.62838264|Test loss: 4.47102491\n","Epoch: 518 | Lr: 0.00100000000000000002 |Train loss: 3.65994799|Test loss: 4.59704955\n","Epoch: 519 | Lr: 0.00100000000000000002 |Train loss: 3.72984338|Test loss: 4.38509973\n","Epoch: 520 | Lr: 0.00100000000000000002 |Train loss: 3.66601270|Test loss: 4.21757015\n","Epoch: 521 | Lr: 0.00100000000000000002 |Train loss: 3.59768542|Test loss: 3.99865365\n","Epoch: 522 | Lr: 0.00100000000000000002 |Train loss: 3.56155489|Test loss: 4.03618201\n","Epoch: 523 | Lr: 0.00100000000000000002 |Train loss: 3.53543508|Test loss: 4.02914611\n","Epoch: 524 | Lr: 0.00100000000000000002 |Train loss: 3.53219577|Test loss: 4.15566397\n","Epoch: 525 | Lr: 0.00100000000000000002 |Train loss: 3.53376677|Test loss: 4.04717541\n","Epoch: 526 | Lr: 0.00100000000000000002 |Train loss: 3.55560331|Test loss: 4.20377755\n","Epoch: 527 | Lr: 0.00100000000000000002 |Train loss: 3.52555635|Test loss: 4.20942537\n","Epoch: 528 | Lr: 0.00100000000000000002 |Train loss: 3.53391169|Test loss: 4.38124267\n","Epoch: 529 | Lr: 0.00100000000000000002 |Train loss: 3.54096287|Test loss: 4.39977129\n","Epoch: 530 | Lr: 0.00100000000000000002 |Train loss: 3.54565358|Test loss: 4.52654028\n","Epoch: 531 | Lr: 0.00100000000000000002 |Train loss: 3.53118513|Test loss: 4.39271212\n","Epoch: 532 | Lr: 0.00100000000000000002 |Train loss: 3.57898327|Test loss: 4.27832532\n","Epoch: 533 | Lr: 0.00100000000000000002 |Train loss: 3.54118633|Test loss: 4.38330777\n","Epoch: 534 | Lr: 0.00100000000000000002 |Train loss: 3.53526288|Test loss: 4.22901114\n","Epoch: 535 | Lr: 0.00100000000000000002 |Train loss: 3.51437732|Test loss: 4.16476035\n","Epoch: 536 | Lr: 0.00100000000000000002 |Train loss: 3.51551702|Test loss: 4.12280409\n","Epoch: 537 | Lr: 0.00100000000000000002 |Train loss: 3.55169972|Test loss: 4.14478922\n","Epoch: 538 | Lr: 0.00100000000000000002 |Train loss: 3.53191034|Test loss: 4.36405277\n","Epoch: 539 | Lr: 0.00100000000000000002 |Train loss: 3.57607265|Test loss: 4.22253831\n","Epoch: 540 | Lr: 0.00100000000000000002 |Train loss: 3.53572752|Test loss: 4.17940601\n","Epoch: 541 | Lr: 0.00100000000000000002 |Train loss: 3.54729952|Test loss: 4.03326162\n","Epoch: 542 | Lr: 0.00100000000000000002 |Train loss: 3.55529948|Test loss: 4.07481980\n","Epoch: 543 | Lr: 0.00100000000000000002 |Train loss: 3.54329258|Test loss: 4.19437202\n","Epoch: 544 | Lr: 0.00100000000000000002 |Train loss: 3.55760409|Test loss: 4.28310021\n","Epoch: 545 | Lr: 0.00100000000000000002 |Train loss: 3.56400907|Test loss: 4.39876127\n","Epoch: 546 | Lr: 0.00100000000000000002 |Train loss: 3.62672194|Test loss: 4.20855745\n","Epoch: 547 | Lr: 0.00100000000000000002 |Train loss: 3.63665082|Test loss: 4.27408624\n","Epoch: 548 | Lr: 0.00100000000000000002 |Train loss: 3.62427992|Test loss: 4.24922148\n","Epoch: 549 | Lr: 0.00100000000000000002 |Train loss: 3.63698407|Test loss: 4.37047275\n","Epoch: 550 | Lr: 0.00100000000000000002 |Train loss: 3.60922662|Test loss: 4.31461819\n","Epoch: 551 | Lr: 0.00100000000000000002 |Train loss: 3.65634151|Test loss: 4.27152308\n","Epoch: 552 | Lr: 0.00100000000000000002 |Train loss: 3.57990181|Test loss: 4.37122567\n","Epoch: 553 | Lr: 0.00100000000000000002 |Train loss: 3.59367814|Test loss: 4.35423859\n","Epoch: 554 | Lr: 0.00100000000000000002 |Train loss: 3.55716562|Test loss: 4.58015760\n","Epoch: 555 | Lr: 0.00100000000000000002 |Train loss: 3.56089530|Test loss: 4.29331907\n","Epoch: 556 | Lr: 0.00100000000000000002 |Train loss: 3.63528826|Test loss: 4.38180025\n","Epoch: 557 | Lr: 0.00100000000000000002 |Train loss: 3.65900183|Test loss: 4.16961559\n","Epoch: 558 | Lr: 0.00100000000000000002 |Train loss: 3.62896134|Test loss: 4.43429581\n","Epoch: 559 | Lr: 0.00100000000000000002 |Train loss: 3.59531552|Test loss: 4.39292518\n","Epoch: 560 | Lr: 0.00100000000000000002 |Train loss: 3.56282059|Test loss: 4.46181917\n","Epoch: 561 | Lr: 0.00100000000000000002 |Train loss: 3.57236181|Test loss: 4.10375158\n","Epoch: 562 | Lr: 0.00100000000000000002 |Train loss: 3.53222390|Test loss: 4.14086445\n","Epoch: 563 | Lr: 0.00100000000000000002 |Train loss: 3.53895197|Test loss: 4.16014854\n","Epoch: 564 | Lr: 0.00100000000000000002 |Train loss: 3.58530635|Test loss: 4.18968876\n","Epoch: 565 | Lr: 0.00100000000000000002 |Train loss: 3.58827066|Test loss: 4.14802376\n","Epoch: 566 | Lr: 0.00100000000000000002 |Train loss: 3.61957014|Test loss: 4.18721581\n","Epoch: 567 | Lr: 0.00100000000000000002 |Train loss: 3.60322871|Test loss: 4.04150987\n","Epoch: 568 | Lr: 0.00100000000000000002 |Train loss: 3.60976324|Test loss: 4.07331133\n","Epoch: 569 | Lr: 0.00100000000000000002 |Train loss: 3.67633762|Test loss: 4.20467790\n","Epoch: 570 | Lr: 0.00100000000000000002 |Train loss: 3.58671166|Test loss: 4.21393021\n","Epoch: 571 | Lr: 0.00100000000000000002 |Train loss: 3.58172637|Test loss: 4.34011070\n","Epoch: 572 | Lr: 0.00100000000000000002 |Train loss: 3.58386223|Test loss: 4.29251544\n","Epoch: 573 | Lr: 0.00100000000000000002 |Train loss: 3.60444895|Test loss: 4.17392961\n","Epoch: 574 | Lr: 0.00100000000000000002 |Train loss: 3.61102535|Test loss: 4.16731779\n","Epoch: 575 | Lr: 0.00100000000000000002 |Train loss: 3.56207409|Test loss: 4.11947012\n","Epoch: 576 | Lr: 0.00100000000000000002 |Train loss: 3.54382998|Test loss: 4.47618771\n","Epoch: 577 | Lr: 0.00100000000000000002 |Train loss: 3.54374270|Test loss: 4.37667902\n","Epoch: 578 | Lr: 0.00100000000000000002 |Train loss: 3.51360899|Test loss: 4.30912360\n","Epoch: 579 | Lr: 0.00100000000000000002 |Train loss: 3.50502688|Test loss: 4.24610726\n","Epoch: 580 | Lr: 0.00100000000000000002 |Train loss: 3.49090556|Test loss: 4.26327411\n","Epoch: 581 | Lr: 0.00100000000000000002 |Train loss: 3.49147083|Test loss: 4.18327721\n","Epoch: 582 | Lr: 0.00100000000000000002 |Train loss: 3.48774497|Test loss: 4.41553529\n","Epoch: 583 | Lr: 0.00100000000000000002 |Train loss: 3.49407254|Test loss: 4.66899562\n","Epoch: 584 | Lr: 0.00100000000000000002 |Train loss: 3.49167234|Test loss: 4.49708565\n","Epoch: 585 | Lr: 0.00100000000000000002 |Train loss: 3.49208917|Test loss: 4.31918534\n","Epoch: 586 | Lr: 0.00100000000000000002 |Train loss: 3.48510601|Test loss: 4.17638572\n","Epoch: 587 | Lr: 0.00100000000000000002 |Train loss: 3.48977206|Test loss: 4.47461677\n","Epoch: 588 | Lr: 0.00100000000000000002 |Train loss: 3.50751265|Test loss: 4.50859245\n","Epoch: 589 | Lr: 0.00100000000000000002 |Train loss: 3.48770334|Test loss: 4.30446974\n","Epoch: 590 | Lr: 0.00100000000000000002 |Train loss: 3.49822911|Test loss: 4.10582582\n","Epoch: 591 | Lr: 0.00100000000000000002 |Train loss: 3.48682356|Test loss: 4.36204100\n","Epoch: 592 | Lr: 0.00100000000000000002 |Train loss: 3.49830083|Test loss: 4.27556515\n","Epoch: 593 | Lr: 0.00100000000000000002 |Train loss: 3.52701996|Test loss: 4.15948923\n","Epoch: 594 | Lr: 0.00100000000000000002 |Train loss: 3.51479248|Test loss: 4.16199581\n","Epoch: 595 | Lr: 0.00100000000000000002 |Train loss: 3.52556862|Test loss: 4.23220770\n","Epoch: 596 | Lr: 0.00100000000000000002 |Train loss: 3.53599073|Test loss: 4.16831907\n","Epoch: 597 | Lr: 0.00100000000000000002 |Train loss: 3.61750762|Test loss: 4.39972083\n","Epoch: 598 | Lr: 0.00100000000000000002 |Train loss: 3.67866238|Test loss: 4.57404995\n","Epoch: 599 | Lr: 0.00100000000000000002 |Train loss: 3.58453236|Test loss: 4.57848469\n","Epoch: 600 | Lr: 0.00100000000000000002 |Train loss: 3.71094020|Test loss: 4.35820198\n","Epoch: 601 | Lr: 0.00100000000000000002 |Train loss: 3.59084978|Test loss: 4.13976145\n","Epoch: 602 | Lr: 0.00100000000000000002 |Train loss: 3.60304032|Test loss: 4.41779598\n","Epoch: 603 | Lr: 0.00100000000000000002 |Train loss: 3.59176358|Test loss: 4.23681116\n","Epoch: 604 | Lr: 0.00100000000000000002 |Train loss: 3.64699491|Test loss: 4.15070065\n","Epoch: 605 | Lr: 0.00100000000000000002 |Train loss: 3.60916317|Test loss: 4.02659933\n","Epoch: 606 | Lr: 0.00100000000000000002 |Train loss: 3.55303657|Test loss: 4.03514838\n","Epoch: 607 | Lr: 0.00100000000000000002 |Train loss: 3.53264815|Test loss: 4.11085184\n","Epoch: 608 | Lr: 0.00100000000000000002 |Train loss: 3.48969615|Test loss: 4.20356560\n","Epoch: 609 | Lr: 0.00100000000000000002 |Train loss: 3.50230569|Test loss: 4.26962694\n","Epoch: 610 | Lr: 0.00100000000000000002 |Train loss: 3.48115563|Test loss: 4.18770234\n","Epoch: 611 | Lr: 0.00100000000000000002 |Train loss: 3.49045094|Test loss: 4.25497627\n","Epoch: 612 | Lr: 0.00100000000000000002 |Train loss: 3.47457687|Test loss: 4.22659516\n","Epoch: 613 | Lr: 0.00100000000000000002 |Train loss: 3.48447712|Test loss: 4.24752434\n","Epoch: 614 | Lr: 0.00100000000000000002 |Train loss: 3.47261008|Test loss: 4.22553054\n","Epoch: 615 | Lr: 0.00100000000000000002 |Train loss: 3.47459787|Test loss: 4.31442078\n","Epoch: 616 | Lr: 0.00100000000000000002 |Train loss: 3.47823211|Test loss: 4.54079056\n","Epoch: 617 | Lr: 0.00100000000000000002 |Train loss: 3.50313042|Test loss: 4.59436075\n","Epoch: 618 | Lr: 0.00100000000000000002 |Train loss: 3.48400080|Test loss: 4.51404023\n","Epoch: 619 | Lr: 0.00100000000000000002 |Train loss: 3.49441844|Test loss: 4.49733369\n","Epoch: 620 | Lr: 0.00100000000000000002 |Train loss: 3.50102240|Test loss: 4.56852468\n","Epoch: 621 | Lr: 0.00100000000000000002 |Train loss: 3.48887789|Test loss: 4.39520899\n","Epoch: 622 | Lr: 0.00100000000000000002 |Train loss: 3.50442549|Test loss: 4.33088263\n","Epoch: 623 | Lr: 0.00100000000000000002 |Train loss: 3.49432266|Test loss: 4.31086810\n","Epoch: 624 | Lr: 0.00100000000000000002 |Train loss: 3.50410344|Test loss: 4.18407496\n","Epoch: 625 | Lr: 0.00100000000000000002 |Train loss: 3.50464739|Test loss: 4.39195291\n","Epoch: 626 | Lr: 0.00100000000000000002 |Train loss: 3.50267782|Test loss: 4.77320814\n","Epoch: 627 | Lr: 0.00100000000000000002 |Train loss: 3.50452733|Test loss: 4.37614330\n","Epoch: 628 | Lr: 0.00100000000000000002 |Train loss: 3.53122038|Test loss: 4.06951451\n","Epoch: 629 | Lr: 0.00100000000000000002 |Train loss: 3.53055882|Test loss: 4.02403076\n","Epoch: 630 | Lr: 0.00100000000000000002 |Train loss: 3.61696066|Test loss: 4.01765347\n","Epoch: 631 | Lr: 0.00100000000000000002 |Train loss: 3.69738013|Test loss: 4.12388563\n","Epoch: 632 | Lr: 0.00100000000000000002 |Train loss: 3.83949260|Test loss: 4.05419779\n","Epoch: 633 | Lr: 0.00100000000000000002 |Train loss: 3.67126036|Test loss: 4.20259778\n","Epoch: 634 | Lr: 0.00100000000000000002 |Train loss: 3.58264673|Test loss: 4.01811751\n","Epoch: 635 | Lr: 0.00100000000000000002 |Train loss: 3.54413750|Test loss: 4.06922539\n","Epoch: 636 | Lr: 0.00100000000000000002 |Train loss: 3.54234823|Test loss: 4.26300780\n","Epoch: 637 | Lr: 0.00100000000000000002 |Train loss: 3.53185103|Test loss: 4.17836857\n","Epoch: 638 | Lr: 0.00100000000000000002 |Train loss: 3.58018486|Test loss: 4.03899487\n","Epoch: 639 | Lr: 0.00100000000000000002 |Train loss: 3.52810727|Test loss: 4.05328751\n","Epoch: 640 | Lr: 0.00100000000000000002 |Train loss: 3.49539550|Test loss: 4.11758542\n","Epoch: 641 | Lr: 0.00100000000000000002 |Train loss: 3.49664448|Test loss: 4.30765883\n","Epoch: 642 | Lr: 0.00100000000000000002 |Train loss: 3.46416082|Test loss: 4.29691188\n","Epoch: 643 | Lr: 0.00100000000000000002 |Train loss: 3.47205893|Test loss: 4.35869082\n","Epoch: 644 | Lr: 0.00100000000000000002 |Train loss: 3.48277734|Test loss: 4.17741903\n","Epoch: 645 | Lr: 0.00100000000000000002 |Train loss: 3.45546599|Test loss: 4.24192556\n","Epoch: 646 | Lr: 0.00100000000000000002 |Train loss: 3.46588929|Test loss: 4.36973802\n","Epoch: 647 | Lr: 0.00100000000000000002 |Train loss: 3.46274499|Test loss: 4.35232202\n","Epoch: 648 | Lr: 0.00100000000000000002 |Train loss: 3.45345153|Test loss: 4.27665035\n","Epoch: 649 | Lr: 0.00100000000000000002 |Train loss: 3.45852341|Test loss: 4.48882437\n","Epoch: 650 | Lr: 0.00100000000000000002 |Train loss: 3.46859487|Test loss: 4.45941893\n","Epoch: 651 | Lr: 0.00100000000000000002 |Train loss: 3.47666391|Test loss: 4.28231327\n","Epoch: 652 | Lr: 0.00100000000000000002 |Train loss: 3.47606566|Test loss: 4.11018427\n","Epoch: 653 | Lr: 0.00100000000000000002 |Train loss: 3.49663788|Test loss: 4.02722160\n","Epoch: 654 | Lr: 0.00100000000000000002 |Train loss: 3.48536682|Test loss: 4.13198622\n","Epoch: 655 | Lr: 0.00100000000000000002 |Train loss: 3.49895936|Test loss: 4.25857155\n","Epoch: 656 | Lr: 0.00100000000000000002 |Train loss: 3.49013877|Test loss: 4.23252416\n","Epoch: 657 | Lr: 0.00100000000000000002 |Train loss: 3.45653244|Test loss: 4.16038863\n","Epoch: 658 | Lr: 0.00100000000000000002 |Train loss: 3.46751374|Test loss: 4.28241944\n","Epoch: 659 | Lr: 0.00100000000000000002 |Train loss: 3.45900778|Test loss: 4.43259716\n","Epoch: 660 | Lr: 0.00100000000000000002 |Train loss: 3.45549128|Test loss: 4.20948553\n","Epoch: 661 | Lr: 0.00100000000000000002 |Train loss: 3.45597122|Test loss: 4.24646680\n","Epoch: 662 | Lr: 0.00100000000000000002 |Train loss: 3.47020108|Test loss: 4.29403957\n","Epoch: 663 | Lr: 0.00100000000000000002 |Train loss: 3.47724799|Test loss: 4.36741440\n","Epoch: 664 | Lr: 0.00100000000000000002 |Train loss: 3.47810592|Test loss: 4.32208403\n","Epoch: 665 | Lr: 0.00100000000000000002 |Train loss: 3.46990246|Test loss: 4.25421063\n","Epoch: 666 | Lr: 0.00100000000000000002 |Train loss: 3.48002158|Test loss: 4.31727282\n","Epoch: 667 | Lr: 0.00100000000000000002 |Train loss: 3.51337626|Test loss: 4.56738647\n","Epoch: 668 | Lr: 0.00100000000000000002 |Train loss: 3.51683754|Test loss: 4.50421778\n","Epoch: 669 | Lr: 0.00100000000000000002 |Train loss: 3.51296707|Test loss: 4.83509000\n","Epoch: 670 | Lr: 0.00100000000000000002 |Train loss: 3.54773875|Test loss: 4.69361448\n","Epoch: 671 | Lr: 0.00100000000000000002 |Train loss: 3.59974416|Test loss: 4.34408967\n","Epoch: 672 | Lr: 0.00100000000000000002 |Train loss: 3.66397981|Test loss: 4.18052721\n","Epoch: 673 | Lr: 0.00100000000000000002 |Train loss: 3.68291148|Test loss: 4.16570433\n","Epoch: 674 | Lr: 0.00100000000000000002 |Train loss: 3.66334482|Test loss: 4.08272211\n","Epoch: 675 | Lr: 0.00100000000000000002 |Train loss: 3.61116534|Test loss: 4.08909893\n","Epoch: 676 | Lr: 0.00100000000000000002 |Train loss: 3.66869456|Test loss: 4.24000708\n","Epoch: 677 | Lr: 0.00100000000000000002 |Train loss: 3.58759101|Test loss: 4.15608247\n","Epoch: 678 | Lr: 0.00100000000000000002 |Train loss: 3.55405202|Test loss: 4.16248369\n","Epoch: 679 | Lr: 0.00100000000000000002 |Train loss: 3.52505948|Test loss: 4.21489573\n","Epoch: 680 | Lr: 0.00100000000000000002 |Train loss: 3.49857159|Test loss: 3.95012363\n","Epoch: 681 | Lr: 0.00100000000000000002 |Train loss: 3.49606878|Test loss: 3.90743597\n","Epoch: 682 | Lr: 0.00100000000000000002 |Train loss: 3.58034595|Test loss: 4.16468255\n","Epoch: 683 | Lr: 0.00100000000000000002 |Train loss: 3.57506444|Test loss: 4.30900876\n","Epoch: 684 | Lr: 0.00100000000000000002 |Train loss: 3.51719407|Test loss: 4.20746954\n","Epoch: 685 | Lr: 0.00100000000000000002 |Train loss: 3.52737677|Test loss: 4.18358779\n","Epoch: 686 | Lr: 0.00100000000000000002 |Train loss: 3.49404136|Test loss: 4.30500158\n","Epoch: 687 | Lr: 0.00100000000000000002 |Train loss: 3.50699182|Test loss: 4.47506444\n","Epoch: 688 | Lr: 0.00100000000000000002 |Train loss: 3.48148880|Test loss: 4.47216479\n","Epoch: 689 | Lr: 0.00100000000000000002 |Train loss: 3.48899651|Test loss: 4.31561176\n","Epoch: 690 | Lr: 0.00100000000000000002 |Train loss: 3.52615126|Test loss: 4.32338881\n","Epoch: 691 | Lr: 0.00100000000000000002 |Train loss: 3.55206619|Test loss: 4.12669182\n","Epoch: 692 | Lr: 0.00100000000000000002 |Train loss: 3.53605465|Test loss: 4.28495447\n","Epoch: 693 | Lr: 0.00100000000000000002 |Train loss: 3.51147221|Test loss: 4.27956557\n","Epoch: 694 | Lr: 0.00100000000000000002 |Train loss: 3.52008196|Test loss: 4.48072672\n","Epoch: 695 | Lr: 0.00100000000000000002 |Train loss: 3.53209343|Test loss: 4.19323007\n","Epoch: 696 | Lr: 0.00100000000000000002 |Train loss: 3.50915309|Test loss: 4.23249269\n","Epoch: 697 | Lr: 0.00100000000000000002 |Train loss: 3.50266637|Test loss: 4.07014823\n","Epoch: 698 | Lr: 0.00100000000000000002 |Train loss: 3.49913259|Test loss: 4.37767482\n","Epoch: 699 | Lr: 0.00100000000000000002 |Train loss: 3.47491509|Test loss: 4.39421781\n","Epoch: 700 | Lr: 0.00100000000000000002 |Train loss: 3.45461045|Test loss: 4.13627442\n","Epoch: 701 | Lr: 0.00100000000000000002 |Train loss: 3.47593057|Test loss: 4.16473031\n","Epoch: 702 | Lr: 0.00100000000000000002 |Train loss: 3.44107586|Test loss: 4.33821615\n","Epoch: 703 | Lr: 0.00100000000000000002 |Train loss: 3.45989583|Test loss: 4.38431970\n","Epoch: 704 | Lr: 0.00100000000000000002 |Train loss: 3.47943630|Test loss: 4.28081155\n","Epoch: 705 | Lr: 0.00100000000000000002 |Train loss: 3.45735568|Test loss: 4.38118839\n","Epoch: 706 | Lr: 0.00100000000000000002 |Train loss: 3.47520979|Test loss: 4.39328798\n","Epoch: 707 | Lr: 0.00100000000000000002 |Train loss: 3.47645426|Test loss: 4.30372461\n","Epoch: 708 | Lr: 0.00100000000000000002 |Train loss: 3.52483457|Test loss: 4.15388417\n","Epoch: 709 | Lr: 0.00100000000000000002 |Train loss: 3.50885495|Test loss: 4.06189124\n","Epoch: 710 | Lr: 0.00100000000000000002 |Train loss: 3.48345170|Test loss: 4.15483809\n","Epoch: 711 | Lr: 0.00100000000000000002 |Train loss: 3.52730306|Test loss: 4.20552214\n","Epoch: 712 | Lr: 0.00100000000000000002 |Train loss: 3.55551785|Test loss: 4.38737265\n","Epoch: 713 | Lr: 0.00100000000000000002 |Train loss: 3.56275316|Test loss: 4.53450012\n","Epoch: 714 | Lr: 0.00100000000000000002 |Train loss: 3.50153355|Test loss: 4.45183229\n","Epoch: 715 | Lr: 0.00100000000000000002 |Train loss: 3.53564713|Test loss: 4.10797580\n","Epoch: 716 | Lr: 0.00100000000000000002 |Train loss: 3.49330435|Test loss: 4.09086839\n","Epoch: 717 | Lr: 0.00100000000000000002 |Train loss: 3.47864562|Test loss: 4.27273345\n","Epoch: 718 | Lr: 0.00100000000000000002 |Train loss: 3.50224628|Test loss: 4.31841095\n","Epoch: 719 | Lr: 0.00100000000000000002 |Train loss: 3.45939682|Test loss: 4.11608934\n","Epoch: 720 | Lr: 0.00100000000000000002 |Train loss: 3.47813745|Test loss: 4.18599550\n","Epoch: 721 | Lr: 0.00100000000000000002 |Train loss: 3.47500080|Test loss: 4.23535887\n","Epoch: 722 | Lr: 0.00100000000000000002 |Train loss: 3.47741810|Test loss: 4.31446091\n","Epoch: 723 | Lr: 0.00100000000000000002 |Train loss: 3.50423874|Test loss: 4.30504584\n","Epoch: 724 | Lr: 0.00100000000000000002 |Train loss: 3.52894266|Test loss: 4.28679570\n","Epoch: 725 | Lr: 0.00100000000000000002 |Train loss: 3.54703907|Test loss: 4.45747320\n","Epoch: 726 | Lr: 0.00100000000000000002 |Train loss: 3.54704501|Test loss: 4.26448345\n","Epoch: 727 | Lr: 0.00100000000000000002 |Train loss: 3.56225761|Test loss: 4.35744921\n","Epoch: 728 | Lr: 0.00100000000000000002 |Train loss: 3.52530523|Test loss: 4.23492058\n","Epoch: 729 | Lr: 0.00100000000000000002 |Train loss: 3.51925240|Test loss: 4.22698291\n","Epoch: 730 | Lr: 0.00100000000000000002 |Train loss: 3.50347984|Test loss: 4.18885374\n","Epoch: 731 | Lr: 0.00100000000000000002 |Train loss: 3.49367923|Test loss: 4.15888198\n","Epoch: 732 | Lr: 0.00100000000000000002 |Train loss: 3.49661783|Test loss: 4.05067221\n","Epoch: 733 | Lr: 0.00100000000000000002 |Train loss: 3.48263349|Test loss: 3.93692183\n","Epoch: 734 | Lr: 0.00100000000000000002 |Train loss: 3.51964384|Test loss: 4.12938484\n","Epoch: 735 | Lr: 0.00100000000000000002 |Train loss: 3.64396675|Test loss: 4.18736053\n","Epoch: 736 | Lr: 0.00100000000000000002 |Train loss: 3.61806752|Test loss: 4.25049822\n","Epoch: 737 | Lr: 0.00100000000000000002 |Train loss: 3.56863234|Test loss: 4.36468458\n","Epoch: 738 | Lr: 0.00100000000000000002 |Train loss: 3.56585318|Test loss: 4.09479594\n","Epoch: 739 | Lr: 0.00100000000000000002 |Train loss: 3.50914737|Test loss: 4.32760406\n","Epoch: 740 | Lr: 0.00100000000000000002 |Train loss: 3.48028817|Test loss: 4.21396772\n","Epoch: 741 | Lr: 0.00100000000000000002 |Train loss: 3.48058341|Test loss: 4.37677479\n","Epoch: 742 | Lr: 0.00100000000000000002 |Train loss: 3.46448614|Test loss: 4.40008211\n","Epoch: 743 | Lr: 0.00100000000000000002 |Train loss: 3.48419652|Test loss: 4.25251245\n","Epoch: 744 | Lr: 0.00100000000000000002 |Train loss: 3.50254991|Test loss: 4.05548048\n","Epoch: 745 | Lr: 0.00100000000000000002 |Train loss: 3.47877379|Test loss: 4.34100509\n","Epoch: 746 | Lr: 0.00100000000000000002 |Train loss: 3.47740926|Test loss: 4.46675825\n","Epoch: 747 | Lr: 0.00100000000000000002 |Train loss: 3.46802966|Test loss: 4.31492162\n","Epoch: 748 | Lr: 0.00100000000000000002 |Train loss: 3.49097453|Test loss: 4.04025277\n","Epoch: 749 | Lr: 0.00100000000000000002 |Train loss: 3.47130859|Test loss: 4.19658256\n","Epoch: 750 | Lr: 0.00100000000000000002 |Train loss: 3.43283502|Test loss: 4.17923363\n","Epoch: 751 | Lr: 0.00100000000000000002 |Train loss: 3.44822472|Test loss: 4.18345650\n","Epoch: 752 | Lr: 0.00100000000000000002 |Train loss: 3.48116203|Test loss: 4.22797465\n","Epoch: 753 | Lr: 0.00100000000000000002 |Train loss: 3.49645074|Test loss: 4.26889944\n","Epoch: 754 | Lr: 0.00100000000000000002 |Train loss: 3.48871370|Test loss: 4.36509569\n","Epoch: 755 | Lr: 0.00100000000000000002 |Train loss: 3.47635696|Test loss: 4.19379067\n","Epoch: 756 | Lr: 0.00100000000000000002 |Train loss: 3.49937701|Test loss: 4.00401886\n","Epoch: 757 | Lr: 0.00100000000000000002 |Train loss: 3.51302371|Test loss: 3.98813121\n","Epoch: 758 | Lr: 0.00100000000000000002 |Train loss: 3.53015508|Test loss: 4.08905045\n","Epoch: 759 | Lr: 0.00100000000000000002 |Train loss: 3.51428338|Test loss: 4.28849316\n","Epoch: 760 | Lr: 0.00100000000000000002 |Train loss: 3.54423225|Test loss: 4.16838892\n","Epoch: 761 | Lr: 0.00100000000000000002 |Train loss: 3.47826040|Test loss: 4.27777020\n","Epoch: 762 | Lr: 0.00100000000000000002 |Train loss: 3.49239836|Test loss: 4.47791052\n","Epoch: 763 | Lr: 0.00100000000000000002 |Train loss: 3.49117931|Test loss: 4.33948000\n","Epoch: 764 | Lr: 0.00100000000000000002 |Train loss: 3.49969508|Test loss: 4.51356475\n","Epoch: 765 | Lr: 0.00100000000000000002 |Train loss: 3.55209657|Test loss: 4.33104030\n","Epoch: 766 | Lr: 0.00100000000000000002 |Train loss: 3.56187266|Test loss: 4.39805420\n","Epoch: 767 | Lr: 0.00100000000000000002 |Train loss: 3.55367968|Test loss: 4.32023708\n","Epoch: 768 | Lr: 0.00100000000000000002 |Train loss: 3.54828147|Test loss: 4.34165931\n","Epoch: 769 | Lr: 0.00100000000000000002 |Train loss: 3.50284910|Test loss: 4.18431226\n","Epoch: 770 | Lr: 0.00100000000000000002 |Train loss: 3.47364650|Test loss: 4.20631584\n","Epoch: 771 | Lr: 0.00100000000000000002 |Train loss: 3.44099722|Test loss: 4.19518812\n","Epoch: 772 | Lr: 0.00100000000000000002 |Train loss: 3.43218710|Test loss: 4.31078211\n","Epoch: 773 | Lr: 0.00100000000000000002 |Train loss: 3.45010297|Test loss: 4.43630632\n","Epoch: 774 | Lr: 0.00100000000000000002 |Train loss: 3.44779162|Test loss: 4.33655953\n","Epoch: 775 | Lr: 0.00100000000000000002 |Train loss: 3.47042042|Test loss: 4.52458231\n","Epoch: 776 | Lr: 0.00100000000000000002 |Train loss: 3.46616534|Test loss: 4.49769028\n","Epoch: 777 | Lr: 0.00100000000000000002 |Train loss: 3.47875792|Test loss: 4.42052166\n","Epoch: 778 | Lr: 0.00100000000000000002 |Train loss: 3.51844452|Test loss: 4.16395092\n","Epoch: 779 | Lr: 0.00100000000000000002 |Train loss: 3.49024278|Test loss: 4.21075900\n","Epoch: 780 | Lr: 0.00100000000000000002 |Train loss: 3.50254305|Test loss: 4.31985974\n","Epoch: 781 | Lr: 0.00100000000000000002 |Train loss: 3.50839794|Test loss: 4.37753582\n","Epoch: 782 | Lr: 0.00100000000000000002 |Train loss: 3.52175156|Test loss: 4.45907784\n","Epoch: 783 | Lr: 0.00100000000000000002 |Train loss: 3.49848278|Test loss: 4.43918069\n","Epoch: 784 | Lr: 0.00100000000000000002 |Train loss: 3.54748100|Test loss: 4.27653456\n","Epoch: 785 | Lr: 0.00100000000000000002 |Train loss: 3.53281065|Test loss: 4.20276992\n","Epoch: 786 | Lr: 0.00100000000000000002 |Train loss: 3.51723146|Test loss: 4.35305158\n","Epoch: 787 | Lr: 0.00100000000000000002 |Train loss: 3.53142520|Test loss: 4.39677620\n","Epoch: 788 | Lr: 0.00100000000000000002 |Train loss: 3.51463004|Test loss: 4.18402878\n","Epoch: 789 | Lr: 0.00100000000000000002 |Train loss: 3.56992328|Test loss: 4.20696505\n","Epoch: 790 | Lr: 0.00100000000000000002 |Train loss: 3.50830859|Test loss: 4.24391143\n","Epoch: 791 | Lr: 0.00100000000000000002 |Train loss: 3.49604108|Test loss: 4.23161515\n","Epoch: 792 | Lr: 0.00100000000000000002 |Train loss: 3.46495322|Test loss: 4.13653938\n","Epoch: 793 | Lr: 0.00100000000000000002 |Train loss: 3.44973477|Test loss: 4.17745940\n","Epoch: 794 | Lr: 0.00100000000000000002 |Train loss: 3.46023224|Test loss: 4.33282216\n","Epoch: 795 | Lr: 0.00100000000000000002 |Train loss: 3.47520338|Test loss: 4.35840805\n","Epoch: 796 | Lr: 0.00100000000000000002 |Train loss: 3.44877843|Test loss: 4.33995517\n","Epoch: 797 | Lr: 0.00100000000000000002 |Train loss: 3.45680920|Test loss: 4.49447529\n","Epoch: 798 | Lr: 0.00100000000000000002 |Train loss: 3.44933353|Test loss: 4.32121968\n","Epoch: 799 | Lr: 0.00100000000000000002 |Train loss: 3.47706471|Test loss: 4.26243385\n","Epoch: 800 | Lr: 0.00100000000000000002 |Train loss: 3.48932509|Test loss: 4.53341675\n","Epoch: 801 | Lr: 0.00100000000000000002 |Train loss: 3.53519934|Test loss: 4.60843070\n","Epoch: 802 | Lr: 0.00100000000000000002 |Train loss: 3.54010616|Test loss: 4.41374755\n","Epoch: 803 | Lr: 0.00100000000000000002 |Train loss: 3.52702131|Test loss: 4.54046607\n","Epoch: 804 | Lr: 0.00100000000000000002 |Train loss: 3.55020603|Test loss: 4.34899592\n","Epoch: 805 | Lr: 0.00100000000000000002 |Train loss: 3.51734587|Test loss: 4.47575911\n","Epoch: 806 | Lr: 0.00100000000000000002 |Train loss: 3.48384935|Test loss: 4.43114630\n","Epoch: 807 | Lr: 0.00100000000000000002 |Train loss: 3.45712248|Test loss: 4.51032710\n","Epoch: 808 | Lr: 0.00100000000000000002 |Train loss: 3.45507294|Test loss: 4.41916116\n","Epoch: 809 | Lr: 0.00100000000000000002 |Train loss: 3.45878472|Test loss: 4.28896968\n","Epoch: 810 | Lr: 0.00100000000000000002 |Train loss: 3.47440304|Test loss: 4.07804902\n","Epoch: 811 | Lr: 0.00100000000000000002 |Train loss: 3.44795402|Test loss: 4.20488898\n","Epoch: 812 | Lr: 0.00100000000000000002 |Train loss: 3.47221762|Test loss: 4.50812626\n","Epoch: 813 | Lr: 0.00100000000000000002 |Train loss: 3.49341931|Test loss: 4.60843182\n","Epoch: 814 | Lr: 0.00100000000000000002 |Train loss: 3.44752206|Test loss: 4.30392925\n","Epoch: 815 | Lr: 0.00100000000000000002 |Train loss: 3.44412080|Test loss: 4.31165560\n","Epoch: 816 | Lr: 0.00100000000000000002 |Train loss: 3.44078483|Test loss: 4.26788759\n","Epoch: 817 | Lr: 0.00100000000000000002 |Train loss: 3.45314451|Test loss: 4.52382739\n","Epoch: 818 | Lr: 0.00100000000000000002 |Train loss: 3.44632107|Test loss: 4.32837137\n","Epoch: 819 | Lr: 0.00100000000000000002 |Train loss: 3.47231970|Test loss: 4.46042720\n","Epoch: 820 | Lr: 0.00100000000000000002 |Train loss: 3.50358629|Test loss: 4.87105894\n","Epoch: 821 | Lr: 0.00100000000000000002 |Train loss: 3.49737642|Test loss: 4.85067606\n","Epoch: 822 | Lr: 0.00100000000000000002 |Train loss: 3.53099136|Test loss: 4.86026923\n","Epoch: 823 | Lr: 0.00100000000000000002 |Train loss: 3.55750297|Test loss: 4.58454013\n","Epoch: 824 | Lr: 0.00100000000000000002 |Train loss: 3.59673007|Test loss: 4.36064474\n","Epoch: 825 | Lr: 0.00100000000000000002 |Train loss: 3.53285005|Test loss: 4.45604451\n","Epoch: 826 | Lr: 0.00100000000000000002 |Train loss: 3.50082626|Test loss: 4.70878061\n","Epoch: 827 | Lr: 0.00100000000000000002 |Train loss: 3.48904977|Test loss: 4.46197049\n","Epoch: 828 | Lr: 0.00100000000000000002 |Train loss: 3.50295943|Test loss: 4.21097000\n","Epoch: 829 | Lr: 0.00100000000000000002 |Train loss: 3.48828101|Test loss: 4.15909004\n","Epoch: 830 | Lr: 0.00100000000000000002 |Train loss: 3.46677725|Test loss: 4.40549191\n","Epoch: 831 | Lr: 0.00100000000000000002 |Train loss: 3.50334187|Test loss: 4.37467360\n","Epoch: 832 | Lr: 0.00100000000000000002 |Train loss: 3.44940416|Test loss: 4.32131036\n","Epoch: 833 | Lr: 0.00100000000000000002 |Train loss: 3.46436338|Test loss: 4.25617679\n","Epoch: 834 | Lr: 0.00100000000000000002 |Train loss: 3.48659803|Test loss: 4.27030754\n","Epoch: 835 | Lr: 0.00100000000000000002 |Train loss: 3.46854313|Test loss: 4.40544041\n","Epoch: 836 | Lr: 0.00100000000000000002 |Train loss: 3.49600371|Test loss: 4.53935607\n","Epoch: 837 | Lr: 0.00100000000000000002 |Train loss: 3.49882323|Test loss: 4.44813077\n","Epoch: 838 | Lr: 0.00100000000000000002 |Train loss: 3.51733855|Test loss: 4.34104220\n","Epoch: 839 | Lr: 0.00100000000000000002 |Train loss: 3.52446729|Test loss: 4.39730247\n","Epoch: 840 | Lr: 0.00100000000000000002 |Train loss: 3.48695693|Test loss: 4.36401097\n","Epoch: 841 | Lr: 0.00100000000000000002 |Train loss: 3.46154859|Test loss: 4.26485387\n","Epoch: 842 | Lr: 0.00100000000000000002 |Train loss: 3.44290125|Test loss: 4.23832289\n","Epoch: 843 | Lr: 0.00100000000000000002 |Train loss: 3.45062544|Test loss: 4.38091707\n","Epoch: 844 | Lr: 0.00100000000000000002 |Train loss: 3.44729672|Test loss: 4.31037490\n","Epoch: 845 | Lr: 0.00100000000000000002 |Train loss: 3.44663252|Test loss: 4.29407907\n","Epoch: 846 | Lr: 0.00100000000000000002 |Train loss: 3.44034366|Test loss: 4.26777403\n","Epoch: 847 | Lr: 0.00100000000000000002 |Train loss: 3.46368476|Test loss: 4.30642581\n","Epoch: 848 | Lr: 0.00100000000000000002 |Train loss: 3.46457760|Test loss: 4.60316936\n","Epoch: 849 | Lr: 0.00100000000000000002 |Train loss: 3.48847254|Test loss: 4.48549334\n","Epoch: 850 | Lr: 0.00100000000000000002 |Train loss: 3.45667376|Test loss: 4.54532146\n","Epoch: 851 | Lr: 0.00100000000000000002 |Train loss: 3.48667868|Test loss: 4.37880039\n","Epoch: 852 | Lr: 0.00100000000000000002 |Train loss: 3.50489710|Test loss: 4.40153472\n","Epoch: 853 | Lr: 0.00100000000000000002 |Train loss: 3.53410763|Test loss: 4.60986121\n","Epoch: 854 | Lr: 0.00100000000000000002 |Train loss: 3.56297952|Test loss: 4.52610413\n","Epoch: 855 | Lr: 0.00100000000000000002 |Train loss: 3.57902014|Test loss: 4.44977919\n","Epoch: 856 | Lr: 0.00100000000000000002 |Train loss: 3.59310095|Test loss: 4.14556416\n","Epoch: 857 | Lr: 0.00100000000000000002 |Train loss: 3.59060669|Test loss: 4.32112114\n","Epoch: 858 | Lr: 0.00100000000000000002 |Train loss: 3.49419755|Test loss: 4.41973011\n","Epoch: 859 | Lr: 0.00100000000000000002 |Train loss: 3.50228810|Test loss: 4.34583831\n","Epoch: 860 | Lr: 0.00100000000000000002 |Train loss: 3.49086036|Test loss: 4.09741704\n","Epoch: 861 | Lr: 0.00100000000000000002 |Train loss: 3.46481824|Test loss: 4.28985182\n","Epoch: 862 | Lr: 0.00100000000000000002 |Train loss: 3.44870855|Test loss: 4.32063683\n","Epoch: 863 | Lr: 0.00100000000000000002 |Train loss: 3.43823957|Test loss: 4.36857907\n","Epoch: 864 | Lr: 0.00100000000000000002 |Train loss: 3.42846582|Test loss: 4.23513977\n","Epoch: 865 | Lr: 0.00100000000000000002 |Train loss: 3.43156934|Test loss: 4.28650602\n","Epoch: 866 | Lr: 0.00100000000000000002 |Train loss: 3.43331315|Test loss: 4.25047183\n","Epoch: 867 | Lr: 0.00100000000000000002 |Train loss: 3.44447166|Test loss: 4.32035359\n","Epoch: 868 | Lr: 0.00100000000000000002 |Train loss: 3.43885974|Test loss: 4.58802843\n","Epoch: 869 | Lr: 0.00100000000000000002 |Train loss: 3.44235263|Test loss: 4.44437257\n","Epoch: 870 | Lr: 0.00100000000000000002 |Train loss: 3.42530817|Test loss: 4.37427171\n","Epoch: 871 | Lr: 0.00100000000000000002 |Train loss: 3.44096261|Test loss: 4.42444905\n","Epoch: 872 | Lr: 0.00100000000000000002 |Train loss: 3.44036563|Test loss: 4.41649826\n","Epoch: 873 | Lr: 0.00100000000000000002 |Train loss: 3.46615454|Test loss: 4.38016494\n","Epoch: 874 | Lr: 0.00100000000000000002 |Train loss: 3.47063522|Test loss: 4.46917582\n","Epoch: 875 | Lr: 0.00100000000000000002 |Train loss: 3.48866036|Test loss: 4.50007145\n","Epoch: 876 | Lr: 0.00100000000000000002 |Train loss: 3.49463099|Test loss: 4.54621887\n","Epoch: 877 | Lr: 0.00100000000000000002 |Train loss: 3.51350421|Test loss: 4.54369275\n","Epoch: 878 | Lr: 0.00100000000000000002 |Train loss: 3.49907786|Test loss: 4.36458532\n","Epoch: 879 | Lr: 0.00100000000000000002 |Train loss: 3.51873628|Test loss: 4.30101824\n","Epoch: 880 | Lr: 0.00100000000000000002 |Train loss: 3.48689272|Test loss: 4.07654119\n","Epoch: 881 | Lr: 0.00100000000000000002 |Train loss: 3.53705126|Test loss: 4.09049543\n","Epoch: 882 | Lr: 0.00100000000000000002 |Train loss: 3.59379683|Test loss: 4.39036345\n","Epoch: 883 | Lr: 0.00100000000000000002 |Train loss: 3.59797130|Test loss: 4.39239534\n","Epoch: 884 | Lr: 0.00100000000000000002 |Train loss: 3.49572114|Test loss: 4.37976265\n","Epoch: 885 | Lr: 0.00100000000000000002 |Train loss: 3.46367691|Test loss: 4.26841704\n","Epoch: 886 | Lr: 0.00100000000000000002 |Train loss: 3.45558117|Test loss: 4.39412069\n","Epoch: 887 | Lr: 0.00100000000000000002 |Train loss: 3.45252095|Test loss: 4.55424881\n","Epoch: 888 | Lr: 0.00100000000000000002 |Train loss: 3.44337050|Test loss: 4.58978105\n","Epoch: 889 | Lr: 0.00100000000000000002 |Train loss: 3.45135252|Test loss: 4.57594776\n","Epoch: 890 | Lr: 0.00100000000000000002 |Train loss: 3.53086348|Test loss: 4.13014078\n","Epoch: 891 | Lr: 0.00100000000000000002 |Train loss: 3.48302154|Test loss: 4.18673301\n","Epoch: 892 | Lr: 0.00100000000000000002 |Train loss: 3.53910168|Test loss: 4.33607507\n","Epoch: 893 | Lr: 0.00100000000000000002 |Train loss: 3.53721835|Test loss: 4.22374320\n","Epoch: 894 | Lr: 0.00100000000000000002 |Train loss: 3.44912861|Test loss: 4.25660833\n","Epoch: 895 | Lr: 0.00100000000000000002 |Train loss: 3.46597832|Test loss: 4.12927175\n","Epoch: 896 | Lr: 0.00100000000000000002 |Train loss: 3.45013156|Test loss: 4.00814668\n","Epoch: 897 | Lr: 0.00100000000000000002 |Train loss: 3.43734854|Test loss: 4.12747383\n","Epoch: 898 | Lr: 0.00100000000000000002 |Train loss: 3.45987473|Test loss: 4.15648580\n","Epoch: 899 | Lr: 0.00100000000000000002 |Train loss: 3.44916123|Test loss: 4.24566730\n","Epoch: 900 | Lr: 0.00100000000000000002 |Train loss: 3.42806500|Test loss: 4.13494746\n","Epoch: 901 | Lr: 0.00100000000000000002 |Train loss: 3.44552354|Test loss: 4.11162217\n","Epoch: 902 | Lr: 0.00100000000000000002 |Train loss: 3.44358504|Test loss: 4.24622281\n","Epoch: 903 | Lr: 0.00100000000000000002 |Train loss: 3.46210217|Test loss: 4.32205780\n","Epoch: 904 | Lr: 0.00100000000000000002 |Train loss: 3.46377426|Test loss: 4.31822681\n","Epoch: 905 | Lr: 0.00100000000000000002 |Train loss: 3.46814462|Test loss: 4.13512548\n","Epoch: 906 | Lr: 0.00100000000000000002 |Train loss: 3.46808273|Test loss: 4.28989784\n","Epoch: 907 | Lr: 0.00100000000000000002 |Train loss: 3.46236485|Test loss: 4.40351446\n","Epoch: 908 | Lr: 0.00100000000000000002 |Train loss: 3.53334496|Test loss: 4.48504019\n","Epoch: 909 | Lr: 0.00100000000000000002 |Train loss: 3.53503271|Test loss: 4.40043887\n","Epoch: 910 | Lr: 0.00100000000000000002 |Train loss: 3.57709068|Test loss: 4.46525931\n","Epoch: 911 | Lr: 0.00100000000000000002 |Train loss: 3.55997223|Test loss: 4.28098901\n","Epoch: 912 | Lr: 0.00100000000000000002 |Train loss: 3.54151527|Test loss: 4.51356904\n","Epoch: 913 | Lr: 0.00100000000000000002 |Train loss: 3.49584885|Test loss: 4.39025871\n","Epoch: 914 | Lr: 0.00100000000000000002 |Train loss: 3.46239456|Test loss: 4.33330933\n","Epoch: 915 | Lr: 0.00100000000000000002 |Train loss: 3.49738578|Test loss: 4.14435156\n","Epoch: 916 | Lr: 0.00100000000000000002 |Train loss: 3.50602891|Test loss: 4.02217118\n","Epoch: 917 | Lr: 0.00100000000000000002 |Train loss: 3.48082260|Test loss: 4.31531119\n","Epoch: 918 | Lr: 0.00100000000000000002 |Train loss: 3.51529966|Test loss: 4.23778621\n","Epoch: 919 | Lr: 0.00100000000000000002 |Train loss: 3.45397166|Test loss: 4.21238097\n","Epoch: 920 | Lr: 0.00100000000000000002 |Train loss: 3.46014686|Test loss: 4.30168859\n","Epoch: 921 | Lr: 0.00100000000000000002 |Train loss: 3.44790612|Test loss: 4.27603483\n","Epoch: 922 | Lr: 0.00100000000000000002 |Train loss: 3.46395322|Test loss: 4.36879110\n","Epoch: 923 | Lr: 0.00100000000000000002 |Train loss: 3.46666876|Test loss: 4.45086432\n","Epoch: 924 | Lr: 0.00100000000000000002 |Train loss: 3.43728902|Test loss: 4.35937238\n","Epoch: 925 | Lr: 0.00100000000000000002 |Train loss: 3.44781526|Test loss: 4.38543479\n","Epoch: 926 | Lr: 0.00100000000000000002 |Train loss: 3.47535886|Test loss: 4.47340139\n","Epoch: 927 | Lr: 0.00100000000000000002 |Train loss: 3.46943261|Test loss: 4.63523753\n","Epoch: 928 | Lr: 0.00100000000000000002 |Train loss: 3.45802395|Test loss: 4.52185329\n","Epoch: 929 | Lr: 0.00100000000000000002 |Train loss: 3.47680225|Test loss: 4.32266625\n","Epoch: 930 | Lr: 0.00100000000000000002 |Train loss: 3.50560886|Test loss: 4.11088856\n","Epoch: 931 | Lr: 0.00100000000000000002 |Train loss: 3.51922977|Test loss: 4.16927616\n","Epoch: 932 | Lr: 0.00100000000000000002 |Train loss: 3.53505043|Test loss: 4.22454373\n","Epoch: 933 | Lr: 0.00100000000000000002 |Train loss: 3.60814093|Test loss: 4.17520038\n","Epoch: 934 | Lr: 0.00100000000000000002 |Train loss: 3.55683271|Test loss: 4.16096608\n","Epoch: 935 | Lr: 0.00100000000000000002 |Train loss: 3.48144641|Test loss: 4.21117520\n","Epoch: 936 | Lr: 0.00100000000000000002 |Train loss: 3.48214543|Test loss: 4.24705458\n","Epoch: 937 | Lr: 0.00100000000000000002 |Train loss: 3.45522608|Test loss: 4.37525821\n","Epoch: 938 | Lr: 0.00100000000000000002 |Train loss: 3.44460694|Test loss: 4.26262132\n","Epoch: 939 | Lr: 0.00100000000000000002 |Train loss: 3.47925522|Test loss: 4.29016527\n","Epoch: 940 | Lr: 0.00100000000000000002 |Train loss: 3.47151838|Test loss: 4.47761766\n","Epoch: 941 | Lr: 0.00100000000000000002 |Train loss: 3.46210357|Test loss: 4.45518128\n","Epoch: 942 | Lr: 0.00100000000000000002 |Train loss: 3.47013589|Test loss: 4.47962356\n","Epoch: 943 | Lr: 0.00100000000000000002 |Train loss: 3.46448159|Test loss: 4.40767741\n","Epoch: 944 | Lr: 0.00100000000000000002 |Train loss: 3.43530148|Test loss: 4.44593000\n","Epoch: 945 | Lr: 0.00100000000000000002 |Train loss: 3.42544786|Test loss: 4.55675769\n","Epoch: 946 | Lr: 0.00100000000000000002 |Train loss: 3.43045688|Test loss: 4.43783323\n","Epoch: 947 | Lr: 0.00100000000000000002 |Train loss: 3.43827657|Test loss: 4.46477000\n","Epoch: 948 | Lr: 0.00100000000000000002 |Train loss: 3.45397536|Test loss: 4.32761256\n","Epoch: 949 | Lr: 0.00100000000000000002 |Train loss: 3.48936766|Test loss: 4.16258915\n","Epoch: 950 | Lr: 0.00100000000000000002 |Train loss: 3.48920417|Test loss: 4.08829840\n","Epoch: 951 | Lr: 0.00100000000000000002 |Train loss: 3.48265284|Test loss: 4.17162577\n","Epoch: 952 | Lr: 0.00100000000000000002 |Train loss: 3.55120973|Test loss: 4.23082519\n","Epoch: 953 | Lr: 0.00100000000000000002 |Train loss: 3.49722459|Test loss: 4.32680543\n","Epoch: 954 | Lr: 0.00100000000000000002 |Train loss: 3.45336735|Test loss: 4.42640082\n","Epoch: 955 | Lr: 0.00100000000000000002 |Train loss: 3.45359453|Test loss: 4.48772701\n","Epoch: 956 | Lr: 0.00100000000000000002 |Train loss: 3.49204485|Test loss: 4.35542782\n","Epoch: 957 | Lr: 0.00100000000000000002 |Train loss: 3.50417338|Test loss: 4.69120471\n","Epoch: 958 | Lr: 0.00100000000000000002 |Train loss: 3.50108965|Test loss: 4.51659354\n","Epoch: 959 | Lr: 0.00100000000000000002 |Train loss: 3.45964730|Test loss: 4.51378632\n","Epoch: 960 | Lr: 0.00100000000000000002 |Train loss: 3.49165634|Test loss: 4.20637155\n","Epoch: 961 | Lr: 0.00100000000000000002 |Train loss: 3.53398430|Test loss: 4.10613529\n","Epoch: 962 | Lr: 0.00100000000000000002 |Train loss: 3.47765358|Test loss: 4.26687845\n","Epoch: 963 | Lr: 0.00100000000000000002 |Train loss: 3.54861871|Test loss: 4.16368119\n","Epoch: 964 | Lr: 0.00100000000000000002 |Train loss: 3.45016905|Test loss: 4.25717513\n","Epoch: 965 | Lr: 0.00100000000000000002 |Train loss: 3.47464935|Test loss: 4.29388475\n","Epoch: 966 | Lr: 0.00100000000000000002 |Train loss: 3.46482954|Test loss: 4.47426987\n","Epoch: 967 | Lr: 0.00100000000000000002 |Train loss: 3.49600716|Test loss: 4.34691612\n","Epoch: 968 | Lr: 0.00100000000000000002 |Train loss: 3.44358919|Test loss: 4.27382962\n","Epoch: 969 | Lr: 0.00100000000000000002 |Train loss: 3.46438064|Test loss: 4.39854145\n","Epoch: 970 | Lr: 0.00100000000000000002 |Train loss: 3.46171131|Test loss: 4.44855642\n","Epoch: 971 | Lr: 0.00100000000000000002 |Train loss: 3.44516220|Test loss: 4.51134459\n","Epoch: 972 | Lr: 0.00100000000000000002 |Train loss: 3.48538822|Test loss: 4.39823000\n","Epoch: 973 | Lr: 0.00100000000000000002 |Train loss: 3.47038080|Test loss: 4.22001863\n","Epoch: 974 | Lr: 0.00100000000000000002 |Train loss: 3.46703690|Test loss: 4.15271505\n","Epoch: 975 | Lr: 0.00100000000000000002 |Train loss: 3.43016001|Test loss: 4.19282881\n","Epoch: 976 | Lr: 0.00100000000000000002 |Train loss: 3.45048362|Test loss: 4.24161124\n","Epoch: 977 | Lr: 0.00100000000000000002 |Train loss: 3.44392989|Test loss: 4.30925131\n","Epoch: 978 | Lr: 0.00100000000000000002 |Train loss: 3.44518107|Test loss: 4.41401998\n","Epoch: 979 | Lr: 0.00100000000000000002 |Train loss: 3.45381037|Test loss: 4.39239899\n","Epoch: 980 | Lr: 0.00100000000000000002 |Train loss: 3.56586564|Test loss: 4.26704343\n","Epoch: 981 | Lr: 0.00100000000000000002 |Train loss: 3.61824824|Test loss: 4.29314137\n","Epoch: 982 | Lr: 0.00100000000000000002 |Train loss: 3.54702737|Test loss: 4.76941109\n","Epoch: 983 | Lr: 0.00100000000000000002 |Train loss: 3.51912554|Test loss: 4.49593170\n","Epoch: 984 | Lr: 0.00100000000000000002 |Train loss: 3.45973223|Test loss: 4.40577753\n","Epoch: 985 | Lr: 0.00100000000000000002 |Train loss: 3.45073946|Test loss: 4.48693681\n","Epoch: 986 | Lr: 0.00100000000000000002 |Train loss: 3.43962534|Test loss: 4.57294544\n","Epoch: 987 | Lr: 0.00100000000000000002 |Train loss: 3.44989938|Test loss: 4.50569065\n","Epoch: 988 | Lr: 0.00100000000000000002 |Train loss: 3.42112019|Test loss: 4.47167571\n","Epoch: 989 | Lr: 0.00100000000000000002 |Train loss: 3.41310038|Test loss: 4.45097486\n","Epoch: 990 | Lr: 0.00100000000000000002 |Train loss: 3.41266272|Test loss: 4.55787635\n","Epoch: 991 | Lr: 0.00100000000000000002 |Train loss: 3.41924055|Test loss: 4.53001046\n","Epoch: 992 | Lr: 0.00100000000000000002 |Train loss: 3.43772521|Test loss: 4.41699235\n","Epoch: 993 | Lr: 0.00100000000000000002 |Train loss: 3.42628765|Test loss: 4.58569678\n","Epoch: 994 | Lr: 0.00100000000000000002 |Train loss: 3.45073066|Test loss: 4.56009571\n","Epoch: 995 | Lr: 0.00100000000000000002 |Train loss: 3.45366319|Test loss: 4.62576779\n","Epoch: 996 | Lr: 0.00100000000000000002 |Train loss: 3.47066677|Test loss: 4.92886337\n","Epoch: 997 | Lr: 0.00100000000000000002 |Train loss: 3.49435308|Test loss: 4.71422990\n","Epoch: 998 | Lr: 0.00100000000000000002 |Train loss: 3.48988148|Test loss: 4.49565021\n","Epoch: 999 | Lr: 0.00100000000000000002 |Train loss: 3.52442346|Test loss: 4.57173959\n","Epoch: 1000 | Lr: 0.00100000000000000002 |Train loss: 3.49506388|Test loss: 4.73441807\n","\n","Training finished.\n","\n"]}]},{"cell_type":"code","source":["plt.plot(np.arange(1000), train_mean)\n","plt.plot(np.arange(1000), test_mean)\n","plt.xlabel('epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Train','Test'])"],"metadata":{"id":"NTwYy9OW45OA","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1661111214834,"user_tz":240,"elapsed":650,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"37171f20-099d-44ce-f6f1-f50b3cb5630a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7ffb08b6e4d0>"]},"metadata":{},"execution_count":62},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Try to use different correlation matrix:\n","corrleation = 1/ (h^x)  \n","h = 2: training loss = 2.88, testing loss = 3.59\\\n","h = 3: training loss = 2.31, testing loss = 3.42\\\n","h = 4: training loss = 2.26, testing loss = 3.24"],"metadata":{"id":"x1JrBj8T8dma"}},{"cell_type":"code","source":["time_step = 5\n","feature_matrix = np.load('feature_matrix.npy')\n","corrlation = np.load('correlation_2.npy').astype(np.float32)\n","feature_matrix,target = normalization(feature_matrix)\n","feature_matrix = torch.tensor(feature_matrix.astype(np.float32))\n","adj = torch.tensor(corrlation)\n","target = torch.tensor(target.astype(np.float32))\n","features, results = get_features(time_step, feature_matrix)\n","train_idx = int(0.8*features.shape[0])\n","train_feature, train_result = features[:train_idx,:,:], results[:train_idx,:,:]\n","test_feature, test_result = features[train_idx:,:,:], results[train_idx:,:,:]"],"metadata":{"id":"BC4jAp0z8cn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_val_loss = np.inf\n","epochs = 1000\n","train_mean, test_mean = np.zeros((epochs,1)), np.zeros((epochs,1))\n","model = Generator(time_step*5+50, 32, 1).to(device)#time_step*5: feature nums, 32: hid layer, 1:output\n","loss = nn.MSELoss()\n","optimizer = optim.AdamW(model.parameters(),lr=0.001)\n","for epoch in tqdm_notebook(range(1,epochs + 1)):\n","    train_mean_loss, test_mean_loss, n, n1 = np.zeros((train_feature.shape[0],1)), np.zeros((test_feature.shape[0],1)), train_feature.shape[0], test_feature.shape[0]\n","    for i in range(n):\n","      #train_loss\n","      noise = torch.randn(train_feature.shape[1], 50)\n","      noise = torch.concat([noise, train_feature[i]], dim = 1) \n","      train = model(noise, adj)\n","      train_loss = loss(train, train_result[i])\n","      optimizer.zero_grad()\n","      train_loss.backward()\n","      optimizer.step()\n","      train_mean_loss[i] = train_loss.detach().numpy()\n","    for i in range(n1):\n","      noise2 = torch.randn(test_feature.shape[1], 50)\n","      noise2 = torch.concat([noise2, test_feature[i]], dim = 1)\n","      test = model(noise2, adj)\n","      test_loss = loss(test, test_result[i])\n","      test_mean_loss[i] = test_loss.detach().numpy()\n","    train_mean[epoch - 1], test_mean[epoch - 1] = train_mean_loss.mean(), test_mean_loss.mean()\n","    if mean_loss.mean() < min_val_loss:\n","      min_val_loss = mean_loss.mean()\n","    print('Epoch: {:03d} | Lr: {:.20f} |Train loss: {:.8f}|Test loss: {:.8f}'.\\\n","          format(epoch, optimizer.param_groups[0]['lr'], train_mean_loss.mean(), test_mean_loss.mean()))\n","print('\\nTraining finished.\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5648ebecf5cc4d95b6e27a8e53d6836b","03e0e92e4ade49c18c59ed1836bc4e34","7f5856ba8fbc417b92225144b2928808","b1e6524d0549477eb97f474161c44d36","03cd8fdaf25045b79dc6bdd4ae9b8de9","3fe7876a5a7d44ad8349fe6114fd3893","a68b3451953d4ece9b31d1317849301c","54e8c52fb13e492eac0d31b342bf1c44","892474f4e6994456bd4363effd49c62f","2eeee8ca2f4242788f36d8cfaa3da0e2","e16372e921934e68ae2b4aef1572586d"]},"id":"VQn8TNo59KFP","executionInfo":{"status":"ok","timestamp":1661111918746,"user_tz":240,"elapsed":500427,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"3ab82b1f-e5fd-42eb-8456-16bffc9f6f01"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5648ebecf5cc4d95b6e27a8e53d6836b"},"application/json":{"n":0,"total":1000,"elapsed":0.05813932418823242,"ncols":null,"nrows":null,"prefix":"","ascii":false,"unit":"it","unit_scale":false,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1000,"initial":0,"colour":null}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 29.91359488|Test loss: 8.12398783\n","Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 15.41730531|Test loss: 9.00487868\n","Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 7.63540630|Test loss: 5.65271997\n","Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 6.13402291|Test loss: 5.04152393\n","Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 4.70910267|Test loss: 4.89197556\n","Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 4.41085676|Test loss: 4.51088127\n","Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 4.26868898|Test loss: 4.20434443\n","Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 4.15486201|Test loss: 4.25463104\n","Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 4.10175075|Test loss: 4.29898930\n","Epoch: 010 | Lr: 0.00100000000000000002 |Train loss: 4.05499589|Test loss: 4.14314063\n","Epoch: 011 | Lr: 0.00100000000000000002 |Train loss: 4.02991056|Test loss: 4.02972817\n","Epoch: 012 | Lr: 0.00100000000000000002 |Train loss: 4.03299564|Test loss: 4.01724863\n","Epoch: 013 | Lr: 0.00100000000000000002 |Train loss: 4.03093561|Test loss: 4.09659934\n","Epoch: 014 | Lr: 0.00100000000000000002 |Train loss: 4.04560588|Test loss: 4.03927581\n","Epoch: 015 | Lr: 0.00100000000000000002 |Train loss: 3.92506538|Test loss: 4.19400787\n","Epoch: 016 | Lr: 0.00100000000000000002 |Train loss: 3.98693438|Test loss: 4.01761993\n","Epoch: 017 | Lr: 0.00100000000000000002 |Train loss: 3.96959517|Test loss: 4.10806847\n","Epoch: 018 | Lr: 0.00100000000000000002 |Train loss: 3.90085850|Test loss: 4.12901862\n","Epoch: 019 | Lr: 0.00100000000000000002 |Train loss: 3.91920877|Test loss: 4.02669899\n","Epoch: 020 | Lr: 0.00100000000000000002 |Train loss: 3.94847854|Test loss: 4.00710773\n","Epoch: 021 | Lr: 0.00100000000000000002 |Train loss: 3.94574900|Test loss: 3.98441784\n","Epoch: 022 | Lr: 0.00100000000000000002 |Train loss: 3.89701768|Test loss: 4.05877240\n","Epoch: 023 | Lr: 0.00100000000000000002 |Train loss: 3.90106513|Test loss: 3.95520655\n","Epoch: 024 | Lr: 0.00100000000000000002 |Train loss: 3.90984859|Test loss: 4.01184543\n","Epoch: 025 | Lr: 0.00100000000000000002 |Train loss: 3.96550934|Test loss: 3.99258113\n","Epoch: 026 | Lr: 0.00100000000000000002 |Train loss: 3.94172378|Test loss: 4.08267816\n","Epoch: 027 | Lr: 0.00100000000000000002 |Train loss: 3.91858586|Test loss: 3.96655528\n","Epoch: 028 | Lr: 0.00100000000000000002 |Train loss: 3.89549255|Test loss: 3.97135560\n","Epoch: 029 | Lr: 0.00100000000000000002 |Train loss: 3.90381753|Test loss: 3.93296758\n","Epoch: 030 | Lr: 0.00100000000000000002 |Train loss: 3.88544214|Test loss: 3.93573292\n","Epoch: 031 | Lr: 0.00100000000000000002 |Train loss: 3.88514322|Test loss: 3.98473605\n","Epoch: 032 | Lr: 0.00100000000000000002 |Train loss: 3.86566649|Test loss: 3.95081091\n","Epoch: 033 | Lr: 0.00100000000000000002 |Train loss: 3.86159762|Test loss: 3.93160844\n","Epoch: 034 | Lr: 0.00100000000000000002 |Train loss: 3.86397405|Test loss: 3.92776036\n","Epoch: 035 | Lr: 0.00100000000000000002 |Train loss: 3.87754846|Test loss: 3.92308609\n","Epoch: 036 | Lr: 0.00100000000000000002 |Train loss: 3.85374784|Test loss: 4.05182934\n","Epoch: 037 | Lr: 0.00100000000000000002 |Train loss: 3.85489500|Test loss: 3.94276444\n","Epoch: 038 | Lr: 0.00100000000000000002 |Train loss: 3.87408066|Test loss: 3.91580606\n","Epoch: 039 | Lr: 0.00100000000000000002 |Train loss: 3.84983557|Test loss: 3.91091808\n","Epoch: 040 | Lr: 0.00100000000000000002 |Train loss: 3.84026120|Test loss: 3.93079726\n","Epoch: 041 | Lr: 0.00100000000000000002 |Train loss: 3.84323029|Test loss: 3.91271321\n","Epoch: 042 | Lr: 0.00100000000000000002 |Train loss: 3.83981788|Test loss: 3.94180266\n","Epoch: 043 | Lr: 0.00100000000000000002 |Train loss: 3.84070971|Test loss: 3.92385046\n","Epoch: 044 | Lr: 0.00100000000000000002 |Train loss: 3.83531543|Test loss: 3.90607087\n","Epoch: 045 | Lr: 0.00100000000000000002 |Train loss: 3.84591768|Test loss: 3.90832933\n","Epoch: 046 | Lr: 0.00100000000000000002 |Train loss: 3.81508251|Test loss: 3.92027354\n","Epoch: 047 | Lr: 0.00100000000000000002 |Train loss: 3.85202783|Test loss: 3.90332619\n","Epoch: 048 | Lr: 0.00100000000000000002 |Train loss: 3.81911196|Test loss: 3.91912238\n","Epoch: 049 | Lr: 0.00100000000000000002 |Train loss: 3.83318559|Test loss: 3.93615373\n","Epoch: 050 | Lr: 0.00100000000000000002 |Train loss: 3.80149957|Test loss: 4.04082481\n","Epoch: 051 | Lr: 0.00100000000000000002 |Train loss: 3.83454480|Test loss: 3.90297469\n","Epoch: 052 | Lr: 0.00100000000000000002 |Train loss: 3.84660439|Test loss: 3.90830564\n","Epoch: 053 | Lr: 0.00100000000000000002 |Train loss: 3.81989684|Test loss: 3.91730086\n","Epoch: 054 | Lr: 0.00100000000000000002 |Train loss: 3.84358243|Test loss: 3.92749778\n","Epoch: 055 | Lr: 0.00100000000000000002 |Train loss: 3.81991386|Test loss: 3.90320420\n","Epoch: 056 | Lr: 0.00100000000000000002 |Train loss: 3.81146495|Test loss: 3.91827814\n","Epoch: 057 | Lr: 0.00100000000000000002 |Train loss: 3.81176643|Test loss: 3.90237594\n","Epoch: 058 | Lr: 0.00100000000000000002 |Train loss: 3.80356137|Test loss: 3.90837598\n","Epoch: 059 | Lr: 0.00100000000000000002 |Train loss: 3.80255580|Test loss: 3.99639408\n","Epoch: 060 | Lr: 0.00100000000000000002 |Train loss: 3.81603400|Test loss: 3.90877978\n","Epoch: 061 | Lr: 0.00100000000000000002 |Train loss: 3.82682433|Test loss: 3.92843302\n","Epoch: 062 | Lr: 0.00100000000000000002 |Train loss: 3.81379223|Test loss: 3.89553563\n","Epoch: 063 | Lr: 0.00100000000000000002 |Train loss: 3.81002822|Test loss: 3.92824157\n","Epoch: 064 | Lr: 0.00100000000000000002 |Train loss: 3.79556914|Test loss: 4.00956662\n","Epoch: 065 | Lr: 0.00100000000000000002 |Train loss: 3.79989417|Test loss: 3.94375094\n","Epoch: 066 | Lr: 0.00100000000000000002 |Train loss: 3.80341339|Test loss: 3.91570870\n","Epoch: 067 | Lr: 0.00100000000000000002 |Train loss: 3.83074065|Test loss: 3.90476942\n","Epoch: 068 | Lr: 0.00100000000000000002 |Train loss: 3.79089753|Test loss: 3.93370620\n","Epoch: 069 | Lr: 0.00100000000000000002 |Train loss: 3.79622696|Test loss: 3.89822300\n","Epoch: 070 | Lr: 0.00100000000000000002 |Train loss: 3.79335727|Test loss: 3.95686865\n","Epoch: 071 | Lr: 0.00100000000000000002 |Train loss: 3.80494851|Test loss: 3.89901797\n","Epoch: 072 | Lr: 0.00100000000000000002 |Train loss: 3.79058681|Test loss: 3.89100377\n","Epoch: 073 | Lr: 0.00100000000000000002 |Train loss: 3.78380777|Test loss: 3.89727585\n","Epoch: 074 | Lr: 0.00100000000000000002 |Train loss: 3.80904661|Test loss: 3.91698901\n","Epoch: 075 | Lr: 0.00100000000000000002 |Train loss: 3.79867512|Test loss: 3.90220253\n","Epoch: 076 | Lr: 0.00100000000000000002 |Train loss: 3.79088761|Test loss: 3.91548872\n","Epoch: 077 | Lr: 0.00100000000000000002 |Train loss: 3.79246952|Test loss: 3.89370704\n","Epoch: 078 | Lr: 0.00100000000000000002 |Train loss: 3.78427178|Test loss: 3.89370521\n","Epoch: 079 | Lr: 0.00100000000000000002 |Train loss: 3.76890882|Test loss: 3.87281466\n","Epoch: 080 | Lr: 0.00100000000000000002 |Train loss: 3.76941256|Test loss: 3.96633609\n","Epoch: 081 | Lr: 0.00100000000000000002 |Train loss: 3.76920164|Test loss: 3.94750500\n","Epoch: 082 | Lr: 0.00100000000000000002 |Train loss: 3.77378813|Test loss: 3.88088957\n","Epoch: 083 | Lr: 0.00100000000000000002 |Train loss: 3.77609680|Test loss: 3.88824995\n","Epoch: 084 | Lr: 0.00100000000000000002 |Train loss: 3.74945480|Test loss: 3.89152853\n","Epoch: 085 | Lr: 0.00100000000000000002 |Train loss: 3.71985161|Test loss: 3.83604638\n","Epoch: 086 | Lr: 0.00100000000000000002 |Train loss: 3.66502432|Test loss: 3.84748793\n","Epoch: 087 | Lr: 0.00100000000000000002 |Train loss: 3.64776599|Test loss: 3.80556687\n","Epoch: 088 | Lr: 0.00100000000000000002 |Train loss: 3.65577324|Test loss: 3.78316132\n","Epoch: 089 | Lr: 0.00100000000000000002 |Train loss: 3.62763892|Test loss: 3.81650893\n","Epoch: 090 | Lr: 0.00100000000000000002 |Train loss: 3.69695932|Test loss: 3.81342904\n","Epoch: 091 | Lr: 0.00100000000000000002 |Train loss: 3.71904639|Test loss: 3.81310685\n","Epoch: 092 | Lr: 0.00100000000000000002 |Train loss: 3.63139592|Test loss: 3.80207102\n","Epoch: 093 | Lr: 0.00100000000000000002 |Train loss: 3.60720116|Test loss: 3.78035887\n","Epoch: 094 | Lr: 0.00100000000000000002 |Train loss: 3.58973845|Test loss: 3.80134153\n","Epoch: 095 | Lr: 0.00100000000000000002 |Train loss: 3.62993979|Test loss: 3.78163973\n","Epoch: 096 | Lr: 0.00100000000000000002 |Train loss: 3.63810617|Test loss: 3.73572707\n","Epoch: 097 | Lr: 0.00100000000000000002 |Train loss: 3.58883903|Test loss: 3.77204450\n","Epoch: 098 | Lr: 0.00100000000000000002 |Train loss: 3.58340933|Test loss: 3.74025162\n","Epoch: 099 | Lr: 0.00100000000000000002 |Train loss: 3.55248610|Test loss: 3.72993771\n","Epoch: 100 | Lr: 0.00100000000000000002 |Train loss: 3.54089483|Test loss: 3.75056998\n","Epoch: 101 | Lr: 0.00100000000000000002 |Train loss: 3.54649538|Test loss: 3.73620288\n","Epoch: 102 | Lr: 0.00100000000000000002 |Train loss: 3.54293762|Test loss: 3.70305689\n","Epoch: 103 | Lr: 0.00100000000000000002 |Train loss: 3.53201348|Test loss: 3.72337008\n","Epoch: 104 | Lr: 0.00100000000000000002 |Train loss: 3.55624745|Test loss: 3.70853662\n","Epoch: 105 | Lr: 0.00100000000000000002 |Train loss: 3.51023531|Test loss: 3.72550090\n","Epoch: 106 | Lr: 0.00100000000000000002 |Train loss: 3.51098953|Test loss: 3.68944168\n","Epoch: 107 | Lr: 0.00100000000000000002 |Train loss: 3.51202681|Test loss: 3.71009707\n","Epoch: 108 | Lr: 0.00100000000000000002 |Train loss: 3.52113291|Test loss: 3.73778375\n","Epoch: 109 | Lr: 0.00100000000000000002 |Train loss: 3.51665829|Test loss: 3.69484973\n","Epoch: 110 | Lr: 0.00100000000000000002 |Train loss: 3.48698515|Test loss: 3.71311061\n","Epoch: 111 | Lr: 0.00100000000000000002 |Train loss: 3.48469947|Test loss: 3.71842313\n","Epoch: 112 | Lr: 0.00100000000000000002 |Train loss: 3.47943711|Test loss: 3.69467600\n","Epoch: 113 | Lr: 0.00100000000000000002 |Train loss: 3.49998464|Test loss: 3.72519493\n","Epoch: 114 | Lr: 0.00100000000000000002 |Train loss: 3.50404676|Test loss: 3.69522127\n","Epoch: 115 | Lr: 0.00100000000000000002 |Train loss: 3.49312311|Test loss: 3.71716086\n","Epoch: 116 | Lr: 0.00100000000000000002 |Train loss: 3.47973222|Test loss: 3.75874718\n","Epoch: 117 | Lr: 0.00100000000000000002 |Train loss: 3.47905656|Test loss: 3.72369091\n","Epoch: 118 | Lr: 0.00100000000000000002 |Train loss: 3.49004388|Test loss: 3.67647449\n","Epoch: 119 | Lr: 0.00100000000000000002 |Train loss: 3.48684647|Test loss: 3.70396042\n","Epoch: 120 | Lr: 0.00100000000000000002 |Train loss: 3.46796246|Test loss: 3.72528187\n","Epoch: 121 | Lr: 0.00100000000000000002 |Train loss: 3.46260341|Test loss: 3.71598474\n","Epoch: 122 | Lr: 0.00100000000000000002 |Train loss: 3.46036456|Test loss: 3.67472903\n","Epoch: 123 | Lr: 0.00100000000000000002 |Train loss: 3.46242996|Test loss: 3.67533731\n","Epoch: 124 | Lr: 0.00100000000000000002 |Train loss: 3.45985943|Test loss: 3.66472975\n","Epoch: 125 | Lr: 0.00100000000000000002 |Train loss: 3.46582882|Test loss: 3.74916331\n","Epoch: 126 | Lr: 0.00100000000000000002 |Train loss: 3.46963652|Test loss: 3.68488812\n","Epoch: 127 | Lr: 0.00100000000000000002 |Train loss: 3.45914022|Test loss: 3.68420005\n","Epoch: 128 | Lr: 0.00100000000000000002 |Train loss: 3.47950516|Test loss: 3.68127290\n","Epoch: 129 | Lr: 0.00100000000000000002 |Train loss: 3.47085281|Test loss: 3.71996458\n","Epoch: 130 | Lr: 0.00100000000000000002 |Train loss: 3.50312974|Test loss: 3.68100206\n","Epoch: 131 | Lr: 0.00100000000000000002 |Train loss: 3.47753934|Test loss: 3.68343099\n","Epoch: 132 | Lr: 0.00100000000000000002 |Train loss: 3.46499417|Test loss: 3.66346995\n","Epoch: 133 | Lr: 0.00100000000000000002 |Train loss: 3.44491671|Test loss: 3.70299339\n","Epoch: 134 | Lr: 0.00100000000000000002 |Train loss: 3.44793189|Test loss: 3.68110259\n","Epoch: 135 | Lr: 0.00100000000000000002 |Train loss: 3.45135631|Test loss: 3.68242542\n","Epoch: 136 | Lr: 0.00100000000000000002 |Train loss: 3.44985710|Test loss: 3.66781211\n","Epoch: 137 | Lr: 0.00100000000000000002 |Train loss: 3.45526004|Test loss: 3.70643624\n","Epoch: 138 | Lr: 0.00100000000000000002 |Train loss: 3.45565579|Test loss: 3.67915956\n","Epoch: 139 | Lr: 0.00100000000000000002 |Train loss: 3.45635980|Test loss: 3.69191957\n","Epoch: 140 | Lr: 0.00100000000000000002 |Train loss: 3.44545486|Test loss: 3.67469279\n","Epoch: 141 | Lr: 0.00100000000000000002 |Train loss: 3.44984148|Test loss: 3.70008039\n","Epoch: 142 | Lr: 0.00100000000000000002 |Train loss: 3.44801207|Test loss: 3.68335390\n","Epoch: 143 | Lr: 0.00100000000000000002 |Train loss: 3.44120210|Test loss: 3.70710381\n","Epoch: 144 | Lr: 0.00100000000000000002 |Train loss: 3.44481331|Test loss: 3.69886565\n","Epoch: 145 | Lr: 0.00100000000000000002 |Train loss: 3.44461542|Test loss: 3.67133617\n","Epoch: 146 | Lr: 0.00100000000000000002 |Train loss: 3.44881507|Test loss: 3.68049463\n","Epoch: 147 | Lr: 0.00100000000000000002 |Train loss: 3.44613806|Test loss: 3.66802303\n","Epoch: 148 | Lr: 0.00100000000000000002 |Train loss: 3.44308954|Test loss: 3.69311833\n","Epoch: 149 | Lr: 0.00100000000000000002 |Train loss: 3.44341675|Test loss: 3.68315673\n","Epoch: 150 | Lr: 0.00100000000000000002 |Train loss: 3.43301300|Test loss: 3.66699251\n","Epoch: 151 | Lr: 0.00100000000000000002 |Train loss: 3.43515621|Test loss: 3.69521952\n","Epoch: 152 | Lr: 0.00100000000000000002 |Train loss: 3.43372718|Test loss: 3.68843389\n","Epoch: 153 | Lr: 0.00100000000000000002 |Train loss: 3.43712638|Test loss: 3.69851629\n","Epoch: 154 | Lr: 0.00100000000000000002 |Train loss: 3.44598027|Test loss: 3.67469827\n","Epoch: 155 | Lr: 0.00100000000000000002 |Train loss: 3.43544666|Test loss: 3.68683298\n","Epoch: 156 | Lr: 0.00100000000000000002 |Train loss: 3.44120745|Test loss: 3.67628042\n","Epoch: 157 | Lr: 0.00100000000000000002 |Train loss: 3.44089743|Test loss: 3.67582655\n","Epoch: 158 | Lr: 0.00100000000000000002 |Train loss: 3.43302006|Test loss: 3.72600087\n","Epoch: 159 | Lr: 0.00100000000000000002 |Train loss: 3.43548737|Test loss: 3.71692920\n","Epoch: 160 | Lr: 0.00100000000000000002 |Train loss: 3.43048046|Test loss: 3.66643866\n","Epoch: 161 | Lr: 0.00100000000000000002 |Train loss: 3.44148747|Test loss: 3.67232641\n","Epoch: 162 | Lr: 0.00100000000000000002 |Train loss: 3.43888781|Test loss: 3.67049122\n","Epoch: 163 | Lr: 0.00100000000000000002 |Train loss: 3.43821118|Test loss: 3.70340880\n","Epoch: 164 | Lr: 0.00100000000000000002 |Train loss: 3.44094582|Test loss: 3.67162029\n","Epoch: 165 | Lr: 0.00100000000000000002 |Train loss: 3.43822519|Test loss: 3.66320070\n","Epoch: 166 | Lr: 0.00100000000000000002 |Train loss: 3.42841001|Test loss: 3.69404801\n","Epoch: 167 | Lr: 0.00100000000000000002 |Train loss: 3.42827060|Test loss: 3.67234667\n","Epoch: 168 | Lr: 0.00100000000000000002 |Train loss: 3.42873434|Test loss: 3.66666293\n","Epoch: 169 | Lr: 0.00100000000000000002 |Train loss: 3.42856173|Test loss: 3.68939781\n","Epoch: 170 | Lr: 0.00100000000000000002 |Train loss: 3.42408935|Test loss: 3.66344213\n","Epoch: 171 | Lr: 0.00100000000000000002 |Train loss: 3.42831383|Test loss: 3.68327538\n","Epoch: 172 | Lr: 0.00100000000000000002 |Train loss: 3.43805069|Test loss: 3.69369849\n","Epoch: 173 | Lr: 0.00100000000000000002 |Train loss: 3.43385086|Test loss: 3.68964648\n","Epoch: 174 | Lr: 0.00100000000000000002 |Train loss: 3.43778535|Test loss: 3.69064744\n","Epoch: 175 | Lr: 0.00100000000000000002 |Train loss: 3.42249876|Test loss: 3.65834403\n","Epoch: 176 | Lr: 0.00100000000000000002 |Train loss: 3.42905809|Test loss: 3.70746422\n","Epoch: 177 | Lr: 0.00100000000000000002 |Train loss: 3.42820420|Test loss: 3.71130697\n","Epoch: 178 | Lr: 0.00100000000000000002 |Train loss: 3.42270700|Test loss: 3.66634107\n","Epoch: 179 | Lr: 0.00100000000000000002 |Train loss: 3.42031584|Test loss: 3.67984549\n","Epoch: 180 | Lr: 0.00100000000000000002 |Train loss: 3.41944804|Test loss: 3.65761725\n","Epoch: 181 | Lr: 0.00100000000000000002 |Train loss: 3.41954972|Test loss: 3.67379951\n","Epoch: 182 | Lr: 0.00100000000000000002 |Train loss: 3.41824236|Test loss: 3.66013638\n","Epoch: 183 | Lr: 0.00100000000000000002 |Train loss: 3.42847514|Test loss: 3.68161257\n","Epoch: 184 | Lr: 0.00100000000000000002 |Train loss: 3.42344711|Test loss: 3.67245674\n","Epoch: 185 | Lr: 0.00100000000000000002 |Train loss: 3.42439528|Test loss: 3.70693684\n","Epoch: 186 | Lr: 0.00100000000000000002 |Train loss: 3.42312948|Test loss: 3.67980027\n","Epoch: 187 | Lr: 0.00100000000000000002 |Train loss: 3.41668314|Test loss: 3.66682879\n","Epoch: 188 | Lr: 0.00100000000000000002 |Train loss: 3.42451835|Test loss: 3.67815781\n","Epoch: 189 | Lr: 0.00100000000000000002 |Train loss: 3.41796271|Test loss: 3.67335900\n","Epoch: 190 | Lr: 0.00100000000000000002 |Train loss: 3.41925444|Test loss: 3.66600331\n","Epoch: 191 | Lr: 0.00100000000000000002 |Train loss: 3.41449245|Test loss: 3.69800210\n","Epoch: 192 | Lr: 0.00100000000000000002 |Train loss: 3.42692618|Test loss: 3.66013773\n","Epoch: 193 | Lr: 0.00100000000000000002 |Train loss: 3.41693817|Test loss: 3.67114568\n","Epoch: 194 | Lr: 0.00100000000000000002 |Train loss: 3.41808265|Test loss: 3.73778447\n","Epoch: 195 | Lr: 0.00100000000000000002 |Train loss: 3.42456202|Test loss: 3.70500286\n","Epoch: 196 | Lr: 0.00100000000000000002 |Train loss: 3.41279052|Test loss: 3.66345779\n","Epoch: 197 | Lr: 0.00100000000000000002 |Train loss: 3.42866713|Test loss: 3.67107344\n","Epoch: 198 | Lr: 0.00100000000000000002 |Train loss: 3.41940469|Test loss: 3.68889689\n","Epoch: 199 | Lr: 0.00100000000000000002 |Train loss: 3.41279906|Test loss: 3.69629868\n","Epoch: 200 | Lr: 0.00100000000000000002 |Train loss: 3.41665794|Test loss: 3.67707888\n","Epoch: 201 | Lr: 0.00100000000000000002 |Train loss: 3.41305403|Test loss: 3.66985981\n","Epoch: 202 | Lr: 0.00100000000000000002 |Train loss: 3.41091031|Test loss: 3.67095145\n","Epoch: 203 | Lr: 0.00100000000000000002 |Train loss: 3.41370678|Test loss: 3.65995812\n","Epoch: 204 | Lr: 0.00100000000000000002 |Train loss: 3.41592896|Test loss: 3.72072967\n","Epoch: 205 | Lr: 0.00100000000000000002 |Train loss: 3.42526110|Test loss: 3.73005335\n","Epoch: 206 | Lr: 0.00100000000000000002 |Train loss: 3.41692118|Test loss: 3.68771203\n","Epoch: 207 | Lr: 0.00100000000000000002 |Train loss: 3.42076919|Test loss: 3.67620627\n","Epoch: 208 | Lr: 0.00100000000000000002 |Train loss: 3.43265269|Test loss: 3.69350195\n","Epoch: 209 | Lr: 0.00100000000000000002 |Train loss: 3.44515667|Test loss: 3.65162230\n","Epoch: 210 | Lr: 0.00100000000000000002 |Train loss: 3.42930386|Test loss: 3.68890278\n","Epoch: 211 | Lr: 0.00100000000000000002 |Train loss: 3.42879377|Test loss: 3.73085912\n","Epoch: 212 | Lr: 0.00100000000000000002 |Train loss: 3.43007684|Test loss: 3.68970982\n","Epoch: 213 | Lr: 0.00100000000000000002 |Train loss: 3.41926457|Test loss: 3.66519825\n","Epoch: 214 | Lr: 0.00100000000000000002 |Train loss: 3.41161789|Test loss: 3.66382726\n","Epoch: 215 | Lr: 0.00100000000000000002 |Train loss: 3.40718110|Test loss: 3.66171265\n","Epoch: 216 | Lr: 0.00100000000000000002 |Train loss: 3.40377738|Test loss: 3.66573930\n","Epoch: 217 | Lr: 0.00100000000000000002 |Train loss: 3.40761932|Test loss: 3.68768207\n","Epoch: 218 | Lr: 0.00100000000000000002 |Train loss: 3.40590831|Test loss: 3.68777577\n","Epoch: 219 | Lr: 0.00100000000000000002 |Train loss: 3.40638443|Test loss: 3.66401498\n","Epoch: 220 | Lr: 0.00100000000000000002 |Train loss: 3.40501330|Test loss: 3.66302641\n","Epoch: 221 | Lr: 0.00100000000000000002 |Train loss: 3.40831826|Test loss: 3.67483314\n","Epoch: 222 | Lr: 0.00100000000000000002 |Train loss: 3.41493209|Test loss: 3.68804328\n","Epoch: 223 | Lr: 0.00100000000000000002 |Train loss: 3.40919612|Test loss: 3.67335145\n","Epoch: 224 | Lr: 0.00100000000000000002 |Train loss: 3.39814279|Test loss: 3.67801420\n","Epoch: 225 | Lr: 0.00100000000000000002 |Train loss: 3.40612312|Test loss: 3.66659220\n","Epoch: 226 | Lr: 0.00100000000000000002 |Train loss: 3.40411103|Test loss: 3.65299002\n","Epoch: 227 | Lr: 0.00100000000000000002 |Train loss: 3.40056229|Test loss: 3.67080347\n","Epoch: 228 | Lr: 0.00100000000000000002 |Train loss: 3.41335404|Test loss: 3.69262218\n","Epoch: 229 | Lr: 0.00100000000000000002 |Train loss: 3.40569083|Test loss: 3.69229857\n","Epoch: 230 | Lr: 0.00100000000000000002 |Train loss: 3.40612288|Test loss: 3.67048430\n","Epoch: 231 | Lr: 0.00100000000000000002 |Train loss: 3.40569550|Test loss: 3.66325521\n","Epoch: 232 | Lr: 0.00100000000000000002 |Train loss: 3.41048666|Test loss: 3.64818406\n","Epoch: 233 | Lr: 0.00100000000000000002 |Train loss: 3.40616020|Test loss: 3.66672182\n","Epoch: 234 | Lr: 0.00100000000000000002 |Train loss: 3.39939038|Test loss: 3.64898260\n","Epoch: 235 | Lr: 0.00100000000000000002 |Train loss: 3.39605989|Test loss: 3.66318742\n","Epoch: 236 | Lr: 0.00100000000000000002 |Train loss: 3.39869946|Test loss: 3.68539103\n","Epoch: 237 | Lr: 0.00100000000000000002 |Train loss: 3.40915835|Test loss: 3.70575054\n","Epoch: 238 | Lr: 0.00100000000000000002 |Train loss: 3.40012505|Test loss: 3.67534041\n","Epoch: 239 | Lr: 0.00100000000000000002 |Train loss: 3.39808913|Test loss: 3.65907804\n","Epoch: 240 | Lr: 0.00100000000000000002 |Train loss: 3.40450788|Test loss: 3.64325595\n","Epoch: 241 | Lr: 0.00100000000000000002 |Train loss: 3.39559821|Test loss: 3.67324479\n","Epoch: 242 | Lr: 0.00100000000000000002 |Train loss: 3.39746455|Test loss: 3.66284664\n","Epoch: 243 | Lr: 0.00100000000000000002 |Train loss: 3.39614065|Test loss: 3.68609738\n","Epoch: 244 | Lr: 0.00100000000000000002 |Train loss: 3.40101236|Test loss: 3.66502587\n","Epoch: 245 | Lr: 0.00100000000000000002 |Train loss: 3.39743364|Test loss: 3.69470286\n","Epoch: 246 | Lr: 0.00100000000000000002 |Train loss: 3.39467565|Test loss: 3.67130057\n","Epoch: 247 | Lr: 0.00100000000000000002 |Train loss: 3.40184267|Test loss: 3.68462896\n","Epoch: 248 | Lr: 0.00100000000000000002 |Train loss: 3.39413704|Test loss: 3.66785097\n","Epoch: 249 | Lr: 0.00100000000000000002 |Train loss: 3.39565849|Test loss: 3.75034857\n","Epoch: 250 | Lr: 0.00100000000000000002 |Train loss: 3.39664374|Test loss: 3.67752409\n","Epoch: 251 | Lr: 0.00100000000000000002 |Train loss: 3.39206511|Test loss: 3.67379522\n","Epoch: 252 | Lr: 0.00100000000000000002 |Train loss: 3.39613523|Test loss: 3.66272910\n","Epoch: 253 | Lr: 0.00100000000000000002 |Train loss: 3.39814691|Test loss: 3.67118732\n","Epoch: 254 | Lr: 0.00100000000000000002 |Train loss: 3.39263767|Test loss: 3.66596619\n","Epoch: 255 | Lr: 0.00100000000000000002 |Train loss: 3.39225169|Test loss: 3.66829817\n","Epoch: 256 | Lr: 0.00100000000000000002 |Train loss: 3.39402670|Test loss: 3.67475414\n","Epoch: 257 | Lr: 0.00100000000000000002 |Train loss: 3.39725814|Test loss: 3.65559824\n","Epoch: 258 | Lr: 0.00100000000000000002 |Train loss: 3.39552814|Test loss: 3.67316643\n","Epoch: 259 | Lr: 0.00100000000000000002 |Train loss: 3.39972550|Test loss: 3.69250131\n","Epoch: 260 | Lr: 0.00100000000000000002 |Train loss: 3.40341791|Test loss: 3.68677147\n","Epoch: 261 | Lr: 0.00100000000000000002 |Train loss: 3.40024322|Test loss: 3.66657082\n","Epoch: 262 | Lr: 0.00100000000000000002 |Train loss: 3.41158734|Test loss: 3.64979204\n","Epoch: 263 | Lr: 0.00100000000000000002 |Train loss: 3.42840385|Test loss: 3.66811593\n","Epoch: 264 | Lr: 0.00100000000000000002 |Train loss: 3.40026589|Test loss: 3.66352089\n","Epoch: 265 | Lr: 0.00100000000000000002 |Train loss: 3.40818369|Test loss: 3.66178099\n","Epoch: 266 | Lr: 0.00100000000000000002 |Train loss: 3.40988376|Test loss: 3.65679216\n","Epoch: 267 | Lr: 0.00100000000000000002 |Train loss: 3.41810058|Test loss: 3.69967159\n","Epoch: 268 | Lr: 0.00100000000000000002 |Train loss: 3.42678070|Test loss: 3.74668392\n","Epoch: 269 | Lr: 0.00100000000000000002 |Train loss: 3.40960439|Test loss: 3.67090487\n","Epoch: 270 | Lr: 0.00100000000000000002 |Train loss: 3.39174537|Test loss: 3.66505035\n","Epoch: 271 | Lr: 0.00100000000000000002 |Train loss: 3.39119742|Test loss: 3.66364463\n","Epoch: 272 | Lr: 0.00100000000000000002 |Train loss: 3.38808155|Test loss: 3.65413872\n","Epoch: 273 | Lr: 0.00100000000000000002 |Train loss: 3.39399101|Test loss: 3.64567939\n","Epoch: 274 | Lr: 0.00100000000000000002 |Train loss: 3.40130359|Test loss: 3.64941971\n","Epoch: 275 | Lr: 0.00100000000000000002 |Train loss: 3.38957640|Test loss: 3.65031370\n","Epoch: 276 | Lr: 0.00100000000000000002 |Train loss: 3.38619687|Test loss: 3.66143735\n","Epoch: 277 | Lr: 0.00100000000000000002 |Train loss: 3.38719714|Test loss: 3.66033101\n","Epoch: 278 | Lr: 0.00100000000000000002 |Train loss: 3.39007841|Test loss: 3.66325378\n","Epoch: 279 | Lr: 0.00100000000000000002 |Train loss: 3.38570120|Test loss: 3.66633097\n","Epoch: 280 | Lr: 0.00100000000000000002 |Train loss: 3.38603318|Test loss: 3.66102862\n","Epoch: 281 | Lr: 0.00100000000000000002 |Train loss: 3.38627513|Test loss: 3.63654804\n","Epoch: 282 | Lr: 0.00100000000000000002 |Train loss: 3.38222859|Test loss: 3.64438756\n","Epoch: 283 | Lr: 0.00100000000000000002 |Train loss: 3.38810380|Test loss: 3.66647871\n","Epoch: 284 | Lr: 0.00100000000000000002 |Train loss: 3.38780715|Test loss: 3.65789437\n","Epoch: 285 | Lr: 0.00100000000000000002 |Train loss: 3.38801638|Test loss: 3.65110048\n","Epoch: 286 | Lr: 0.00100000000000000002 |Train loss: 3.38677100|Test loss: 3.65952619\n","Epoch: 287 | Lr: 0.00100000000000000002 |Train loss: 3.38808205|Test loss: 3.65868266\n","Epoch: 288 | Lr: 0.00100000000000000002 |Train loss: 3.38825967|Test loss: 3.67337728\n","Epoch: 289 | Lr: 0.00100000000000000002 |Train loss: 3.38825391|Test loss: 3.64510767\n","Epoch: 290 | Lr: 0.00100000000000000002 |Train loss: 3.38828339|Test loss: 3.66373308\n","Epoch: 291 | Lr: 0.00100000000000000002 |Train loss: 3.38907643|Test loss: 3.65530078\n","Epoch: 292 | Lr: 0.00100000000000000002 |Train loss: 3.38394801|Test loss: 3.64752706\n","Epoch: 293 | Lr: 0.00100000000000000002 |Train loss: 3.38885425|Test loss: 3.67632286\n","Epoch: 294 | Lr: 0.00100000000000000002 |Train loss: 3.38626732|Test loss: 3.67179990\n","Epoch: 295 | Lr: 0.00100000000000000002 |Train loss: 3.38816416|Test loss: 3.66900341\n","Epoch: 296 | Lr: 0.00100000000000000002 |Train loss: 3.38141972|Test loss: 3.66855812\n","Epoch: 297 | Lr: 0.00100000000000000002 |Train loss: 3.38531552|Test loss: 3.64200767\n","Epoch: 298 | Lr: 0.00100000000000000002 |Train loss: 3.38514537|Test loss: 3.63700779\n","Epoch: 299 | Lr: 0.00100000000000000002 |Train loss: 3.39096389|Test loss: 3.65159504\n","Epoch: 300 | Lr: 0.00100000000000000002 |Train loss: 3.39047025|Test loss: 3.64806787\n","Epoch: 301 | Lr: 0.00100000000000000002 |Train loss: 3.38158820|Test loss: 3.63768570\n","Epoch: 302 | Lr: 0.00100000000000000002 |Train loss: 3.38029989|Test loss: 3.65311416\n","Epoch: 303 | Lr: 0.00100000000000000002 |Train loss: 3.39184622|Test loss: 3.67791470\n","Epoch: 304 | Lr: 0.00100000000000000002 |Train loss: 3.39179800|Test loss: 3.70722214\n","Epoch: 305 | Lr: 0.00100000000000000002 |Train loss: 3.39154637|Test loss: 3.66247129\n","Epoch: 306 | Lr: 0.00100000000000000002 |Train loss: 3.38731138|Test loss: 3.65219259\n","Epoch: 307 | Lr: 0.00100000000000000002 |Train loss: 3.38155393|Test loss: 3.65386518\n","Epoch: 308 | Lr: 0.00100000000000000002 |Train loss: 3.38513352|Test loss: 3.63318531\n","Epoch: 309 | Lr: 0.00100000000000000002 |Train loss: 3.38678996|Test loss: 3.65810299\n","Epoch: 310 | Lr: 0.00100000000000000002 |Train loss: 3.39281040|Test loss: 3.63660169\n","Epoch: 311 | Lr: 0.00100000000000000002 |Train loss: 3.37550110|Test loss: 3.64261826\n","Epoch: 312 | Lr: 0.00100000000000000002 |Train loss: 3.38077394|Test loss: 3.64884766\n","Epoch: 313 | Lr: 0.00100000000000000002 |Train loss: 3.38068106|Test loss: 3.65272681\n","Epoch: 314 | Lr: 0.00100000000000000002 |Train loss: 3.38032607|Test loss: 3.64756624\n","Epoch: 315 | Lr: 0.00100000000000000002 |Train loss: 3.37274083|Test loss: 3.65745767\n","Epoch: 316 | Lr: 0.00100000000000000002 |Train loss: 3.37326803|Test loss: 3.64493577\n","Epoch: 317 | Lr: 0.00100000000000000002 |Train loss: 3.37567470|Test loss: 3.63707066\n","Epoch: 318 | Lr: 0.00100000000000000002 |Train loss: 3.37332968|Test loss: 3.66306901\n","Epoch: 319 | Lr: 0.00100000000000000002 |Train loss: 3.36890358|Test loss: 3.65452933\n","Epoch: 320 | Lr: 0.00100000000000000002 |Train loss: 3.37472399|Test loss: 3.64726472\n","Epoch: 321 | Lr: 0.00100000000000000002 |Train loss: 3.38461796|Test loss: 3.64914187\n","Epoch: 322 | Lr: 0.00100000000000000002 |Train loss: 3.37382917|Test loss: 3.71887890\n","Epoch: 323 | Lr: 0.00100000000000000002 |Train loss: 3.38019991|Test loss: 3.62343550\n","Epoch: 324 | Lr: 0.00100000000000000002 |Train loss: 3.37020709|Test loss: 3.63084102\n","Epoch: 325 | Lr: 0.00100000000000000002 |Train loss: 3.37304093|Test loss: 3.64589945\n","Epoch: 326 | Lr: 0.00100000000000000002 |Train loss: 3.37297630|Test loss: 3.63897212\n","Epoch: 327 | Lr: 0.00100000000000000002 |Train loss: 3.36586620|Test loss: 3.66193620\n","Epoch: 328 | Lr: 0.00100000000000000002 |Train loss: 3.37653842|Test loss: 3.65280747\n","Epoch: 329 | Lr: 0.00100000000000000002 |Train loss: 3.37414537|Test loss: 3.63972624\n","Epoch: 330 | Lr: 0.00100000000000000002 |Train loss: 3.36567968|Test loss: 3.63076528\n","Epoch: 331 | Lr: 0.00100000000000000002 |Train loss: 3.36984201|Test loss: 3.63908323\n","Epoch: 332 | Lr: 0.00100000000000000002 |Train loss: 3.37453592|Test loss: 3.65008481\n","Epoch: 333 | Lr: 0.00100000000000000002 |Train loss: 3.37409588|Test loss: 3.66954295\n","Epoch: 334 | Lr: 0.00100000000000000002 |Train loss: 3.37089159|Test loss: 3.66376344\n","Epoch: 335 | Lr: 0.00100000000000000002 |Train loss: 3.37439203|Test loss: 3.66895262\n","Epoch: 336 | Lr: 0.00100000000000000002 |Train loss: 3.37923447|Test loss: 3.64873624\n","Epoch: 337 | Lr: 0.00100000000000000002 |Train loss: 3.38565743|Test loss: 3.63304631\n","Epoch: 338 | Lr: 0.00100000000000000002 |Train loss: 3.37267661|Test loss: 3.62900893\n","Epoch: 339 | Lr: 0.00100000000000000002 |Train loss: 3.37001572|Test loss: 3.64986293\n","Epoch: 340 | Lr: 0.00100000000000000002 |Train loss: 3.37516624|Test loss: 3.62070568\n","Epoch: 341 | Lr: 0.00100000000000000002 |Train loss: 3.36544945|Test loss: 3.65696049\n","Epoch: 342 | Lr: 0.00100000000000000002 |Train loss: 3.36741440|Test loss: 3.65446647\n","Epoch: 343 | Lr: 0.00100000000000000002 |Train loss: 3.36645691|Test loss: 3.67114329\n","Epoch: 344 | Lr: 0.00100000000000000002 |Train loss: 3.36305185|Test loss: 3.64556861\n","Epoch: 345 | Lr: 0.00100000000000000002 |Train loss: 3.35677089|Test loss: 3.64638313\n","Epoch: 346 | Lr: 0.00100000000000000002 |Train loss: 3.35311319|Test loss: 3.63334012\n","Epoch: 347 | Lr: 0.00100000000000000002 |Train loss: 3.35589284|Test loss: 3.64190507\n","Epoch: 348 | Lr: 0.00100000000000000002 |Train loss: 3.35586792|Test loss: 3.64393163\n","Epoch: 349 | Lr: 0.00100000000000000002 |Train loss: 3.35355202|Test loss: 3.65954566\n","Epoch: 350 | Lr: 0.00100000000000000002 |Train loss: 3.35582171|Test loss: 3.63585138\n","Epoch: 351 | Lr: 0.00100000000000000002 |Train loss: 3.35545629|Test loss: 3.72450177\n","Epoch: 352 | Lr: 0.00100000000000000002 |Train loss: 3.35496986|Test loss: 3.62291177\n","Epoch: 353 | Lr: 0.00100000000000000002 |Train loss: 3.35405880|Test loss: 3.65029224\n","Epoch: 354 | Lr: 0.00100000000000000002 |Train loss: 3.35492637|Test loss: 3.64844100\n","Epoch: 355 | Lr: 0.00100000000000000002 |Train loss: 3.34384642|Test loss: 3.59864863\n","Epoch: 356 | Lr: 0.00100000000000000002 |Train loss: 3.35113821|Test loss: 3.63587228\n","Epoch: 357 | Lr: 0.00100000000000000002 |Train loss: 3.35327713|Test loss: 3.61818878\n","Epoch: 358 | Lr: 0.00100000000000000002 |Train loss: 3.35907680|Test loss: 3.62950667\n","Epoch: 359 | Lr: 0.00100000000000000002 |Train loss: 3.34932427|Test loss: 3.62381268\n","Epoch: 360 | Lr: 0.00100000000000000002 |Train loss: 3.34829736|Test loss: 3.69114876\n","Epoch: 361 | Lr: 0.00100000000000000002 |Train loss: 3.35380393|Test loss: 3.60028903\n","Epoch: 362 | Lr: 0.00100000000000000002 |Train loss: 3.34988205|Test loss: 3.61979771\n","Epoch: 363 | Lr: 0.00100000000000000002 |Train loss: 3.33833565|Test loss: 3.81985307\n","Epoch: 364 | Lr: 0.00100000000000000002 |Train loss: 3.35376763|Test loss: 3.62330985\n","Epoch: 365 | Lr: 0.00100000000000000002 |Train loss: 3.36320442|Test loss: 3.66348060\n","Epoch: 366 | Lr: 0.00100000000000000002 |Train loss: 3.35916404|Test loss: 3.60489408\n","Epoch: 367 | Lr: 0.00100000000000000002 |Train loss: 3.35358163|Test loss: 3.64049141\n","Epoch: 368 | Lr: 0.00100000000000000002 |Train loss: 3.34450098|Test loss: 3.61472487\n","Epoch: 369 | Lr: 0.00100000000000000002 |Train loss: 3.35132903|Test loss: 3.67367387\n","Epoch: 370 | Lr: 0.00100000000000000002 |Train loss: 3.36336736|Test loss: 3.61933255\n","Epoch: 371 | Lr: 0.00100000000000000002 |Train loss: 3.35615289|Test loss: 3.65335925\n","Epoch: 372 | Lr: 0.00100000000000000002 |Train loss: 3.35594330|Test loss: 3.61537043\n","Epoch: 373 | Lr: 0.00100000000000000002 |Train loss: 3.34205621|Test loss: 3.62347738\n","Epoch: 374 | Lr: 0.00100000000000000002 |Train loss: 3.34499470|Test loss: 3.70167510\n","Epoch: 375 | Lr: 0.00100000000000000002 |Train loss: 3.34463475|Test loss: 3.62043730\n","Epoch: 376 | Lr: 0.00100000000000000002 |Train loss: 3.33983586|Test loss: 3.67500257\n","Epoch: 377 | Lr: 0.00100000000000000002 |Train loss: 3.33617314|Test loss: 3.61669215\n","Epoch: 378 | Lr: 0.00100000000000000002 |Train loss: 3.33596484|Test loss: 3.62198893\n","Epoch: 379 | Lr: 0.00100000000000000002 |Train loss: 3.33635439|Test loss: 3.62199513\n","Epoch: 380 | Lr: 0.00100000000000000002 |Train loss: 3.33282238|Test loss: 3.60053651\n","Epoch: 381 | Lr: 0.00100000000000000002 |Train loss: 3.35001528|Test loss: 3.68263841\n","Epoch: 382 | Lr: 0.00100000000000000002 |Train loss: 3.34846765|Test loss: 3.60934480\n","Epoch: 383 | Lr: 0.00100000000000000002 |Train loss: 3.35881617|Test loss: 3.63175186\n","Epoch: 384 | Lr: 0.00100000000000000002 |Train loss: 3.36713980|Test loss: 3.61369928\n","Epoch: 385 | Lr: 0.00100000000000000002 |Train loss: 3.35669442|Test loss: 3.65263049\n","Epoch: 386 | Lr: 0.00100000000000000002 |Train loss: 3.36404099|Test loss: 3.63880022\n","Epoch: 387 | Lr: 0.00100000000000000002 |Train loss: 3.35871595|Test loss: 3.64803330\n","Epoch: 388 | Lr: 0.00100000000000000002 |Train loss: 3.33767563|Test loss: 3.63828405\n","Epoch: 389 | Lr: 0.00100000000000000002 |Train loss: 3.33652616|Test loss: 3.65981476\n","Epoch: 390 | Lr: 0.00100000000000000002 |Train loss: 3.33622479|Test loss: 3.66675401\n","Epoch: 391 | Lr: 0.00100000000000000002 |Train loss: 3.33795669|Test loss: 3.62684306\n","Epoch: 392 | Lr: 0.00100000000000000002 |Train loss: 3.34870549|Test loss: 3.62807409\n","Epoch: 393 | Lr: 0.00100000000000000002 |Train loss: 3.35396995|Test loss: 3.65494704\n","Epoch: 394 | Lr: 0.00100000000000000002 |Train loss: 3.36044445|Test loss: 3.61881216\n","Epoch: 395 | Lr: 0.00100000000000000002 |Train loss: 3.35775475|Test loss: 3.64427050\n","Epoch: 396 | Lr: 0.00100000000000000002 |Train loss: 3.39250894|Test loss: 3.62404648\n","Epoch: 397 | Lr: 0.00100000000000000002 |Train loss: 3.63531210|Test loss: 3.77531560\n","Epoch: 398 | Lr: 0.00100000000000000002 |Train loss: 3.50676447|Test loss: 3.71860043\n","Epoch: 399 | Lr: 0.00100000000000000002 |Train loss: 3.47836016|Test loss: 3.67983508\n","Epoch: 400 | Lr: 0.00100000000000000002 |Train loss: 3.45695559|Test loss: 3.68252794\n","Epoch: 401 | Lr: 0.00100000000000000002 |Train loss: 3.44198370|Test loss: 3.68351658\n","Epoch: 402 | Lr: 0.00100000000000000002 |Train loss: 3.44593086|Test loss: 3.66950846\n","Epoch: 403 | Lr: 0.00100000000000000002 |Train loss: 3.42869518|Test loss: 3.67902517\n","Epoch: 404 | Lr: 0.00100000000000000002 |Train loss: 3.42947143|Test loss: 3.67214505\n","Epoch: 405 | Lr: 0.00100000000000000002 |Train loss: 3.42389335|Test loss: 3.66547410\n","Epoch: 406 | Lr: 0.00100000000000000002 |Train loss: 3.41751881|Test loss: 3.67791645\n","Epoch: 407 | Lr: 0.00100000000000000002 |Train loss: 3.42328427|Test loss: 3.68728503\n","Epoch: 408 | Lr: 0.00100000000000000002 |Train loss: 3.41685218|Test loss: 3.65672072\n","Epoch: 409 | Lr: 0.00100000000000000002 |Train loss: 3.44095627|Test loss: 3.67452590\n","Epoch: 410 | Lr: 0.00100000000000000002 |Train loss: 3.42436713|Test loss: 3.66673867\n","Epoch: 411 | Lr: 0.00100000000000000002 |Train loss: 3.41475741|Test loss: 3.66243688\n","Epoch: 412 | Lr: 0.00100000000000000002 |Train loss: 3.41344696|Test loss: 3.66674940\n","Epoch: 413 | Lr: 0.00100000000000000002 |Train loss: 3.41170925|Test loss: 3.65443206\n","Epoch: 414 | Lr: 0.00100000000000000002 |Train loss: 3.41035563|Test loss: 3.66320690\n","Epoch: 415 | Lr: 0.00100000000000000002 |Train loss: 3.41416019|Test loss: 3.66120553\n","Epoch: 416 | Lr: 0.00100000000000000002 |Train loss: 3.40888909|Test loss: 3.64929136\n","Epoch: 417 | Lr: 0.00100000000000000002 |Train loss: 3.40726844|Test loss: 3.65414906\n","Epoch: 418 | Lr: 0.00100000000000000002 |Train loss: 3.41229433|Test loss: 3.65378435\n","Epoch: 419 | Lr: 0.00100000000000000002 |Train loss: 3.40901544|Test loss: 3.67227562\n","Epoch: 420 | Lr: 0.00100000000000000002 |Train loss: 3.40428187|Test loss: 3.64762060\n","Epoch: 421 | Lr: 0.00100000000000000002 |Train loss: 3.39957897|Test loss: 3.71282093\n","Epoch: 422 | Lr: 0.00100000000000000002 |Train loss: 3.40984420|Test loss: 3.73666954\n","Epoch: 423 | Lr: 0.00100000000000000002 |Train loss: 3.41607968|Test loss: 3.65507515\n","Epoch: 424 | Lr: 0.00100000000000000002 |Train loss: 3.42228723|Test loss: 3.67821431\n","Epoch: 425 | Lr: 0.00100000000000000002 |Train loss: 3.41695263|Test loss: 3.65653261\n","Epoch: 426 | Lr: 0.00100000000000000002 |Train loss: 3.41408322|Test loss: 3.65961798\n","Epoch: 427 | Lr: 0.00100000000000000002 |Train loss: 3.40787391|Test loss: 3.64845157\n","Epoch: 428 | Lr: 0.00100000000000000002 |Train loss: 3.40655382|Test loss: 3.64729675\n","Epoch: 429 | Lr: 0.00100000000000000002 |Train loss: 3.40812896|Test loss: 3.67473284\n","Epoch: 430 | Lr: 0.00100000000000000002 |Train loss: 3.41163894|Test loss: 3.70958130\n","Epoch: 431 | Lr: 0.00100000000000000002 |Train loss: 3.40424677|Test loss: 3.65211344\n","Epoch: 432 | Lr: 0.00100000000000000002 |Train loss: 3.41940498|Test loss: 3.68883419\n","Epoch: 433 | Lr: 0.00100000000000000002 |Train loss: 3.42109372|Test loss: 3.69942458\n","Epoch: 434 | Lr: 0.00100000000000000002 |Train loss: 3.41669834|Test loss: 3.66868854\n","Epoch: 435 | Lr: 0.00100000000000000002 |Train loss: 3.40904377|Test loss: 3.66640822\n","Epoch: 436 | Lr: 0.00100000000000000002 |Train loss: 3.40772847|Test loss: 3.65371259\n","Epoch: 437 | Lr: 0.00100000000000000002 |Train loss: 3.41041879|Test loss: 3.65509876\n","Epoch: 438 | Lr: 0.00100000000000000002 |Train loss: 3.40381173|Test loss: 3.64273993\n","Epoch: 439 | Lr: 0.00100000000000000002 |Train loss: 3.40407491|Test loss: 3.66318242\n","Epoch: 440 | Lr: 0.00100000000000000002 |Train loss: 3.40392560|Test loss: 3.64174247\n","Epoch: 441 | Lr: 0.00100000000000000002 |Train loss: 3.39716860|Test loss: 3.63951143\n","Epoch: 442 | Lr: 0.00100000000000000002 |Train loss: 3.39956073|Test loss: 3.64743948\n","Epoch: 443 | Lr: 0.00100000000000000002 |Train loss: 3.39516658|Test loss: 3.65402460\n","Epoch: 444 | Lr: 0.00100000000000000002 |Train loss: 3.39131250|Test loss: 3.65726344\n","Epoch: 445 | Lr: 0.00100000000000000002 |Train loss: 3.39094190|Test loss: 3.64652205\n","Epoch: 446 | Lr: 0.00100000000000000002 |Train loss: 3.39126350|Test loss: 3.64524682\n","Epoch: 447 | Lr: 0.00100000000000000002 |Train loss: 3.39565303|Test loss: 3.64443485\n","Epoch: 448 | Lr: 0.00100000000000000002 |Train loss: 3.39924828|Test loss: 3.66035104\n","Epoch: 449 | Lr: 0.00100000000000000002 |Train loss: 3.40032190|Test loss: 3.65214125\n","Epoch: 450 | Lr: 0.00100000000000000002 |Train loss: 3.40091656|Test loss: 3.63751690\n","Epoch: 451 | Lr: 0.00100000000000000002 |Train loss: 3.39977388|Test loss: 3.63966990\n","Epoch: 452 | Lr: 0.00100000000000000002 |Train loss: 3.40418579|Test loss: 3.64912534\n","Epoch: 453 | Lr: 0.00100000000000000002 |Train loss: 3.39155769|Test loss: 3.64648771\n","Epoch: 454 | Lr: 0.00100000000000000002 |Train loss: 3.40089293|Test loss: 3.65717157\n","Epoch: 455 | Lr: 0.00100000000000000002 |Train loss: 3.38919463|Test loss: 3.65282671\n","Epoch: 456 | Lr: 0.00100000000000000002 |Train loss: 3.39131180|Test loss: 3.70252593\n","Epoch: 457 | Lr: 0.00100000000000000002 |Train loss: 3.39460196|Test loss: 3.65137657\n","Epoch: 458 | Lr: 0.00100000000000000002 |Train loss: 3.38593688|Test loss: 3.63356527\n","Epoch: 459 | Lr: 0.00100000000000000002 |Train loss: 3.39394808|Test loss: 3.63816730\n","Epoch: 460 | Lr: 0.00100000000000000002 |Train loss: 3.40317140|Test loss: 3.66221937\n","Epoch: 461 | Lr: 0.00100000000000000002 |Train loss: 3.39047001|Test loss: 3.68721747\n","Epoch: 462 | Lr: 0.00100000000000000002 |Train loss: 3.38573921|Test loss: 3.66831589\n","Epoch: 463 | Lr: 0.00100000000000000002 |Train loss: 3.38742683|Test loss: 3.68030055\n","Epoch: 464 | Lr: 0.00100000000000000002 |Train loss: 3.40074821|Test loss: 3.65051166\n","Epoch: 465 | Lr: 0.00100000000000000002 |Train loss: 3.39941531|Test loss: 3.63997912\n","Epoch: 466 | Lr: 0.00100000000000000002 |Train loss: 3.40581816|Test loss: 3.65143577\n","Epoch: 467 | Lr: 0.00100000000000000002 |Train loss: 3.39531559|Test loss: 3.64440910\n","Epoch: 468 | Lr: 0.00100000000000000002 |Train loss: 3.40009534|Test loss: 3.63850419\n","Epoch: 469 | Lr: 0.00100000000000000002 |Train loss: 3.40387881|Test loss: 3.65979123\n","Epoch: 470 | Lr: 0.00100000000000000002 |Train loss: 3.41104458|Test loss: 3.67092164\n","Epoch: 471 | Lr: 0.00100000000000000002 |Train loss: 3.45330789|Test loss: 3.70317507\n","Epoch: 472 | Lr: 0.00100000000000000002 |Train loss: 3.40362569|Test loss: 3.77024523\n","Epoch: 473 | Lr: 0.00100000000000000002 |Train loss: 3.45615236|Test loss: 3.65830255\n","Epoch: 474 | Lr: 0.00100000000000000002 |Train loss: 3.41578430|Test loss: 3.64795009\n","Epoch: 475 | Lr: 0.00100000000000000002 |Train loss: 3.40695824|Test loss: 3.65957753\n","Epoch: 476 | Lr: 0.00100000000000000002 |Train loss: 3.40253083|Test loss: 3.66508786\n","Epoch: 477 | Lr: 0.00100000000000000002 |Train loss: 3.39961129|Test loss: 3.64960082\n","Epoch: 478 | Lr: 0.00100000000000000002 |Train loss: 3.39466379|Test loss: 3.66082597\n","Epoch: 479 | Lr: 0.00100000000000000002 |Train loss: 3.39477426|Test loss: 3.64560191\n","Epoch: 480 | Lr: 0.00100000000000000002 |Train loss: 3.39449604|Test loss: 3.66726073\n","Epoch: 481 | Lr: 0.00100000000000000002 |Train loss: 3.39551739|Test loss: 3.67304897\n","Epoch: 482 | Lr: 0.00100000000000000002 |Train loss: 3.38905511|Test loss: 3.64393973\n","Epoch: 483 | Lr: 0.00100000000000000002 |Train loss: 3.38062620|Test loss: 3.64689302\n","Epoch: 484 | Lr: 0.00100000000000000002 |Train loss: 3.37532520|Test loss: 3.64077393\n","Epoch: 485 | Lr: 0.00100000000000000002 |Train loss: 3.38773781|Test loss: 3.65428313\n","Epoch: 486 | Lr: 0.00100000000000000002 |Train loss: 3.38410318|Test loss: 3.66186706\n","Epoch: 487 | Lr: 0.00100000000000000002 |Train loss: 3.39770144|Test loss: 3.65425531\n","Epoch: 488 | Lr: 0.00100000000000000002 |Train loss: 3.39813662|Test loss: 3.64984870\n","Epoch: 489 | Lr: 0.00100000000000000002 |Train loss: 3.39032809|Test loss: 3.83342091\n","Epoch: 490 | Lr: 0.00100000000000000002 |Train loss: 3.39815221|Test loss: 3.66654452\n","Epoch: 491 | Lr: 0.00100000000000000002 |Train loss: 3.41153131|Test loss: 3.65652855\n","Epoch: 492 | Lr: 0.00100000000000000002 |Train loss: 3.43272535|Test loss: 3.68864862\n","Epoch: 493 | Lr: 0.00100000000000000002 |Train loss: 3.43162497|Test loss: 3.68362610\n","Epoch: 494 | Lr: 0.00100000000000000002 |Train loss: 3.39265780|Test loss: 3.64860900\n","Epoch: 495 | Lr: 0.00100000000000000002 |Train loss: 3.38042456|Test loss: 3.66520675\n","Epoch: 496 | Lr: 0.00100000000000000002 |Train loss: 3.38910111|Test loss: 3.66457081\n","Epoch: 497 | Lr: 0.00100000000000000002 |Train loss: 3.37877045|Test loss: 3.67954055\n","Epoch: 498 | Lr: 0.00100000000000000002 |Train loss: 3.38690172|Test loss: 3.63656060\n","Epoch: 499 | Lr: 0.00100000000000000002 |Train loss: 3.38662221|Test loss: 3.72834524\n","Epoch: 500 | Lr: 0.00100000000000000002 |Train loss: 3.38088206|Test loss: 3.70043238\n","Epoch: 501 | Lr: 0.00100000000000000002 |Train loss: 3.37984029|Test loss: 3.72439559\n","Epoch: 502 | Lr: 0.00100000000000000002 |Train loss: 3.41021003|Test loss: 3.64649431\n","Epoch: 503 | Lr: 0.00100000000000000002 |Train loss: 3.39640754|Test loss: 3.67330591\n","Epoch: 504 | Lr: 0.00100000000000000002 |Train loss: 3.39198061|Test loss: 3.65511680\n","Epoch: 505 | Lr: 0.00100000000000000002 |Train loss: 3.36882633|Test loss: 3.67248257\n","Epoch: 506 | Lr: 0.00100000000000000002 |Train loss: 3.36706567|Test loss: 3.64936360\n","Epoch: 507 | Lr: 0.00100000000000000002 |Train loss: 3.37928194|Test loss: 3.65725549\n","Epoch: 508 | Lr: 0.00100000000000000002 |Train loss: 3.38064222|Test loss: 3.72909331\n","Epoch: 509 | Lr: 0.00100000000000000002 |Train loss: 3.37545298|Test loss: 3.77433228\n","Epoch: 510 | Lr: 0.00100000000000000002 |Train loss: 3.37884265|Test loss: 3.68475095\n","Epoch: 511 | Lr: 0.00100000000000000002 |Train loss: 3.37172057|Test loss: 3.68066223\n","Epoch: 512 | Lr: 0.00100000000000000002 |Train loss: 3.42724146|Test loss: 3.67412869\n","Epoch: 513 | Lr: 0.00100000000000000002 |Train loss: 3.40197666|Test loss: 3.69595432\n","Epoch: 514 | Lr: 0.00100000000000000002 |Train loss: 3.40227880|Test loss: 3.65753810\n","Epoch: 515 | Lr: 0.00100000000000000002 |Train loss: 3.38711943|Test loss: 3.63456511\n","Epoch: 516 | Lr: 0.00100000000000000002 |Train loss: 3.37723541|Test loss: 3.63162541\n","Epoch: 517 | Lr: 0.00100000000000000002 |Train loss: 3.37246720|Test loss: 3.64181900\n","Epoch: 518 | Lr: 0.00100000000000000002 |Train loss: 3.36034669|Test loss: 3.67162164\n","Epoch: 519 | Lr: 0.00100000000000000002 |Train loss: 3.34785463|Test loss: 3.76905163\n","Epoch: 520 | Lr: 0.00100000000000000002 |Train loss: 3.35438194|Test loss: 3.66709638\n","Epoch: 521 | Lr: 0.00100000000000000002 |Train loss: 3.34765216|Test loss: 3.71823104\n","Epoch: 522 | Lr: 0.00100000000000000002 |Train loss: 3.34818111|Test loss: 3.64269153\n","Epoch: 523 | Lr: 0.00100000000000000002 |Train loss: 3.35632976|Test loss: 3.70147292\n","Epoch: 524 | Lr: 0.00100000000000000002 |Train loss: 3.35278269|Test loss: 3.77009090\n","Epoch: 525 | Lr: 0.00100000000000000002 |Train loss: 3.39435341|Test loss: 3.70475904\n","Epoch: 526 | Lr: 0.00100000000000000002 |Train loss: 3.41211061|Test loss: 3.67358136\n","Epoch: 527 | Lr: 0.00100000000000000002 |Train loss: 3.41072526|Test loss: 3.66856345\n","Epoch: 528 | Lr: 0.00100000000000000002 |Train loss: 3.39960355|Test loss: 3.67697334\n","Epoch: 529 | Lr: 0.00100000000000000002 |Train loss: 3.39065530|Test loss: 3.66914336\n","Epoch: 530 | Lr: 0.00100000000000000002 |Train loss: 3.38804909|Test loss: 3.66525364\n","Epoch: 531 | Lr: 0.00100000000000000002 |Train loss: 3.38320871|Test loss: 3.65373270\n","Epoch: 532 | Lr: 0.00100000000000000002 |Train loss: 3.38513275|Test loss: 3.67290028\n","Epoch: 533 | Lr: 0.00100000000000000002 |Train loss: 3.38009389|Test loss: 3.65112853\n","Epoch: 534 | Lr: 0.00100000000000000002 |Train loss: 3.37316630|Test loss: 3.64515678\n","Epoch: 535 | Lr: 0.00100000000000000002 |Train loss: 3.36175770|Test loss: 3.64496764\n","Epoch: 536 | Lr: 0.00100000000000000002 |Train loss: 3.35427185|Test loss: 3.66036820\n","Epoch: 537 | Lr: 0.00100000000000000002 |Train loss: 3.33631980|Test loss: 3.65679399\n","Epoch: 538 | Lr: 0.00100000000000000002 |Train loss: 3.33864812|Test loss: 3.62435142\n","Epoch: 539 | Lr: 0.00100000000000000002 |Train loss: 3.33729190|Test loss: 3.68501488\n","Epoch: 540 | Lr: 0.00100000000000000002 |Train loss: 3.38609411|Test loss: 3.71289992\n","Epoch: 541 | Lr: 0.00100000000000000002 |Train loss: 3.39849538|Test loss: 3.68347430\n","Epoch: 542 | Lr: 0.00100000000000000002 |Train loss: 3.39728630|Test loss: 3.68658837\n","Epoch: 543 | Lr: 0.00100000000000000002 |Train loss: 3.41445035|Test loss: 3.69159698\n","Epoch: 544 | Lr: 0.00100000000000000002 |Train loss: 3.40292531|Test loss: 4.29097239\n","Epoch: 545 | Lr: 0.00100000000000000002 |Train loss: 3.39289252|Test loss: 3.66442847\n","Epoch: 546 | Lr: 0.00100000000000000002 |Train loss: 3.42334598|Test loss: 3.66772596\n","Epoch: 547 | Lr: 0.00100000000000000002 |Train loss: 3.41220450|Test loss: 3.62557666\n","Epoch: 548 | Lr: 0.00100000000000000002 |Train loss: 3.36004978|Test loss: 3.63640340\n","Epoch: 549 | Lr: 0.00100000000000000002 |Train loss: 3.35106613|Test loss: 3.68858290\n","Epoch: 550 | Lr: 0.00100000000000000002 |Train loss: 3.34351830|Test loss: 3.63071497\n","Epoch: 551 | Lr: 0.00100000000000000002 |Train loss: 3.31393373|Test loss: 3.64744719\n","Epoch: 552 | Lr: 0.00100000000000000002 |Train loss: 3.36031983|Test loss: 3.65387837\n","Epoch: 553 | Lr: 0.00100000000000000002 |Train loss: 3.38290246|Test loss: 3.74281240\n","Epoch: 554 | Lr: 0.00100000000000000002 |Train loss: 3.37589373|Test loss: 3.77225264\n","Epoch: 555 | Lr: 0.00100000000000000002 |Train loss: 3.42022910|Test loss: 3.67359114\n","Epoch: 556 | Lr: 0.00100000000000000002 |Train loss: 3.40153029|Test loss: 3.66450167\n","Epoch: 557 | Lr: 0.00100000000000000002 |Train loss: 3.36713356|Test loss: 3.65208507\n","Epoch: 558 | Lr: 0.00100000000000000002 |Train loss: 3.36652199|Test loss: 3.62746787\n","Epoch: 559 | Lr: 0.00100000000000000002 |Train loss: 3.36253132|Test loss: 3.64552538\n","Epoch: 560 | Lr: 0.00100000000000000002 |Train loss: 3.35722729|Test loss: 3.64285620\n","Epoch: 561 | Lr: 0.00100000000000000002 |Train loss: 3.34415366|Test loss: 3.65562526\n","Epoch: 562 | Lr: 0.00100000000000000002 |Train loss: 3.35224803|Test loss: 3.64341195\n","Epoch: 563 | Lr: 0.00100000000000000002 |Train loss: 3.33205924|Test loss: 3.66332650\n","Epoch: 564 | Lr: 0.00100000000000000002 |Train loss: 3.34406213|Test loss: 3.73003872\n","Epoch: 565 | Lr: 0.00100000000000000002 |Train loss: 3.33769939|Test loss: 3.72269654\n","Epoch: 566 | Lr: 0.00100000000000000002 |Train loss: 3.36324008|Test loss: 3.66845671\n","Epoch: 567 | Lr: 0.00100000000000000002 |Train loss: 3.35060970|Test loss: 3.72945611\n","Epoch: 568 | Lr: 0.00100000000000000002 |Train loss: 3.34568679|Test loss: 3.68259915\n","Epoch: 569 | Lr: 0.00100000000000000002 |Train loss: 3.36679395|Test loss: 3.60874859\n","Epoch: 570 | Lr: 0.00100000000000000002 |Train loss: 3.36157238|Test loss: 3.65521407\n","Epoch: 571 | Lr: 0.00100000000000000002 |Train loss: 3.33962935|Test loss: 3.73193924\n","Epoch: 572 | Lr: 0.00100000000000000002 |Train loss: 3.32063613|Test loss: 3.70385003\n","Epoch: 573 | Lr: 0.00100000000000000002 |Train loss: 3.34640753|Test loss: 3.64299401\n","Epoch: 574 | Lr: 0.00100000000000000002 |Train loss: 3.35498605|Test loss: 3.61762778\n","Epoch: 575 | Lr: 0.00100000000000000002 |Train loss: 3.40378803|Test loss: 3.67209323\n","Epoch: 576 | Lr: 0.00100000000000000002 |Train loss: 3.36104800|Test loss: 3.64919472\n","Epoch: 577 | Lr: 0.00100000000000000002 |Train loss: 3.32594395|Test loss: 3.60041412\n","Epoch: 578 | Lr: 0.00100000000000000002 |Train loss: 3.31422079|Test loss: 3.62332368\n","Epoch: 579 | Lr: 0.00100000000000000002 |Train loss: 3.31962566|Test loss: 3.66495816\n","Epoch: 580 | Lr: 0.00100000000000000002 |Train loss: 3.29916666|Test loss: 3.73423823\n","Epoch: 581 | Lr: 0.00100000000000000002 |Train loss: 3.29550777|Test loss: 3.75778214\n","Epoch: 582 | Lr: 0.00100000000000000002 |Train loss: 3.30508018|Test loss: 3.69015416\n","Epoch: 583 | Lr: 0.00100000000000000002 |Train loss: 3.38940797|Test loss: 3.67727844\n","Epoch: 584 | Lr: 0.00100000000000000002 |Train loss: 3.37153945|Test loss: 3.68368689\n","Epoch: 585 | Lr: 0.00100000000000000002 |Train loss: 3.34200887|Test loss: 3.60023181\n","Epoch: 586 | Lr: 0.00100000000000000002 |Train loss: 3.35877617|Test loss: 3.62686785\n","Epoch: 587 | Lr: 0.00100000000000000002 |Train loss: 3.35075700|Test loss: 3.67872802\n","Epoch: 588 | Lr: 0.00100000000000000002 |Train loss: 3.29067985|Test loss: 3.64328472\n","Epoch: 589 | Lr: 0.00100000000000000002 |Train loss: 3.26192294|Test loss: 3.95032605\n","Epoch: 590 | Lr: 0.00100000000000000002 |Train loss: 3.26663897|Test loss: 3.61950572\n","Epoch: 591 | Lr: 0.00100000000000000002 |Train loss: 3.24386400|Test loss: 3.69223690\n","Epoch: 592 | Lr: 0.00100000000000000002 |Train loss: 3.26876710|Test loss: 3.64975985\n","Epoch: 593 | Lr: 0.00100000000000000002 |Train loss: 3.31855047|Test loss: 3.62882257\n","Epoch: 594 | Lr: 0.00100000000000000002 |Train loss: 3.26589111|Test loss: 3.68602904\n","Epoch: 595 | Lr: 0.00100000000000000002 |Train loss: 3.25480918|Test loss: 3.62862635\n","Epoch: 596 | Lr: 0.00100000000000000002 |Train loss: 3.27337464|Test loss: 3.59832692\n","Epoch: 597 | Lr: 0.00100000000000000002 |Train loss: 3.28897905|Test loss: 3.63020126\n","Epoch: 598 | Lr: 0.00100000000000000002 |Train loss: 3.28954051|Test loss: 3.63634419\n","Epoch: 599 | Lr: 0.00100000000000000002 |Train loss: 3.32276624|Test loss: 3.65413531\n","Epoch: 600 | Lr: 0.00100000000000000002 |Train loss: 3.30924706|Test loss: 3.64681212\n","Epoch: 601 | Lr: 0.00100000000000000002 |Train loss: 3.29696137|Test loss: 3.67289074\n","Epoch: 602 | Lr: 0.00100000000000000002 |Train loss: 3.28776739|Test loss: 3.67490625\n","Epoch: 603 | Lr: 0.00100000000000000002 |Train loss: 3.28252689|Test loss: 3.69616993\n","Epoch: 604 | Lr: 0.00100000000000000002 |Train loss: 3.25613407|Test loss: 3.72088424\n","Epoch: 605 | Lr: 0.00100000000000000002 |Train loss: 3.31924748|Test loss: 3.66387383\n","Epoch: 606 | Lr: 0.00100000000000000002 |Train loss: 3.28578514|Test loss: 3.77156766\n","Epoch: 607 | Lr: 0.00100000000000000002 |Train loss: 3.24022933|Test loss: 3.77748632\n","Epoch: 608 | Lr: 0.00100000000000000002 |Train loss: 3.48021130|Test loss: 3.64367874\n","Epoch: 609 | Lr: 0.00100000000000000002 |Train loss: 3.34860913|Test loss: 3.68992877\n","Epoch: 610 | Lr: 0.00100000000000000002 |Train loss: 3.34688207|Test loss: 3.70177730\n","Epoch: 611 | Lr: 0.00100000000000000002 |Train loss: 3.34023925|Test loss: 3.66707389\n","Epoch: 612 | Lr: 0.00100000000000000002 |Train loss: 3.32983398|Test loss: 3.70029434\n","Epoch: 613 | Lr: 0.00100000000000000002 |Train loss: 3.37638293|Test loss: 3.61949817\n","Epoch: 614 | Lr: 0.00100000000000000002 |Train loss: 3.38459742|Test loss: 3.63996991\n","Epoch: 615 | Lr: 0.00100000000000000002 |Train loss: 3.31911550|Test loss: 3.63332399\n","Epoch: 616 | Lr: 0.00100000000000000002 |Train loss: 3.26372027|Test loss: 3.71482666\n","Epoch: 617 | Lr: 0.00100000000000000002 |Train loss: 3.24241336|Test loss: 3.74533113\n","Epoch: 618 | Lr: 0.00100000000000000002 |Train loss: 3.30349747|Test loss: 3.73169351\n","Epoch: 619 | Lr: 0.00100000000000000002 |Train loss: 3.31649939|Test loss: 3.58812451\n","Epoch: 620 | Lr: 0.00100000000000000002 |Train loss: 3.32010126|Test loss: 3.60005554\n","Epoch: 621 | Lr: 0.00100000000000000002 |Train loss: 3.29790237|Test loss: 3.73183544\n","Epoch: 622 | Lr: 0.00100000000000000002 |Train loss: 3.25940589|Test loss: 3.63129187\n","Epoch: 623 | Lr: 0.00100000000000000002 |Train loss: 3.27752177|Test loss: 3.61948514\n","Epoch: 624 | Lr: 0.00100000000000000002 |Train loss: 3.24931981|Test loss: 3.59303761\n","Epoch: 625 | Lr: 0.00100000000000000002 |Train loss: 3.22163820|Test loss: 3.62488333\n","Epoch: 626 | Lr: 0.00100000000000000002 |Train loss: 3.24224033|Test loss: 3.62272843\n","Epoch: 627 | Lr: 0.00100000000000000002 |Train loss: 3.23198537|Test loss: 3.68080648\n","Epoch: 628 | Lr: 0.00100000000000000002 |Train loss: 3.20408636|Test loss: 3.85056090\n","Epoch: 629 | Lr: 0.00100000000000000002 |Train loss: 3.18548552|Test loss: 3.65280557\n","Epoch: 630 | Lr: 0.00100000000000000002 |Train loss: 3.21684319|Test loss: 3.79722953\n","Epoch: 631 | Lr: 0.00100000000000000002 |Train loss: 3.20332384|Test loss: 3.64976891\n","Epoch: 632 | Lr: 0.00100000000000000002 |Train loss: 3.22767154|Test loss: 3.57321350\n","Epoch: 633 | Lr: 0.00100000000000000002 |Train loss: 3.23007391|Test loss: 3.56995344\n","Epoch: 634 | Lr: 0.00100000000000000002 |Train loss: 3.23099230|Test loss: 3.65665150\n","Epoch: 635 | Lr: 0.00100000000000000002 |Train loss: 3.20711366|Test loss: 3.58624975\n","Epoch: 636 | Lr: 0.00100000000000000002 |Train loss: 3.21815151|Test loss: 3.61899869\n","Epoch: 637 | Lr: 0.00100000000000000002 |Train loss: 3.20943598|Test loss: 3.63411339\n","Epoch: 638 | Lr: 0.00100000000000000002 |Train loss: 3.21056831|Test loss: 3.62613281\n","Epoch: 639 | Lr: 0.00100000000000000002 |Train loss: 3.20119125|Test loss: 3.74245286\n","Epoch: 640 | Lr: 0.00100000000000000002 |Train loss: 3.18140167|Test loss: 4.03724146\n","Epoch: 641 | Lr: 0.00100000000000000002 |Train loss: 3.29495362|Test loss: 3.68239927\n","Epoch: 642 | Lr: 0.00100000000000000002 |Train loss: 3.30701496|Test loss: 3.68895737\n","Epoch: 643 | Lr: 0.00100000000000000002 |Train loss: 3.33649063|Test loss: 3.60695513\n","Epoch: 644 | Lr: 0.00100000000000000002 |Train loss: 3.31960358|Test loss: 3.63342746\n","Epoch: 645 | Lr: 0.00100000000000000002 |Train loss: 3.30110365|Test loss: 3.66318520\n","Epoch: 646 | Lr: 0.00100000000000000002 |Train loss: 3.36223940|Test loss: 3.68059468\n","Epoch: 647 | Lr: 0.00100000000000000002 |Train loss: 3.32236465|Test loss: 3.71371166\n","Epoch: 648 | Lr: 0.00100000000000000002 |Train loss: 3.22200602|Test loss: 3.62554415\n","Epoch: 649 | Lr: 0.00100000000000000002 |Train loss: 3.21670304|Test loss: 3.67454831\n","Epoch: 650 | Lr: 0.00100000000000000002 |Train loss: 3.19976519|Test loss: 3.66151587\n","Epoch: 651 | Lr: 0.00100000000000000002 |Train loss: 3.19112382|Test loss: 3.65425086\n","Epoch: 652 | Lr: 0.00100000000000000002 |Train loss: 3.26366087|Test loss: 3.60140959\n","Epoch: 653 | Lr: 0.00100000000000000002 |Train loss: 3.24907804|Test loss: 3.56558005\n","Epoch: 654 | Lr: 0.00100000000000000002 |Train loss: 3.22334156|Test loss: 3.59191736\n","Epoch: 655 | Lr: 0.00100000000000000002 |Train loss: 3.24896854|Test loss: 3.61636670\n","Epoch: 656 | Lr: 0.00100000000000000002 |Train loss: 3.40497539|Test loss: 3.71595867\n","Epoch: 657 | Lr: 0.00100000000000000002 |Train loss: 3.31513371|Test loss: 3.66446265\n","Epoch: 658 | Lr: 0.00100000000000000002 |Train loss: 3.17526960|Test loss: 3.61013945\n","Epoch: 659 | Lr: 0.00100000000000000002 |Train loss: 3.18187177|Test loss: 3.56312903\n","Epoch: 660 | Lr: 0.00100000000000000002 |Train loss: 3.20626360|Test loss: 3.58151444\n","Epoch: 661 | Lr: 0.00100000000000000002 |Train loss: 3.17652454|Test loss: 3.61323110\n","Epoch: 662 | Lr: 0.00100000000000000002 |Train loss: 3.20960867|Test loss: 3.64071361\n","Epoch: 663 | Lr: 0.00100000000000000002 |Train loss: 3.14485896|Test loss: 3.64348729\n","Epoch: 664 | Lr: 0.00100000000000000002 |Train loss: 3.16118578|Test loss: 3.71460660\n","Epoch: 665 | Lr: 0.00100000000000000002 |Train loss: 3.14163627|Test loss: 3.67734202\n","Epoch: 666 | Lr: 0.00100000000000000002 |Train loss: 3.16418217|Test loss: 3.64233653\n","Epoch: 667 | Lr: 0.00100000000000000002 |Train loss: 3.19811992|Test loss: 3.56747548\n","Epoch: 668 | Lr: 0.00100000000000000002 |Train loss: 3.16734489|Test loss: 3.57284347\n","Epoch: 669 | Lr: 0.00100000000000000002 |Train loss: 3.15078990|Test loss: 3.53650149\n","Epoch: 670 | Lr: 0.00100000000000000002 |Train loss: 3.15668478|Test loss: 3.60752829\n","Epoch: 671 | Lr: 0.00100000000000000002 |Train loss: 3.24028786|Test loss: 3.64698752\n","Epoch: 672 | Lr: 0.00100000000000000002 |Train loss: 3.19432781|Test loss: 3.70052155\n","Epoch: 673 | Lr: 0.00100000000000000002 |Train loss: 3.14785496|Test loss: 3.81056762\n","Epoch: 674 | Lr: 0.00100000000000000002 |Train loss: 3.11882500|Test loss: 3.71827014\n","Epoch: 675 | Lr: 0.00100000000000000002 |Train loss: 3.18597964|Test loss: 3.69161042\n","Epoch: 676 | Lr: 0.00100000000000000002 |Train loss: 3.19570591|Test loss: 3.55877908\n","Epoch: 677 | Lr: 0.00100000000000000002 |Train loss: 3.15176044|Test loss: 3.60509308\n","Epoch: 678 | Lr: 0.00100000000000000002 |Train loss: 3.15202848|Test loss: 3.57689834\n","Epoch: 679 | Lr: 0.00100000000000000002 |Train loss: 3.12607191|Test loss: 3.58955264\n","Epoch: 680 | Lr: 0.00100000000000000002 |Train loss: 3.12811659|Test loss: 3.58622392\n","Epoch: 681 | Lr: 0.00100000000000000002 |Train loss: 3.13731829|Test loss: 3.66327659\n","Epoch: 682 | Lr: 0.00100000000000000002 |Train loss: 3.09396793|Test loss: 3.65008696\n","Epoch: 683 | Lr: 0.00100000000000000002 |Train loss: 3.10245891|Test loss: 3.73369590\n","Epoch: 684 | Lr: 0.00100000000000000002 |Train loss: 3.18598284|Test loss: 3.72310090\n","Epoch: 685 | Lr: 0.00100000000000000002 |Train loss: 3.19792416|Test loss: 3.78205530\n","Epoch: 686 | Lr: 0.00100000000000000002 |Train loss: 3.23027720|Test loss: 3.69109797\n","Epoch: 687 | Lr: 0.00100000000000000002 |Train loss: 3.14177370|Test loss: 3.64191143\n","Epoch: 688 | Lr: 0.00100000000000000002 |Train loss: 3.13915040|Test loss: 3.59527461\n","Epoch: 689 | Lr: 0.00100000000000000002 |Train loss: 3.18891617|Test loss: 3.57632669\n","Epoch: 690 | Lr: 0.00100000000000000002 |Train loss: 3.17765476|Test loss: 3.64072132\n","Epoch: 691 | Lr: 0.00100000000000000002 |Train loss: 3.19108991|Test loss: 3.67912237\n","Epoch: 692 | Lr: 0.00100000000000000002 |Train loss: 3.15423614|Test loss: 3.70499659\n","Epoch: 693 | Lr: 0.00100000000000000002 |Train loss: 3.14469234|Test loss: 3.69347882\n","Epoch: 694 | Lr: 0.00100000000000000002 |Train loss: 3.21041117|Test loss: 3.77510635\n","Epoch: 695 | Lr: 0.00100000000000000002 |Train loss: 3.16485639|Test loss: 3.67923315\n","Epoch: 696 | Lr: 0.00100000000000000002 |Train loss: 3.17634223|Test loss: 3.63096547\n","Epoch: 697 | Lr: 0.00100000000000000002 |Train loss: 3.23752040|Test loss: 3.56605999\n","Epoch: 698 | Lr: 0.00100000000000000002 |Train loss: 3.23478866|Test loss: 3.64655781\n","Epoch: 699 | Lr: 0.00100000000000000002 |Train loss: 3.23629884|Test loss: 3.65471474\n","Epoch: 700 | Lr: 0.00100000000000000002 |Train loss: 3.23628940|Test loss: 3.76453169\n","Epoch: 701 | Lr: 0.00100000000000000002 |Train loss: 3.12595447|Test loss: 3.77230811\n","Epoch: 702 | Lr: 0.00100000000000000002 |Train loss: 3.12504900|Test loss: 3.62865305\n","Epoch: 703 | Lr: 0.00100000000000000002 |Train loss: 3.30745163|Test loss: 3.57983049\n","Epoch: 704 | Lr: 0.00100000000000000002 |Train loss: 3.14326167|Test loss: 3.60029165\n","Epoch: 705 | Lr: 0.00100000000000000002 |Train loss: 3.14777792|Test loss: 3.67527668\n","Epoch: 706 | Lr: 0.00100000000000000002 |Train loss: 3.11796761|Test loss: 3.59493200\n","Epoch: 707 | Lr: 0.00100000000000000002 |Train loss: 3.09608308|Test loss: 3.73510536\n","Epoch: 708 | Lr: 0.00100000000000000002 |Train loss: 3.16242222|Test loss: 3.55591448\n","Epoch: 709 | Lr: 0.00100000000000000002 |Train loss: 3.11708252|Test loss: 3.58855422\n","Epoch: 710 | Lr: 0.00100000000000000002 |Train loss: 3.11108883|Test loss: 3.60601123\n","Epoch: 711 | Lr: 0.00100000000000000002 |Train loss: 3.09102130|Test loss: 3.60152928\n","Epoch: 712 | Lr: 0.00100000000000000002 |Train loss: 3.06270329|Test loss: 3.72076265\n","Epoch: 713 | Lr: 0.00100000000000000002 |Train loss: 3.04088267|Test loss: 3.67154050\n","Epoch: 714 | Lr: 0.00100000000000000002 |Train loss: 3.11849097|Test loss: 3.55753803\n","Epoch: 715 | Lr: 0.00100000000000000002 |Train loss: 3.08732953|Test loss: 3.56994788\n","Epoch: 716 | Lr: 0.00100000000000000002 |Train loss: 3.11532132|Test loss: 3.58805943\n","Epoch: 717 | Lr: 0.00100000000000000002 |Train loss: 3.07449496|Test loss: 3.60581565\n","Epoch: 718 | Lr: 0.00100000000000000002 |Train loss: 3.07626830|Test loss: 3.78147125\n","Epoch: 719 | Lr: 0.00100000000000000002 |Train loss: 3.11205902|Test loss: 3.66136535\n","Epoch: 720 | Lr: 0.00100000000000000002 |Train loss: 3.07365994|Test loss: 3.65737589\n","Epoch: 721 | Lr: 0.00100000000000000002 |Train loss: 3.11251140|Test loss: 3.55945627\n","Epoch: 722 | Lr: 0.00100000000000000002 |Train loss: 3.13511010|Test loss: 3.68249400\n","Epoch: 723 | Lr: 0.00100000000000000002 |Train loss: 3.07538611|Test loss: 3.70286226\n","Epoch: 724 | Lr: 0.00100000000000000002 |Train loss: 3.04514082|Test loss: 3.68316062\n","Epoch: 725 | Lr: 0.00100000000000000002 |Train loss: 3.06933335|Test loss: 3.68474166\n","Epoch: 726 | Lr: 0.00100000000000000002 |Train loss: 3.08743550|Test loss: 3.72366444\n","Epoch: 727 | Lr: 0.00100000000000000002 |Train loss: 3.14913112|Test loss: 3.74159630\n","Epoch: 728 | Lr: 0.00100000000000000002 |Train loss: 3.13793784|Test loss: 3.76018635\n","Epoch: 729 | Lr: 0.00100000000000000002 |Train loss: 3.15181688|Test loss: 3.55112378\n","Epoch: 730 | Lr: 0.00100000000000000002 |Train loss: 3.08101292|Test loss: 3.56469003\n","Epoch: 731 | Lr: 0.00100000000000000002 |Train loss: 3.11531103|Test loss: 3.62091398\n","Epoch: 732 | Lr: 0.00100000000000000002 |Train loss: 3.15035731|Test loss: 3.64725240\n","Epoch: 733 | Lr: 0.00100000000000000002 |Train loss: 3.15600896|Test loss: 3.75443498\n","Epoch: 734 | Lr: 0.00100000000000000002 |Train loss: 3.10018319|Test loss: 3.78805677\n","Epoch: 735 | Lr: 0.00100000000000000002 |Train loss: 3.10542649|Test loss: 3.60608824\n","Epoch: 736 | Lr: 0.00100000000000000002 |Train loss: 3.06652006|Test loss: 3.65422956\n","Epoch: 737 | Lr: 0.00100000000000000002 |Train loss: 3.09489584|Test loss: 3.59682536\n","Epoch: 738 | Lr: 0.00100000000000000002 |Train loss: 3.26304026|Test loss: 3.55863349\n","Epoch: 739 | Lr: 0.00100000000000000002 |Train loss: 3.16810987|Test loss: 3.56338739\n","Epoch: 740 | Lr: 0.00100000000000000002 |Train loss: 3.21657497|Test loss: 3.61428920\n","Epoch: 741 | Lr: 0.00100000000000000002 |Train loss: 3.17796302|Test loss: 3.79044906\n","Epoch: 742 | Lr: 0.00100000000000000002 |Train loss: 3.14698275|Test loss: 3.70729264\n","Epoch: 743 | Lr: 0.00100000000000000002 |Train loss: 3.31200969|Test loss: 3.60275030\n","Epoch: 744 | Lr: 0.00100000000000000002 |Train loss: 3.23137548|Test loss: 3.54799946\n","Epoch: 745 | Lr: 0.00100000000000000002 |Train loss: 3.23202240|Test loss: 3.72173134\n","Epoch: 746 | Lr: 0.00100000000000000002 |Train loss: 3.16864693|Test loss: 3.72679098\n","Epoch: 747 | Lr: 0.00100000000000000002 |Train loss: 3.08846347|Test loss: 3.65847301\n","Epoch: 748 | Lr: 0.00100000000000000002 |Train loss: 3.11083815|Test loss: 3.59617813\n","Epoch: 749 | Lr: 0.00100000000000000002 |Train loss: 3.09241879|Test loss: 3.62896887\n","Epoch: 750 | Lr: 0.00100000000000000002 |Train loss: 3.07699112|Test loss: 3.58979328\n","Epoch: 751 | Lr: 0.00100000000000000002 |Train loss: 3.13724981|Test loss: 3.55190452\n","Epoch: 752 | Lr: 0.00100000000000000002 |Train loss: 3.11426888|Test loss: 3.64724580\n","Epoch: 753 | Lr: 0.00100000000000000002 |Train loss: 3.12597934|Test loss: 3.64888732\n","Epoch: 754 | Lr: 0.00100000000000000002 |Train loss: 3.07503849|Test loss: 3.75456754\n","Epoch: 755 | Lr: 0.00100000000000000002 |Train loss: 3.05166662|Test loss: 3.63094004\n","Epoch: 756 | Lr: 0.00100000000000000002 |Train loss: 3.04131949|Test loss: 3.57679892\n","Epoch: 757 | Lr: 0.00100000000000000002 |Train loss: 3.12070115|Test loss: 3.58493638\n","Epoch: 758 | Lr: 0.00100000000000000002 |Train loss: 3.08554222|Test loss: 3.60712179\n","Epoch: 759 | Lr: 0.00100000000000000002 |Train loss: 3.09954999|Test loss: 3.61479576\n","Epoch: 760 | Lr: 0.00100000000000000002 |Train loss: 3.02823102|Test loss: 3.67584952\n","Epoch: 761 | Lr: 0.00100000000000000002 |Train loss: 3.01074231|Test loss: 3.80266897\n","Epoch: 762 | Lr: 0.00100000000000000002 |Train loss: 3.03952980|Test loss: 3.62024236\n","Epoch: 763 | Lr: 0.00100000000000000002 |Train loss: 3.12674586|Test loss: 3.53091550\n","Epoch: 764 | Lr: 0.00100000000000000002 |Train loss: 3.09317636|Test loss: 3.52530320\n","Epoch: 765 | Lr: 0.00100000000000000002 |Train loss: 3.09447839|Test loss: 3.67735553\n","Epoch: 766 | Lr: 0.00100000000000000002 |Train loss: 3.10320610|Test loss: 3.78741201\n","Epoch: 767 | Lr: 0.00100000000000000002 |Train loss: 3.07075512|Test loss: 3.82068721\n","Epoch: 768 | Lr: 0.00100000000000000002 |Train loss: 3.12389986|Test loss: 3.60324383\n","Epoch: 769 | Lr: 0.00100000000000000002 |Train loss: 3.15592599|Test loss: 3.62514591\n","Epoch: 770 | Lr: 0.00100000000000000002 |Train loss: 3.10317667|Test loss: 3.52767809\n","Epoch: 771 | Lr: 0.00100000000000000002 |Train loss: 3.14013171|Test loss: 3.69944692\n","Epoch: 772 | Lr: 0.00100000000000000002 |Train loss: 3.06146463|Test loss: 3.71190707\n","Epoch: 773 | Lr: 0.00100000000000000002 |Train loss: 3.03360707|Test loss: 3.61449782\n","Epoch: 774 | Lr: 0.00100000000000000002 |Train loss: 3.04325322|Test loss: 3.58800451\n","Epoch: 775 | Lr: 0.00100000000000000002 |Train loss: 3.05847065|Test loss: 3.61231279\n","Epoch: 776 | Lr: 0.00100000000000000002 |Train loss: 3.05706245|Test loss: 3.58115220\n","Epoch: 777 | Lr: 0.00100000000000000002 |Train loss: 3.02378166|Test loss: 3.65946651\n","Epoch: 778 | Lr: 0.00100000000000000002 |Train loss: 3.01535686|Test loss: 3.57976826\n","Epoch: 779 | Lr: 0.00100000000000000002 |Train loss: 3.03149295|Test loss: 3.56235170\n","Epoch: 780 | Lr: 0.00100000000000000002 |Train loss: 2.99201562|Test loss: 3.58077836\n","Epoch: 781 | Lr: 0.00100000000000000002 |Train loss: 2.99066873|Test loss: 3.57306862\n","Epoch: 782 | Lr: 0.00100000000000000002 |Train loss: 2.99902856|Test loss: 3.63073508\n","Epoch: 783 | Lr: 0.00100000000000000002 |Train loss: 2.97883993|Test loss: 3.68410190\n","Epoch: 784 | Lr: 0.00100000000000000002 |Train loss: 2.99152545|Test loss: 3.73812429\n","Epoch: 785 | Lr: 0.00100000000000000002 |Train loss: 2.97465773|Test loss: 3.73202316\n","Epoch: 786 | Lr: 0.00100000000000000002 |Train loss: 2.99337312|Test loss: 3.69385203\n","Epoch: 787 | Lr: 0.00100000000000000002 |Train loss: 3.09747565|Test loss: 3.59612592\n","Epoch: 788 | Lr: 0.00100000000000000002 |Train loss: 3.00023766|Test loss: 3.57828800\n","Epoch: 789 | Lr: 0.00100000000000000002 |Train loss: 3.02039337|Test loss: 3.65572349\n","Epoch: 790 | Lr: 0.00100000000000000002 |Train loss: 2.99366059|Test loss: 3.69889665\n","Epoch: 791 | Lr: 0.00100000000000000002 |Train loss: 3.00939645|Test loss: 3.72152058\n","Epoch: 792 | Lr: 0.00100000000000000002 |Train loss: 3.02243719|Test loss: 3.61690124\n","Epoch: 793 | Lr: 0.00100000000000000002 |Train loss: 3.01446464|Test loss: 3.56222296\n","Epoch: 794 | Lr: 0.00100000000000000002 |Train loss: 3.10533961|Test loss: 3.55531502\n","Epoch: 795 | Lr: 0.00100000000000000002 |Train loss: 3.07173659|Test loss: 3.55919099\n","Epoch: 796 | Lr: 0.00100000000000000002 |Train loss: 3.05178171|Test loss: 3.64162119\n","Epoch: 797 | Lr: 0.00100000000000000002 |Train loss: 3.03022293|Test loss: 3.70270149\n","Epoch: 798 | Lr: 0.00100000000000000002 |Train loss: 3.06125818|Test loss: 3.71414995\n","Epoch: 799 | Lr: 0.00100000000000000002 |Train loss: 3.06403605|Test loss: 3.58648197\n","Epoch: 800 | Lr: 0.00100000000000000002 |Train loss: 3.14192156|Test loss: 3.72296747\n","Epoch: 801 | Lr: 0.00100000000000000002 |Train loss: 2.99907770|Test loss: 3.61256878\n","Epoch: 802 | Lr: 0.00100000000000000002 |Train loss: 2.99802510|Test loss: 3.61495431\n","Epoch: 803 | Lr: 0.00100000000000000002 |Train loss: 2.97525537|Test loss: 3.67188120\n","Epoch: 804 | Lr: 0.00100000000000000002 |Train loss: 2.95282422|Test loss: 3.61835361\n","Epoch: 805 | Lr: 0.00100000000000000002 |Train loss: 2.94218574|Test loss: 3.69340920\n","Epoch: 806 | Lr: 0.00100000000000000002 |Train loss: 3.05048555|Test loss: 3.62885459\n","Epoch: 807 | Lr: 0.00100000000000000002 |Train loss: 3.04571923|Test loss: 3.60597897\n","Epoch: 808 | Lr: 0.00100000000000000002 |Train loss: 3.02681190|Test loss: 3.58359146\n","Epoch: 809 | Lr: 0.00100000000000000002 |Train loss: 3.02107648|Test loss: 3.58385380\n","Epoch: 810 | Lr: 0.00100000000000000002 |Train loss: 3.03673325|Test loss: 3.51226552\n","Epoch: 811 | Lr: 0.00100000000000000002 |Train loss: 3.09126951|Test loss: 3.68787726\n","Epoch: 812 | Lr: 0.00100000000000000002 |Train loss: 3.12152030|Test loss: 3.66612291\n","Epoch: 813 | Lr: 0.00100000000000000002 |Train loss: 3.06834273|Test loss: 3.73515034\n","Epoch: 814 | Lr: 0.00100000000000000002 |Train loss: 3.00803896|Test loss: 3.56553936\n","Epoch: 815 | Lr: 0.00100000000000000002 |Train loss: 3.00499203|Test loss: 3.66214172\n","Epoch: 816 | Lr: 0.00100000000000000002 |Train loss: 3.02483833|Test loss: 3.58992894\n","Epoch: 817 | Lr: 0.00100000000000000002 |Train loss: 3.01425912|Test loss: 3.63182616\n","Epoch: 818 | Lr: 0.00100000000000000002 |Train loss: 3.01911642|Test loss: 3.57901239\n","Epoch: 819 | Lr: 0.00100000000000000002 |Train loss: 2.96987806|Test loss: 3.60448043\n","Epoch: 820 | Lr: 0.00100000000000000002 |Train loss: 3.09822945|Test loss: 3.54466629\n","Epoch: 821 | Lr: 0.00100000000000000002 |Train loss: 3.03873424|Test loss: 3.60988712\n","Epoch: 822 | Lr: 0.00100000000000000002 |Train loss: 3.04917294|Test loss: 3.64944013\n","Epoch: 823 | Lr: 0.00100000000000000002 |Train loss: 3.01726868|Test loss: 3.66551232\n","Epoch: 824 | Lr: 0.00100000000000000002 |Train loss: 3.02628915|Test loss: 3.63992882\n","Epoch: 825 | Lr: 0.00100000000000000002 |Train loss: 3.06957179|Test loss: 3.62350599\n","Epoch: 826 | Lr: 0.00100000000000000002 |Train loss: 3.06085239|Test loss: 3.57731525\n","Epoch: 827 | Lr: 0.00100000000000000002 |Train loss: 3.03519388|Test loss: 3.56174413\n","Epoch: 828 | Lr: 0.00100000000000000002 |Train loss: 3.05592543|Test loss: 3.61588788\n","Epoch: 829 | Lr: 0.00100000000000000002 |Train loss: 3.10191429|Test loss: 3.62643401\n","Epoch: 830 | Lr: 0.00100000000000000002 |Train loss: 3.03004026|Test loss: 3.73556622\n","Epoch: 831 | Lr: 0.00100000000000000002 |Train loss: 3.09817113|Test loss: 3.56586591\n","Epoch: 832 | Lr: 0.00100000000000000002 |Train loss: 3.00219282|Test loss: 3.59839853\n","Epoch: 833 | Lr: 0.00100000000000000002 |Train loss: 3.00642794|Test loss: 3.54602917\n","Epoch: 834 | Lr: 0.00100000000000000002 |Train loss: 2.96699593|Test loss: 3.64019664\n","Epoch: 835 | Lr: 0.00100000000000000002 |Train loss: 2.95341192|Test loss: 3.72966456\n","Epoch: 836 | Lr: 0.00100000000000000002 |Train loss: 2.96496558|Test loss: 3.63361224\n","Epoch: 837 | Lr: 0.00100000000000000002 |Train loss: 2.96950201|Test loss: 3.72843687\n","Epoch: 838 | Lr: 0.00100000000000000002 |Train loss: 2.96940907|Test loss: 3.59011618\n","Epoch: 839 | Lr: 0.00100000000000000002 |Train loss: 2.96338791|Test loss: 3.60319972\n","Epoch: 840 | Lr: 0.00100000000000000002 |Train loss: 3.01147749|Test loss: 3.58593082\n","Epoch: 841 | Lr: 0.00100000000000000002 |Train loss: 3.02503989|Test loss: 3.72233574\n","Epoch: 842 | Lr: 0.00100000000000000002 |Train loss: 3.03863831|Test loss: 3.70906512\n","Epoch: 843 | Lr: 0.00100000000000000002 |Train loss: 3.04021267|Test loss: 3.70484503\n","Epoch: 844 | Lr: 0.00100000000000000002 |Train loss: 2.99436913|Test loss: 3.66576068\n","Epoch: 845 | Lr: 0.00100000000000000002 |Train loss: 3.00590789|Test loss: 3.58737270\n","Epoch: 846 | Lr: 0.00100000000000000002 |Train loss: 3.05230234|Test loss: 3.56109770\n","Epoch: 847 | Lr: 0.00100000000000000002 |Train loss: 3.08256787|Test loss: 3.60938303\n","Epoch: 848 | Lr: 0.00100000000000000002 |Train loss: 2.98804859|Test loss: 3.64377475\n","Epoch: 849 | Lr: 0.00100000000000000002 |Train loss: 3.00162260|Test loss: 3.67774185\n","Epoch: 850 | Lr: 0.00100000000000000002 |Train loss: 2.99430486|Test loss: 3.58837016\n","Epoch: 851 | Lr: 0.00100000000000000002 |Train loss: 3.04029274|Test loss: 3.58978629\n","Epoch: 852 | Lr: 0.00100000000000000002 |Train loss: 3.14838539|Test loss: 3.62537432\n","Epoch: 853 | Lr: 0.00100000000000000002 |Train loss: 3.14952570|Test loss: 3.60443958\n","Epoch: 854 | Lr: 0.00100000000000000002 |Train loss: 3.12423110|Test loss: 3.70048475\n","Epoch: 855 | Lr: 0.00100000000000000002 |Train loss: 3.04248116|Test loss: 3.99655215\n","Epoch: 856 | Lr: 0.00100000000000000002 |Train loss: 3.05889710|Test loss: 3.58721399\n","Epoch: 857 | Lr: 0.00100000000000000002 |Train loss: 2.99699314|Test loss: 3.61400565\n","Epoch: 858 | Lr: 0.00100000000000000002 |Train loss: 3.02308333|Test loss: 3.67049336\n","Epoch: 859 | Lr: 0.00100000000000000002 |Train loss: 3.05341244|Test loss: 3.55468011\n","Epoch: 860 | Lr: 0.00100000000000000002 |Train loss: 3.00769516|Test loss: 3.55068310\n","Epoch: 861 | Lr: 0.00100000000000000002 |Train loss: 3.15956485|Test loss: 3.71764771\n","Epoch: 862 | Lr: 0.00100000000000000002 |Train loss: 3.15225013|Test loss: 3.68349663\n","Epoch: 863 | Lr: 0.00100000000000000002 |Train loss: 3.01633813|Test loss: 3.67247279\n","Epoch: 864 | Lr: 0.00100000000000000002 |Train loss: 2.98082894|Test loss: 3.66810878\n","Epoch: 865 | Lr: 0.00100000000000000002 |Train loss: 2.98180477|Test loss: 3.57066027\n","Epoch: 866 | Lr: 0.00100000000000000002 |Train loss: 2.96097471|Test loss: 3.58142813\n","Epoch: 867 | Lr: 0.00100000000000000002 |Train loss: 2.94439143|Test loss: 3.56610982\n","Epoch: 868 | Lr: 0.00100000000000000002 |Train loss: 2.91890059|Test loss: 3.59154987\n","Epoch: 869 | Lr: 0.00100000000000000002 |Train loss: 2.94427490|Test loss: 3.57259854\n","Epoch: 870 | Lr: 0.00100000000000000002 |Train loss: 2.90756001|Test loss: 3.61626069\n","Epoch: 871 | Lr: 0.00100000000000000002 |Train loss: 2.92903864|Test loss: 3.62122663\n","Epoch: 872 | Lr: 0.00100000000000000002 |Train loss: 2.94821807|Test loss: 3.70941607\n","Epoch: 873 | Lr: 0.00100000000000000002 |Train loss: 2.95510928|Test loss: 3.79772131\n","Epoch: 874 | Lr: 0.00100000000000000002 |Train loss: 2.96461852|Test loss: 3.64874419\n","Epoch: 875 | Lr: 0.00100000000000000002 |Train loss: 3.04974381|Test loss: 3.58000771\n","Epoch: 876 | Lr: 0.00100000000000000002 |Train loss: 2.99595988|Test loss: 3.49540456\n","Epoch: 877 | Lr: 0.00100000000000000002 |Train loss: 2.96513756|Test loss: 3.61676669\n","Epoch: 878 | Lr: 0.00100000000000000002 |Train loss: 2.98526752|Test loss: 3.73982390\n","Epoch: 879 | Lr: 0.00100000000000000002 |Train loss: 2.98266170|Test loss: 3.62002746\n","Epoch: 880 | Lr: 0.00100000000000000002 |Train loss: 2.99096890|Test loss: 3.69153380\n","Epoch: 881 | Lr: 0.00100000000000000002 |Train loss: 2.94929663|Test loss: 4.28903333\n","Epoch: 882 | Lr: 0.00100000000000000002 |Train loss: 2.93821579|Test loss: 3.53560591\n","Epoch: 883 | Lr: 0.00100000000000000002 |Train loss: 2.99804187|Test loss: 3.59294343\n","Epoch: 884 | Lr: 0.00100000000000000002 |Train loss: 2.95023348|Test loss: 3.59782084\n","Epoch: 885 | Lr: 0.00100000000000000002 |Train loss: 2.99532918|Test loss: 3.62119675\n","Epoch: 886 | Lr: 0.00100000000000000002 |Train loss: 3.00924613|Test loss: 3.73446369\n","Epoch: 887 | Lr: 0.00100000000000000002 |Train loss: 3.02223323|Test loss: 3.65700809\n","Epoch: 888 | Lr: 0.00100000000000000002 |Train loss: 2.96242464|Test loss: 3.62349025\n","Epoch: 889 | Lr: 0.00100000000000000002 |Train loss: 2.97118396|Test loss: 3.59794044\n","Epoch: 890 | Lr: 0.00100000000000000002 |Train loss: 3.02949617|Test loss: 3.59171748\n","Epoch: 891 | Lr: 0.00100000000000000002 |Train loss: 3.10047358|Test loss: 3.52816900\n","Epoch: 892 | Lr: 0.00100000000000000002 |Train loss: 3.12633616|Test loss: 3.56664236\n","Epoch: 893 | Lr: 0.00100000000000000002 |Train loss: 3.08449020|Test loss: 3.65815910\n","Epoch: 894 | Lr: 0.00100000000000000002 |Train loss: 3.15094300|Test loss: 3.75068251\n","Epoch: 895 | Lr: 0.00100000000000000002 |Train loss: 3.08888972|Test loss: 3.63293616\n","Epoch: 896 | Lr: 0.00100000000000000002 |Train loss: 3.08369877|Test loss: 3.58669194\n","Epoch: 897 | Lr: 0.00100000000000000002 |Train loss: 3.00477620|Test loss: 3.68072279\n","Epoch: 898 | Lr: 0.00100000000000000002 |Train loss: 2.97216266|Test loss: 3.60666815\n","Epoch: 899 | Lr: 0.00100000000000000002 |Train loss: 3.01768363|Test loss: 3.50019399\n","Epoch: 900 | Lr: 0.00100000000000000002 |Train loss: 2.95562923|Test loss: 3.60255003\n","Epoch: 901 | Lr: 0.00100000000000000002 |Train loss: 2.99749207|Test loss: 3.69996413\n","Epoch: 902 | Lr: 0.00100000000000000002 |Train loss: 2.93209557|Test loss: 3.75243839\n","Epoch: 903 | Lr: 0.00100000000000000002 |Train loss: 2.96715625|Test loss: 3.59609405\n","Epoch: 904 | Lr: 0.00100000000000000002 |Train loss: 2.93690550|Test loss: 3.63802767\n","Epoch: 905 | Lr: 0.00100000000000000002 |Train loss: 2.90605400|Test loss: 3.66673168\n","Epoch: 906 | Lr: 0.00100000000000000002 |Train loss: 2.92090668|Test loss: 3.67965150\n","Epoch: 907 | Lr: 0.00100000000000000002 |Train loss: 2.95915912|Test loss: 3.69061542\n","Epoch: 908 | Lr: 0.00100000000000000002 |Train loss: 2.96194883|Test loss: 3.58061552\n","Epoch: 909 | Lr: 0.00100000000000000002 |Train loss: 2.99450570|Test loss: 3.51337934\n","Epoch: 910 | Lr: 0.00100000000000000002 |Train loss: 3.01906367|Test loss: 3.54575316\n","Epoch: 911 | Lr: 0.00100000000000000002 |Train loss: 2.93998826|Test loss: 3.57348450\n","Epoch: 912 | Lr: 0.00100000000000000002 |Train loss: 2.91186885|Test loss: 3.67095963\n","Epoch: 913 | Lr: 0.00100000000000000002 |Train loss: 2.91814633|Test loss: 3.77661657\n","Epoch: 914 | Lr: 0.00100000000000000002 |Train loss: 2.94072700|Test loss: 3.66539995\n","Epoch: 915 | Lr: 0.00100000000000000002 |Train loss: 2.92289297|Test loss: 3.71415170\n","Epoch: 916 | Lr: 0.00100000000000000002 |Train loss: 2.90227936|Test loss: 3.61209599\n","Epoch: 917 | Lr: 0.00100000000000000002 |Train loss: 2.97660273|Test loss: 3.53713115\n","Epoch: 918 | Lr: 0.00100000000000000002 |Train loss: 2.95636920|Test loss: 3.62413565\n","Epoch: 919 | Lr: 0.00100000000000000002 |Train loss: 2.95743835|Test loss: 3.68641448\n","Epoch: 920 | Lr: 0.00100000000000000002 |Train loss: 2.97555532|Test loss: 3.71011678\n","Epoch: 921 | Lr: 0.00100000000000000002 |Train loss: 2.97354015|Test loss: 3.60136382\n","Epoch: 922 | Lr: 0.00100000000000000002 |Train loss: 2.97947232|Test loss: 3.54092828\n","Epoch: 923 | Lr: 0.00100000000000000002 |Train loss: 2.99580038|Test loss: 3.60817369\n","Epoch: 924 | Lr: 0.00100000000000000002 |Train loss: 2.97319959|Test loss: 3.64539091\n","Epoch: 925 | Lr: 0.00100000000000000002 |Train loss: 2.99426041|Test loss: 3.70167740\n","Epoch: 926 | Lr: 0.00100000000000000002 |Train loss: 2.96906877|Test loss: 3.57424219\n","Epoch: 927 | Lr: 0.00100000000000000002 |Train loss: 3.00093532|Test loss: 3.48234304\n","Epoch: 928 | Lr: 0.00100000000000000002 |Train loss: 3.02328545|Test loss: 3.61862636\n","Epoch: 929 | Lr: 0.00100000000000000002 |Train loss: 3.00030792|Test loss: 3.81699268\n","Epoch: 930 | Lr: 0.00100000000000000002 |Train loss: 3.04147977|Test loss: 3.61214574\n","Epoch: 931 | Lr: 0.00100000000000000002 |Train loss: 3.01037860|Test loss: 3.62457267\n","Epoch: 932 | Lr: 0.00100000000000000002 |Train loss: 2.91040589|Test loss: 3.67556858\n","Epoch: 933 | Lr: 0.00100000000000000002 |Train loss: 3.00134738|Test loss: 3.52148350\n","Epoch: 934 | Lr: 0.00100000000000000002 |Train loss: 3.03631904|Test loss: 3.60008510\n","Epoch: 935 | Lr: 0.00100000000000000002 |Train loss: 2.97610738|Test loss: 3.63872544\n","Epoch: 936 | Lr: 0.00100000000000000002 |Train loss: 2.92553381|Test loss: 3.65908519\n","Epoch: 937 | Lr: 0.00100000000000000002 |Train loss: 2.93177682|Test loss: 3.61790903\n","Epoch: 938 | Lr: 0.00100000000000000002 |Train loss: 2.94511801|Test loss: 3.71688048\n","Epoch: 939 | Lr: 0.00100000000000000002 |Train loss: 2.98321589|Test loss: 3.60717519\n","Epoch: 940 | Lr: 0.00100000000000000002 |Train loss: 3.04857926|Test loss: 3.56478016\n","Epoch: 941 | Lr: 0.00100000000000000002 |Train loss: 2.92598132|Test loss: 3.59387310\n","Epoch: 942 | Lr: 0.00100000000000000002 |Train loss: 2.93582221|Test loss: 3.63238112\n","Epoch: 943 | Lr: 0.00100000000000000002 |Train loss: 2.93645531|Test loss: 3.53704691\n","Epoch: 944 | Lr: 0.00100000000000000002 |Train loss: 2.99692669|Test loss: 3.63248603\n","Epoch: 945 | Lr: 0.00100000000000000002 |Train loss: 2.91718249|Test loss: 3.55456726\n","Epoch: 946 | Lr: 0.00100000000000000002 |Train loss: 2.88606022|Test loss: 3.63979840\n","Epoch: 947 | Lr: 0.00100000000000000002 |Train loss: 2.87513463|Test loss: 3.63747756\n","Epoch: 948 | Lr: 0.00100000000000000002 |Train loss: 2.87548290|Test loss: 3.68651613\n","Epoch: 949 | Lr: 0.00100000000000000002 |Train loss: 2.89962020|Test loss: 3.70370309\n","Epoch: 950 | Lr: 0.00100000000000000002 |Train loss: 2.94539922|Test loss: 3.67334986\n","Epoch: 951 | Lr: 0.00100000000000000002 |Train loss: 2.97010275|Test loss: 3.48410900\n","Epoch: 952 | Lr: 0.00100000000000000002 |Train loss: 2.92356986|Test loss: 3.53583908\n","Epoch: 953 | Lr: 0.00100000000000000002 |Train loss: 2.97640224|Test loss: 3.66539359\n","Epoch: 954 | Lr: 0.00100000000000000002 |Train loss: 2.96152339|Test loss: 3.68561323\n","Epoch: 955 | Lr: 0.00100000000000000002 |Train loss: 2.98431776|Test loss: 3.86304808\n","Epoch: 956 | Lr: 0.00100000000000000002 |Train loss: 2.96481979|Test loss: 3.87069599\n","Epoch: 957 | Lr: 0.00100000000000000002 |Train loss: 2.95839681|Test loss: 3.56726964\n","Epoch: 958 | Lr: 0.00100000000000000002 |Train loss: 2.93493259|Test loss: 3.62019666\n","Epoch: 959 | Lr: 0.00100000000000000002 |Train loss: 2.96091459|Test loss: 3.63089252\n","Epoch: 960 | Lr: 0.00100000000000000002 |Train loss: 2.98018962|Test loss: 3.65139842\n","Epoch: 961 | Lr: 0.00100000000000000002 |Train loss: 3.01028385|Test loss: 3.59664671\n","Epoch: 962 | Lr: 0.00100000000000000002 |Train loss: 3.05468861|Test loss: 3.70685045\n","Epoch: 963 | Lr: 0.00100000000000000002 |Train loss: 3.08939864|Test loss: 3.85469937\n","Epoch: 964 | Lr: 0.00100000000000000002 |Train loss: 3.08324194|Test loss: 3.85774231\n","Epoch: 965 | Lr: 0.00100000000000000002 |Train loss: 3.02994138|Test loss: 3.60686374\n","Epoch: 966 | Lr: 0.00100000000000000002 |Train loss: 2.98969183|Test loss: 3.59005419\n","Epoch: 967 | Lr: 0.00100000000000000002 |Train loss: 3.00082153|Test loss: 3.50515167\n","Epoch: 968 | Lr: 0.00100000000000000002 |Train loss: 2.93941921|Test loss: 3.59434732\n","Epoch: 969 | Lr: 0.00100000000000000002 |Train loss: 2.92935463|Test loss: 3.65022143\n","Epoch: 970 | Lr: 0.00100000000000000002 |Train loss: 2.94473948|Test loss: 3.69937674\n","Epoch: 971 | Lr: 0.00100000000000000002 |Train loss: 2.92000337|Test loss: 3.56954900\n","Epoch: 972 | Lr: 0.00100000000000000002 |Train loss: 2.92689103|Test loss: 3.62904406\n","Epoch: 973 | Lr: 0.00100000000000000002 |Train loss: 2.93819696|Test loss: 3.72764182\n","Epoch: 974 | Lr: 0.00100000000000000002 |Train loss: 2.96624474|Test loss: 3.57925510\n","Epoch: 975 | Lr: 0.00100000000000000002 |Train loss: 2.92792153|Test loss: 3.55731344\n","Epoch: 976 | Lr: 0.00100000000000000002 |Train loss: 2.91867095|Test loss: 3.57625318\n","Epoch: 977 | Lr: 0.00100000000000000002 |Train loss: 2.87295961|Test loss: 3.58498549\n","Epoch: 978 | Lr: 0.00100000000000000002 |Train loss: 2.88029025|Test loss: 3.62831720\n","Epoch: 979 | Lr: 0.00100000000000000002 |Train loss: 2.88006963|Test loss: 3.62586562\n","Epoch: 980 | Lr: 0.00100000000000000002 |Train loss: 2.89408197|Test loss: 3.65784065\n","Epoch: 981 | Lr: 0.00100000000000000002 |Train loss: 2.89256787|Test loss: 3.55321646\n","Epoch: 982 | Lr: 0.00100000000000000002 |Train loss: 2.96555221|Test loss: 3.58606656\n","Epoch: 983 | Lr: 0.00100000000000000002 |Train loss: 2.92410070|Test loss: 3.58270558\n","Epoch: 984 | Lr: 0.00100000000000000002 |Train loss: 2.89865549|Test loss: 3.52347438\n","Epoch: 985 | Lr: 0.00100000000000000002 |Train loss: 2.91213679|Test loss: 3.56543628\n","Epoch: 986 | Lr: 0.00100000000000000002 |Train loss: 2.89467712|Test loss: 3.66754937\n","Epoch: 987 | Lr: 0.00100000000000000002 |Train loss: 2.90433097|Test loss: 3.63776000\n","Epoch: 988 | Lr: 0.00100000000000000002 |Train loss: 2.89120922|Test loss: 3.69620490\n","Epoch: 989 | Lr: 0.00100000000000000002 |Train loss: 2.88322586|Test loss: 3.60320115\n","Epoch: 990 | Lr: 0.00100000000000000002 |Train loss: 2.90410604|Test loss: 3.59862963\n","Epoch: 991 | Lr: 0.00100000000000000002 |Train loss: 2.91014715|Test loss: 3.65576037\n","Epoch: 992 | Lr: 0.00100000000000000002 |Train loss: 2.91987211|Test loss: 3.54792166\n","Epoch: 993 | Lr: 0.00100000000000000002 |Train loss: 2.93243579|Test loss: 3.59332363\n","Epoch: 994 | Lr: 0.00100000000000000002 |Train loss: 2.90544822|Test loss: 3.76697842\n","Epoch: 995 | Lr: 0.00100000000000000002 |Train loss: 2.96310951|Test loss: 3.80967538\n","Epoch: 996 | Lr: 0.00100000000000000002 |Train loss: 3.02366153|Test loss: 3.62081559\n","Epoch: 997 | Lr: 0.00100000000000000002 |Train loss: 2.90786113|Test loss: 3.57277528\n","Epoch: 998 | Lr: 0.00100000000000000002 |Train loss: 2.91601181|Test loss: 3.52253842\n","Epoch: 999 | Lr: 0.00100000000000000002 |Train loss: 2.91980386|Test loss: 3.53933040\n","Epoch: 1000 | Lr: 0.00100000000000000002 |Train loss: 2.88664212|Test loss: 3.59235565\n","\n","Training finished.\n","\n"]}]},{"cell_type":"code","source":["time_step = 5\n","feature_matrix = np.load('feature_matrix.npy')\n","corrlation = np.load('correlation_3.npy').astype(np.float32)\n","feature_matrix,target = normalization(feature_matrix)\n","feature_matrix = torch.tensor(feature_matrix.astype(np.float32))\n","adj = torch.tensor(corrlation)\n","target = torch.tensor(target.astype(np.float32))\n","features, results = get_features(time_step, feature_matrix)\n","train_idx = int(0.8*features.shape[0])\n","train_feature, train_result = features[:train_idx,:,:], results[:train_idx,:,:]\n","test_feature, test_result = features[train_idx:,:,:], results[train_idx:,:,:]"],"metadata":{"id":"VhmBHPJt9Uy6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_val_loss = np.inf\n","epochs = 1000\n","train_mean, test_mean = np.zeros((epochs,1)), np.zeros((epochs,1))\n","model = Generator(time_step*5+50, 32, 1).to(device)#time_step*5: feature nums, 32: hid layer, 1:output\n","loss = nn.MSELoss()\n","optimizer = optim.AdamW(model.parameters(),lr=0.001)\n","for epoch in tqdm_notebook(range(1,epochs + 1)):\n","    train_mean_loss, test_mean_loss, n, n1 = np.zeros((train_feature.shape[0],1)), np.zeros((test_feature.shape[0],1)), train_feature.shape[0], test_feature.shape[0]\n","    for i in range(n):\n","      #train_loss\n","      noise = torch.randn(train_feature.shape[1], 50)\n","      noise = torch.concat([noise, train_feature[i]], dim = 1) \n","      train = model(noise, adj)\n","      train_loss = loss(train, train_result[i])\n","      optimizer.zero_grad()\n","      train_loss.backward()\n","      optimizer.step()\n","      train_mean_loss[i] = train_loss.detach().numpy()\n","    for i in range(n1):\n","      noise2 = torch.randn(test_feature.shape[1], 50)\n","      noise2 = torch.concat([noise2, test_feature[i]], dim = 1)\n","      test = model(noise2, adj)\n","      test_loss = loss(test, test_result[i])\n","      test_mean_loss[i] = test_loss.detach().numpy()\n","    train_mean[epoch - 1], test_mean[epoch - 1] = train_mean_loss.mean(), test_mean_loss.mean()\n","    if mean_loss.mean() < min_val_loss:\n","      min_val_loss = mean_loss.mean()\n","    print('Epoch: {:03d} | Lr: {:.20f} |Train loss: {:.8f}|Test loss: {:.8f}'.\\\n","          format(epoch, optimizer.param_groups[0]['lr'], train_mean_loss.mean(), test_mean_loss.mean()))\n","print('\\nTraining finished.\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5c89dceade5041c4a34a94bd0ae7ff2e","fdbf436f106a48998d068ac87f27573b","dd5e54ab6780419ea8382d9759921852","39c52ff617294765a370b3418a6c529d","05f46b466d284136b27c3f91cff98c7e","444e15748de94d8e8e3c17947cc26c9b","d666a07d2fed4a19b752120c605df381","cccc02302d6641ed8e32d106ae535172","1c82233f30944cd2a6abc9ca09375fb3","0969f7cd943a4a58bf0182507b90d2d4","134d00fd82df4c1f984db033b19d0883"]},"id":"IasTuZo69afI","executionInfo":{"status":"ok","timestamp":1661112377637,"user_tz":240,"elapsed":457468,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"1afd5c42-ec1d-4c26-b942-c903b101ac25"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c89dceade5041c4a34a94bd0ae7ff2e"},"application/json":{"n":0,"total":1000,"elapsed":0.04833483695983887,"ncols":null,"nrows":null,"prefix":"","ascii":false,"unit":"it","unit_scale":false,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1000,"initial":0,"colour":null}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 11.93812346|Test loss: 6.93893401\n","Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 5.82775386|Test loss: 4.37393236\n","Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 4.81486468|Test loss: 4.13268280\n","Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 4.30982951|Test loss: 4.36534230\n","Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 4.14970404|Test loss: 4.25343068\n","Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 3.98158433|Test loss: 3.95898382\n","Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 3.88774673|Test loss: 3.93560743\n","Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 3.87434989|Test loss: 3.92863250\n","Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 3.87259175|Test loss: 3.90473167\n","Epoch: 010 | Lr: 0.00100000000000000002 |Train loss: 3.81497693|Test loss: 3.95709403\n","Epoch: 011 | Lr: 0.00100000000000000002 |Train loss: 3.78958639|Test loss: 3.96635540\n","Epoch: 012 | Lr: 0.00100000000000000002 |Train loss: 3.79875334|Test loss: 3.86682399\n","Epoch: 013 | Lr: 0.00100000000000000002 |Train loss: 3.82492965|Test loss: 3.85076936\n","Epoch: 014 | Lr: 0.00100000000000000002 |Train loss: 3.83010165|Test loss: 3.87033367\n","Epoch: 015 | Lr: 0.00100000000000000002 |Train loss: 3.73513087|Test loss: 3.87501351\n","Epoch: 016 | Lr: 0.00100000000000000002 |Train loss: 3.77060326|Test loss: 3.92445048\n","Epoch: 017 | Lr: 0.00100000000000000002 |Train loss: 3.74655267|Test loss: 3.85149892\n","Epoch: 018 | Lr: 0.00100000000000000002 |Train loss: 3.74853454|Test loss: 3.83313998\n","Epoch: 019 | Lr: 0.00100000000000000002 |Train loss: 3.71837427|Test loss: 3.87615172\n","Epoch: 020 | Lr: 0.00100000000000000002 |Train loss: 3.68191455|Test loss: 3.82437269\n","Epoch: 021 | Lr: 0.00100000000000000002 |Train loss: 3.67174238|Test loss: 3.95915675\n","Epoch: 022 | Lr: 0.00100000000000000002 |Train loss: 3.66463451|Test loss: 3.79861259\n","Epoch: 023 | Lr: 0.00100000000000000002 |Train loss: 3.65989421|Test loss: 3.79752692\n","Epoch: 024 | Lr: 0.00100000000000000002 |Train loss: 3.67298426|Test loss: 3.80705516\n","Epoch: 025 | Lr: 0.00100000000000000002 |Train loss: 3.68369220|Test loss: 3.84437450\n","Epoch: 026 | Lr: 0.00100000000000000002 |Train loss: 3.63698628|Test loss: 3.79912988\n","Epoch: 027 | Lr: 0.00100000000000000002 |Train loss: 3.63091538|Test loss: 3.80626702\n","Epoch: 028 | Lr: 0.00100000000000000002 |Train loss: 3.63087219|Test loss: 3.78011425\n","Epoch: 029 | Lr: 0.00100000000000000002 |Train loss: 3.62345117|Test loss: 3.84672936\n","Epoch: 030 | Lr: 0.00100000000000000002 |Train loss: 3.62231354|Test loss: 3.78214176\n","Epoch: 031 | Lr: 0.00100000000000000002 |Train loss: 3.61373788|Test loss: 3.75453575\n","Epoch: 032 | Lr: 0.00100000000000000002 |Train loss: 3.61208129|Test loss: 3.82832797\n","Epoch: 033 | Lr: 0.00100000000000000002 |Train loss: 3.61794923|Test loss: 3.79044088\n","Epoch: 034 | Lr: 0.00100000000000000002 |Train loss: 3.63149351|Test loss: 3.75341407\n","Epoch: 035 | Lr: 0.00100000000000000002 |Train loss: 3.62612255|Test loss: 3.85874502\n","Epoch: 036 | Lr: 0.00100000000000000002 |Train loss: 3.64949085|Test loss: 3.82029549\n","Epoch: 037 | Lr: 0.00100000000000000002 |Train loss: 3.60006013|Test loss: 3.81041265\n","Epoch: 038 | Lr: 0.00100000000000000002 |Train loss: 3.61894854|Test loss: 3.79589740\n","Epoch: 039 | Lr: 0.00100000000000000002 |Train loss: 3.62658135|Test loss: 3.76158460\n","Epoch: 040 | Lr: 0.00100000000000000002 |Train loss: 3.60495339|Test loss: 3.72830073\n","Epoch: 041 | Lr: 0.00100000000000000002 |Train loss: 3.61411975|Test loss: 3.78446460\n","Epoch: 042 | Lr: 0.00100000000000000002 |Train loss: 3.62001495|Test loss: 3.81500483\n","Epoch: 043 | Lr: 0.00100000000000000002 |Train loss: 3.60498734|Test loss: 3.90011152\n","Epoch: 044 | Lr: 0.00100000000000000002 |Train loss: 3.59357701|Test loss: 3.72323998\n","Epoch: 045 | Lr: 0.00100000000000000002 |Train loss: 3.56547159|Test loss: 3.74032338\n","Epoch: 046 | Lr: 0.00100000000000000002 |Train loss: 3.57645446|Test loss: 3.71430286\n","Epoch: 047 | Lr: 0.00100000000000000002 |Train loss: 3.54669368|Test loss: 3.72172149\n","Epoch: 048 | Lr: 0.00100000000000000002 |Train loss: 3.55802137|Test loss: 3.73010627\n","Epoch: 049 | Lr: 0.00100000000000000002 |Train loss: 3.52148632|Test loss: 3.72761456\n","Epoch: 050 | Lr: 0.00100000000000000002 |Train loss: 3.55030290|Test loss: 3.69749228\n","Epoch: 051 | Lr: 0.00100000000000000002 |Train loss: 3.54756971|Test loss: 3.74518458\n","Epoch: 052 | Lr: 0.00100000000000000002 |Train loss: 3.54709127|Test loss: 3.71415750\n","Epoch: 053 | Lr: 0.00100000000000000002 |Train loss: 3.55531812|Test loss: 3.76891883\n","Epoch: 054 | Lr: 0.00100000000000000002 |Train loss: 3.56234767|Test loss: 3.78854386\n","Epoch: 055 | Lr: 0.00100000000000000002 |Train loss: 3.56561355|Test loss: 3.82015133\n","Epoch: 056 | Lr: 0.00100000000000000002 |Train loss: 3.51486164|Test loss: 3.68035865\n","Epoch: 057 | Lr: 0.00100000000000000002 |Train loss: 3.51740813|Test loss: 3.73440091\n","Epoch: 058 | Lr: 0.00100000000000000002 |Train loss: 3.52497192|Test loss: 3.66622798\n","Epoch: 059 | Lr: 0.00100000000000000002 |Train loss: 3.51424507|Test loss: 3.78286322\n","Epoch: 060 | Lr: 0.00100000000000000002 |Train loss: 3.50773396|Test loss: 3.78210219\n","Epoch: 061 | Lr: 0.00100000000000000002 |Train loss: 3.47225809|Test loss: 3.66789786\n","Epoch: 062 | Lr: 0.00100000000000000002 |Train loss: 3.46684506|Test loss: 3.74744081\n","Epoch: 063 | Lr: 0.00100000000000000002 |Train loss: 3.47300303|Test loss: 3.65630905\n","Epoch: 064 | Lr: 0.00100000000000000002 |Train loss: 3.47864238|Test loss: 3.68705416\n","Epoch: 065 | Lr: 0.00100000000000000002 |Train loss: 3.49732067|Test loss: 3.70023727\n","Epoch: 066 | Lr: 0.00100000000000000002 |Train loss: 3.51838388|Test loss: 3.77008009\n","Epoch: 067 | Lr: 0.00100000000000000002 |Train loss: 3.46649893|Test loss: 3.65071948\n","Epoch: 068 | Lr: 0.00100000000000000002 |Train loss: 3.47387975|Test loss: 3.65794818\n","Epoch: 069 | Lr: 0.00100000000000000002 |Train loss: 3.48399341|Test loss: 3.68923028\n","Epoch: 070 | Lr: 0.00100000000000000002 |Train loss: 3.47821089|Test loss: 3.64244938\n","Epoch: 071 | Lr: 0.00100000000000000002 |Train loss: 3.52765137|Test loss: 3.86218913\n","Epoch: 072 | Lr: 0.00100000000000000002 |Train loss: 3.51651442|Test loss: 3.86445149\n","Epoch: 073 | Lr: 0.00100000000000000002 |Train loss: 3.49100904|Test loss: 3.66459163\n","Epoch: 074 | Lr: 0.00100000000000000002 |Train loss: 3.45706566|Test loss: 3.62668713\n","Epoch: 075 | Lr: 0.00100000000000000002 |Train loss: 3.46036069|Test loss: 3.62799978\n","Epoch: 076 | Lr: 0.00100000000000000002 |Train loss: 3.42118108|Test loss: 3.63525414\n","Epoch: 077 | Lr: 0.00100000000000000002 |Train loss: 3.41647857|Test loss: 3.68812919\n","Epoch: 078 | Lr: 0.00100000000000000002 |Train loss: 3.48499248|Test loss: 3.77483145\n","Epoch: 079 | Lr: 0.00100000000000000002 |Train loss: 3.46029405|Test loss: 3.65798918\n","Epoch: 080 | Lr: 0.00100000000000000002 |Train loss: 3.42763005|Test loss: 3.59465313\n","Epoch: 081 | Lr: 0.00100000000000000002 |Train loss: 3.46948912|Test loss: 3.67130542\n","Epoch: 082 | Lr: 0.00100000000000000002 |Train loss: 3.43393040|Test loss: 3.61090000\n","Epoch: 083 | Lr: 0.00100000000000000002 |Train loss: 3.43208426|Test loss: 3.66560904\n","Epoch: 084 | Lr: 0.00100000000000000002 |Train loss: 3.41057158|Test loss: 3.62971361\n","Epoch: 085 | Lr: 0.00100000000000000002 |Train loss: 3.41032704|Test loss: 3.60358659\n","Epoch: 086 | Lr: 0.00100000000000000002 |Train loss: 3.40462200|Test loss: 3.62230062\n","Epoch: 087 | Lr: 0.00100000000000000002 |Train loss: 3.39234936|Test loss: 3.59102996\n","Epoch: 088 | Lr: 0.00100000000000000002 |Train loss: 3.37705644|Test loss: 3.62709006\n","Epoch: 089 | Lr: 0.00100000000000000002 |Train loss: 3.44308434|Test loss: 3.64304622\n","Epoch: 090 | Lr: 0.00100000000000000002 |Train loss: 3.38055038|Test loss: 3.62730972\n","Epoch: 091 | Lr: 0.00100000000000000002 |Train loss: 3.37267460|Test loss: 3.58856996\n","Epoch: 092 | Lr: 0.00100000000000000002 |Train loss: 3.38184116|Test loss: 3.58899919\n","Epoch: 093 | Lr: 0.00100000000000000002 |Train loss: 3.34845845|Test loss: 3.59727200\n","Epoch: 094 | Lr: 0.00100000000000000002 |Train loss: 3.35568027|Test loss: 3.56942574\n","Epoch: 095 | Lr: 0.00100000000000000002 |Train loss: 3.40627100|Test loss: 3.64696964\n","Epoch: 096 | Lr: 0.00100000000000000002 |Train loss: 3.38057347|Test loss: 3.64629745\n","Epoch: 097 | Lr: 0.00100000000000000002 |Train loss: 3.38221296|Test loss: 3.70267876\n","Epoch: 098 | Lr: 0.00100000000000000002 |Train loss: 3.41167168|Test loss: 3.64858890\n","Epoch: 099 | Lr: 0.00100000000000000002 |Train loss: 3.38237413|Test loss: 3.58415357\n","Epoch: 100 | Lr: 0.00100000000000000002 |Train loss: 3.42784526|Test loss: 3.61384519\n","Epoch: 101 | Lr: 0.00100000000000000002 |Train loss: 3.37520607|Test loss: 3.59087737\n","Epoch: 102 | Lr: 0.00100000000000000002 |Train loss: 3.34065628|Test loss: 3.58766246\n","Epoch: 103 | Lr: 0.00100000000000000002 |Train loss: 3.38449140|Test loss: 3.66167720\n","Epoch: 104 | Lr: 0.00100000000000000002 |Train loss: 3.37828712|Test loss: 3.67821932\n","Epoch: 105 | Lr: 0.00100000000000000002 |Train loss: 3.38292881|Test loss: 3.56423958\n","Epoch: 106 | Lr: 0.00100000000000000002 |Train loss: 3.40940126|Test loss: 3.63655472\n","Epoch: 107 | Lr: 0.00100000000000000002 |Train loss: 3.42860826|Test loss: 3.64519890\n","Epoch: 108 | Lr: 0.00100000000000000002 |Train loss: 3.37372055|Test loss: 3.63839006\n","Epoch: 109 | Lr: 0.00100000000000000002 |Train loss: 3.48084744|Test loss: 3.93094873\n","Epoch: 110 | Lr: 0.00100000000000000002 |Train loss: 3.40808511|Test loss: 3.66937399\n","Epoch: 111 | Lr: 0.00100000000000000002 |Train loss: 3.34725982|Test loss: 3.58234048\n","Epoch: 112 | Lr: 0.00100000000000000002 |Train loss: 3.36262850|Test loss: 3.58161171\n","Epoch: 113 | Lr: 0.00100000000000000002 |Train loss: 3.33704754|Test loss: 3.58188494\n","Epoch: 114 | Lr: 0.00100000000000000002 |Train loss: 3.32475835|Test loss: 3.59001064\n","Epoch: 115 | Lr: 0.00100000000000000002 |Train loss: 3.37736122|Test loss: 3.71571596\n","Epoch: 116 | Lr: 0.00100000000000000002 |Train loss: 3.35076946|Test loss: 3.64124910\n","Epoch: 117 | Lr: 0.00100000000000000002 |Train loss: 3.33919849|Test loss: 3.64071488\n","Epoch: 118 | Lr: 0.00100000000000000002 |Train loss: 3.32850033|Test loss: 3.57496365\n","Epoch: 119 | Lr: 0.00100000000000000002 |Train loss: 3.31370012|Test loss: 3.56245852\n","Epoch: 120 | Lr: 0.00100000000000000002 |Train loss: 3.32386041|Test loss: 3.55297089\n","Epoch: 121 | Lr: 0.00100000000000000002 |Train loss: 3.30118700|Test loss: 3.59502101\n","Epoch: 122 | Lr: 0.00100000000000000002 |Train loss: 3.33837710|Test loss: 3.58035302\n","Epoch: 123 | Lr: 0.00100000000000000002 |Train loss: 3.30323766|Test loss: 3.66033371\n","Epoch: 124 | Lr: 0.00100000000000000002 |Train loss: 3.33789396|Test loss: 3.71937815\n","Epoch: 125 | Lr: 0.00100000000000000002 |Train loss: 3.32010959|Test loss: 3.54851135\n","Epoch: 126 | Lr: 0.00100000000000000002 |Train loss: 3.43586355|Test loss: 3.55682278\n","Epoch: 127 | Lr: 0.00100000000000000002 |Train loss: 3.42072952|Test loss: 3.64571524\n","Epoch: 128 | Lr: 0.00100000000000000002 |Train loss: 3.37989690|Test loss: 3.58899609\n","Epoch: 129 | Lr: 0.00100000000000000002 |Train loss: 3.36488070|Test loss: 3.65677055\n","Epoch: 130 | Lr: 0.00100000000000000002 |Train loss: 3.44596320|Test loss: 3.76563549\n","Epoch: 131 | Lr: 0.00100000000000000002 |Train loss: 3.38775301|Test loss: 3.56557059\n","Epoch: 132 | Lr: 0.00100000000000000002 |Train loss: 3.33620111|Test loss: 3.61044908\n","Epoch: 133 | Lr: 0.00100000000000000002 |Train loss: 3.35808857|Test loss: 3.52362847\n","Epoch: 134 | Lr: 0.00100000000000000002 |Train loss: 3.30198336|Test loss: 3.54522928\n","Epoch: 135 | Lr: 0.00100000000000000002 |Train loss: 3.28151528|Test loss: 3.56185953\n","Epoch: 136 | Lr: 0.00100000000000000002 |Train loss: 3.27690812|Test loss: 3.54769723\n","Epoch: 137 | Lr: 0.00100000000000000002 |Train loss: 3.29825966|Test loss: 3.55848289\n","Epoch: 138 | Lr: 0.00100000000000000002 |Train loss: 3.30561936|Test loss: 3.64072903\n","Epoch: 139 | Lr: 0.00100000000000000002 |Train loss: 3.28352869|Test loss: 3.54870645\n","Epoch: 140 | Lr: 0.00100000000000000002 |Train loss: 3.34255530|Test loss: 3.53529453\n","Epoch: 141 | Lr: 0.00100000000000000002 |Train loss: 3.35312786|Test loss: 3.60449974\n","Epoch: 142 | Lr: 0.00100000000000000002 |Train loss: 3.27720336|Test loss: 3.50615724\n","Epoch: 143 | Lr: 0.00100000000000000002 |Train loss: 3.35519844|Test loss: 3.63700318\n","Epoch: 144 | Lr: 0.00100000000000000002 |Train loss: 3.32103151|Test loss: 3.58728623\n","Epoch: 145 | Lr: 0.00100000000000000002 |Train loss: 3.28493132|Test loss: 3.52801005\n","Epoch: 146 | Lr: 0.00100000000000000002 |Train loss: 3.24864473|Test loss: 3.51388152\n","Epoch: 147 | Lr: 0.00100000000000000002 |Train loss: 3.25703539|Test loss: 3.53108215\n","Epoch: 148 | Lr: 0.00100000000000000002 |Train loss: 3.24900724|Test loss: 3.54047402\n","Epoch: 149 | Lr: 0.00100000000000000002 |Train loss: 3.26321926|Test loss: 3.57858793\n","Epoch: 150 | Lr: 0.00100000000000000002 |Train loss: 3.27220798|Test loss: 3.51139752\n","Epoch: 151 | Lr: 0.00100000000000000002 |Train loss: 3.29649039|Test loss: 3.53831712\n","Epoch: 152 | Lr: 0.00100000000000000002 |Train loss: 3.22307012|Test loss: 3.51754649\n","Epoch: 153 | Lr: 0.00100000000000000002 |Train loss: 3.20935820|Test loss: 3.54416227\n","Epoch: 154 | Lr: 0.00100000000000000002 |Train loss: 3.21541860|Test loss: 3.51707466\n","Epoch: 155 | Lr: 0.00100000000000000002 |Train loss: 3.32963677|Test loss: 3.65396047\n","Epoch: 156 | Lr: 0.00100000000000000002 |Train loss: 3.28547146|Test loss: 3.60324764\n","Epoch: 157 | Lr: 0.00100000000000000002 |Train loss: 3.23336083|Test loss: 3.55829859\n","Epoch: 158 | Lr: 0.00100000000000000002 |Train loss: 3.22917485|Test loss: 3.53000053\n","Epoch: 159 | Lr: 0.00100000000000000002 |Train loss: 3.20531084|Test loss: 3.49364773\n","Epoch: 160 | Lr: 0.00100000000000000002 |Train loss: 3.22020652|Test loss: 3.48202316\n","Epoch: 161 | Lr: 0.00100000000000000002 |Train loss: 3.21488647|Test loss: 3.52599994\n","Epoch: 162 | Lr: 0.00100000000000000002 |Train loss: 3.19945623|Test loss: 3.61293093\n","Epoch: 163 | Lr: 0.00100000000000000002 |Train loss: 3.19180959|Test loss: 3.58966724\n","Epoch: 164 | Lr: 0.00100000000000000002 |Train loss: 3.23015803|Test loss: 3.54146830\n","Epoch: 165 | Lr: 0.00100000000000000002 |Train loss: 3.31804087|Test loss: 3.60921081\n","Epoch: 166 | Lr: 0.00100000000000000002 |Train loss: 3.30153471|Test loss: 3.57390094\n","Epoch: 167 | Lr: 0.00100000000000000002 |Train loss: 3.23015626|Test loss: 3.63915833\n","Epoch: 168 | Lr: 0.00100000000000000002 |Train loss: 3.24520471|Test loss: 3.61251752\n","Epoch: 169 | Lr: 0.00100000000000000002 |Train loss: 3.25012078|Test loss: 3.48380550\n","Epoch: 170 | Lr: 0.00100000000000000002 |Train loss: 3.42480773|Test loss: 3.63565882\n","Epoch: 171 | Lr: 0.00100000000000000002 |Train loss: 3.37611556|Test loss: 3.73740403\n","Epoch: 172 | Lr: 0.00100000000000000002 |Train loss: 3.24532406|Test loss: 3.50314903\n","Epoch: 173 | Lr: 0.00100000000000000002 |Train loss: 3.37694273|Test loss: 3.75314005\n","Epoch: 174 | Lr: 0.00100000000000000002 |Train loss: 3.41470784|Test loss: 3.53749808\n","Epoch: 175 | Lr: 0.00100000000000000002 |Train loss: 3.24369627|Test loss: 3.52721524\n","Epoch: 176 | Lr: 0.00100000000000000002 |Train loss: 3.24291567|Test loss: 3.52741758\n","Epoch: 177 | Lr: 0.00100000000000000002 |Train loss: 3.20595356|Test loss: 3.51965618\n","Epoch: 178 | Lr: 0.00100000000000000002 |Train loss: 3.19002626|Test loss: 3.52251927\n","Epoch: 179 | Lr: 0.00100000000000000002 |Train loss: 3.17524618|Test loss: 3.52242438\n","Epoch: 180 | Lr: 0.00100000000000000002 |Train loss: 3.17459975|Test loss: 3.48100026\n","Epoch: 181 | Lr: 0.00100000000000000002 |Train loss: 3.15738581|Test loss: 3.54372660\n","Epoch: 182 | Lr: 0.00100000000000000002 |Train loss: 3.17795736|Test loss: 3.52102741\n","Epoch: 183 | Lr: 0.00100000000000000002 |Train loss: 3.12227309|Test loss: 3.56187646\n","Epoch: 184 | Lr: 0.00100000000000000002 |Train loss: 3.15847907|Test loss: 3.47258941\n","Epoch: 185 | Lr: 0.00100000000000000002 |Train loss: 3.18654666|Test loss: 3.56068993\n","Epoch: 186 | Lr: 0.00100000000000000002 |Train loss: 3.13436516|Test loss: 3.46585941\n","Epoch: 187 | Lr: 0.00100000000000000002 |Train loss: 3.11710586|Test loss: 3.46151416\n","Epoch: 188 | Lr: 0.00100000000000000002 |Train loss: 3.11053487|Test loss: 3.44816772\n","Epoch: 189 | Lr: 0.00100000000000000002 |Train loss: 3.14255446|Test loss: 3.49319394\n","Epoch: 190 | Lr: 0.00100000000000000002 |Train loss: 3.13039386|Test loss: 3.51496275\n","Epoch: 191 | Lr: 0.00100000000000000002 |Train loss: 3.25829935|Test loss: 3.51477933\n","Epoch: 192 | Lr: 0.00100000000000000002 |Train loss: 3.17601881|Test loss: 3.54036848\n","Epoch: 193 | Lr: 0.00100000000000000002 |Train loss: 3.16973948|Test loss: 3.52357435\n","Epoch: 194 | Lr: 0.00100000000000000002 |Train loss: 3.13082308|Test loss: 3.55133971\n","Epoch: 195 | Lr: 0.00100000000000000002 |Train loss: 3.21298426|Test loss: 3.47607390\n","Epoch: 196 | Lr: 0.00100000000000000002 |Train loss: 3.37607777|Test loss: 3.62650760\n","Epoch: 197 | Lr: 0.00100000000000000002 |Train loss: 3.36121013|Test loss: 3.72514987\n","Epoch: 198 | Lr: 0.00100000000000000002 |Train loss: 3.20594279|Test loss: 3.48571364\n","Epoch: 199 | Lr: 0.00100000000000000002 |Train loss: 3.15927831|Test loss: 3.55817628\n","Epoch: 200 | Lr: 0.00100000000000000002 |Train loss: 3.20014705|Test loss: 3.51795292\n","Epoch: 201 | Lr: 0.00100000000000000002 |Train loss: 3.15048711|Test loss: 3.54266055\n","Epoch: 202 | Lr: 0.00100000000000000002 |Train loss: 3.14373034|Test loss: 3.53472527\n","Epoch: 203 | Lr: 0.00100000000000000002 |Train loss: 3.14655445|Test loss: 3.47486083\n","Epoch: 204 | Lr: 0.00100000000000000002 |Train loss: 3.18423973|Test loss: 3.49727575\n","Epoch: 205 | Lr: 0.00100000000000000002 |Train loss: 3.18603816|Test loss: 3.49771643\n","Epoch: 206 | Lr: 0.00100000000000000002 |Train loss: 3.17739914|Test loss: 3.52263729\n","Epoch: 207 | Lr: 0.00100000000000000002 |Train loss: 3.11468091|Test loss: 3.46089133\n","Epoch: 208 | Lr: 0.00100000000000000002 |Train loss: 3.17244828|Test loss: 3.52880470\n","Epoch: 209 | Lr: 0.00100000000000000002 |Train loss: 3.23010149|Test loss: 3.52277565\n","Epoch: 210 | Lr: 0.00100000000000000002 |Train loss: 3.12211943|Test loss: 3.61318676\n","Epoch: 211 | Lr: 0.00100000000000000002 |Train loss: 3.11522710|Test loss: 3.50563622\n","Epoch: 212 | Lr: 0.00100000000000000002 |Train loss: 3.13341590|Test loss: 3.46570055\n","Epoch: 213 | Lr: 0.00100000000000000002 |Train loss: 3.21009547|Test loss: 3.52802070\n","Epoch: 214 | Lr: 0.00100000000000000002 |Train loss: 3.24951132|Test loss: 3.59977523\n","Epoch: 215 | Lr: 0.00100000000000000002 |Train loss: 3.13211777|Test loss: 3.43292030\n","Epoch: 216 | Lr: 0.00100000000000000002 |Train loss: 3.11426924|Test loss: 3.55984012\n","Epoch: 217 | Lr: 0.00100000000000000002 |Train loss: 3.11486652|Test loss: 3.55484605\n","Epoch: 218 | Lr: 0.00100000000000000002 |Train loss: 3.09634225|Test loss: 3.50807985\n","Epoch: 219 | Lr: 0.00100000000000000002 |Train loss: 3.07703588|Test loss: 3.48628306\n","Epoch: 220 | Lr: 0.00100000000000000002 |Train loss: 3.09023656|Test loss: 3.47329791\n","Epoch: 221 | Lr: 0.00100000000000000002 |Train loss: 3.16841308|Test loss: 3.54625241\n","Epoch: 222 | Lr: 0.00100000000000000002 |Train loss: 3.14711901|Test loss: 3.47161579\n","Epoch: 223 | Lr: 0.00100000000000000002 |Train loss: 3.10266747|Test loss: 3.45802196\n","Epoch: 224 | Lr: 0.00100000000000000002 |Train loss: 3.05428274|Test loss: 3.46243231\n","Epoch: 225 | Lr: 0.00100000000000000002 |Train loss: 3.04862736|Test loss: 3.54883583\n","Epoch: 226 | Lr: 0.00100000000000000002 |Train loss: 3.05998512|Test loss: 3.54474886\n","Epoch: 227 | Lr: 0.00100000000000000002 |Train loss: 3.08679505|Test loss: 3.51417740\n","Epoch: 228 | Lr: 0.00100000000000000002 |Train loss: 3.02744967|Test loss: 3.52603364\n","Epoch: 229 | Lr: 0.00100000000000000002 |Train loss: 3.08152097|Test loss: 3.43132663\n","Epoch: 230 | Lr: 0.00100000000000000002 |Train loss: 3.20492806|Test loss: 3.59746925\n","Epoch: 231 | Lr: 0.00100000000000000002 |Train loss: 3.22213537|Test loss: 3.55128598\n","Epoch: 232 | Lr: 0.00100000000000000002 |Train loss: 3.10753838|Test loss: 3.44563866\n","Epoch: 233 | Lr: 0.00100000000000000002 |Train loss: 3.09799570|Test loss: 3.53408194\n","Epoch: 234 | Lr: 0.00100000000000000002 |Train loss: 3.23371414|Test loss: 3.47234583\n","Epoch: 235 | Lr: 0.00100000000000000002 |Train loss: 3.16248188|Test loss: 3.56999866\n","Epoch: 236 | Lr: 0.00100000000000000002 |Train loss: 3.12323320|Test loss: 3.51902620\n","Epoch: 237 | Lr: 0.00100000000000000002 |Train loss: 3.08450150|Test loss: 3.52955731\n","Epoch: 238 | Lr: 0.00100000000000000002 |Train loss: 3.10648179|Test loss: 3.47324022\n","Epoch: 239 | Lr: 0.00100000000000000002 |Train loss: 3.22513958|Test loss: 3.66232196\n","Epoch: 240 | Lr: 0.00100000000000000002 |Train loss: 3.14476899|Test loss: 3.49075309\n","Epoch: 241 | Lr: 0.00100000000000000002 |Train loss: 3.10888147|Test loss: 3.52086186\n","Epoch: 242 | Lr: 0.00100000000000000002 |Train loss: 3.10850179|Test loss: 3.61094451\n","Epoch: 243 | Lr: 0.00100000000000000002 |Train loss: 3.10344326|Test loss: 3.53017640\n","Epoch: 244 | Lr: 0.00100000000000000002 |Train loss: 3.05709175|Test loss: 3.48370139\n","Epoch: 245 | Lr: 0.00100000000000000002 |Train loss: 3.04708997|Test loss: 3.42722535\n","Epoch: 246 | Lr: 0.00100000000000000002 |Train loss: 3.06629743|Test loss: 3.44648600\n","Epoch: 247 | Lr: 0.00100000000000000002 |Train loss: 3.09243538|Test loss: 3.46775866\n","Epoch: 248 | Lr: 0.00100000000000000002 |Train loss: 3.07489723|Test loss: 3.45906822\n","Epoch: 249 | Lr: 0.00100000000000000002 |Train loss: 3.03566507|Test loss: 3.46686308\n","Epoch: 250 | Lr: 0.00100000000000000002 |Train loss: 3.02943774|Test loss: 3.63830034\n","Epoch: 251 | Lr: 0.00100000000000000002 |Train loss: 3.02227702|Test loss: 3.58184958\n","Epoch: 252 | Lr: 0.00100000000000000002 |Train loss: 3.02593720|Test loss: 3.68042056\n","Epoch: 253 | Lr: 0.00100000000000000002 |Train loss: 3.00781876|Test loss: 3.52968470\n","Epoch: 254 | Lr: 0.00100000000000000002 |Train loss: 3.04527018|Test loss: 3.46260031\n","Epoch: 255 | Lr: 0.00100000000000000002 |Train loss: 3.14132611|Test loss: 3.61924934\n","Epoch: 256 | Lr: 0.00100000000000000002 |Train loss: 3.25850525|Test loss: 3.64662608\n","Epoch: 257 | Lr: 0.00100000000000000002 |Train loss: 3.21132841|Test loss: 3.50108981\n","Epoch: 258 | Lr: 0.00100000000000000002 |Train loss: 3.07361193|Test loss: 3.49465823\n","Epoch: 259 | Lr: 0.00100000000000000002 |Train loss: 3.10028519|Test loss: 3.60406677\n","Epoch: 260 | Lr: 0.00100000000000000002 |Train loss: 3.10370515|Test loss: 3.57766239\n","Epoch: 261 | Lr: 0.00100000000000000002 |Train loss: 3.03467751|Test loss: 3.49064938\n","Epoch: 262 | Lr: 0.00100000000000000002 |Train loss: 3.01349018|Test loss: 3.41596516\n","Epoch: 263 | Lr: 0.00100000000000000002 |Train loss: 3.01939499|Test loss: 3.43555363\n","Epoch: 264 | Lr: 0.00100000000000000002 |Train loss: 3.03210892|Test loss: 3.47491558\n","Epoch: 265 | Lr: 0.00100000000000000002 |Train loss: 3.01140068|Test loss: 3.40413260\n","Epoch: 266 | Lr: 0.00100000000000000002 |Train loss: 2.97235550|Test loss: 3.46030323\n","Epoch: 267 | Lr: 0.00100000000000000002 |Train loss: 3.00578350|Test loss: 3.54424437\n","Epoch: 268 | Lr: 0.00100000000000000002 |Train loss: 3.09188517|Test loss: 3.57609502\n","Epoch: 269 | Lr: 0.00100000000000000002 |Train loss: 3.06475474|Test loss: 3.68178121\n","Epoch: 270 | Lr: 0.00100000000000000002 |Train loss: 3.01767250|Test loss: 3.65537246\n","Epoch: 271 | Lr: 0.00100000000000000002 |Train loss: 3.00454426|Test loss: 3.59370216\n","Epoch: 272 | Lr: 0.00100000000000000002 |Train loss: 3.04834251|Test loss: 3.44879381\n","Epoch: 273 | Lr: 0.00100000000000000002 |Train loss: 3.19552034|Test loss: 3.59203442\n","Epoch: 274 | Lr: 0.00100000000000000002 |Train loss: 3.13279166|Test loss: 3.53969153\n","Epoch: 275 | Lr: 0.00100000000000000002 |Train loss: 3.04418574|Test loss: 3.41585000\n","Epoch: 276 | Lr: 0.00100000000000000002 |Train loss: 2.99063075|Test loss: 3.54695543\n","Epoch: 277 | Lr: 0.00100000000000000002 |Train loss: 3.05577920|Test loss: 3.61078723\n","Epoch: 278 | Lr: 0.00100000000000000002 |Train loss: 3.01170456|Test loss: 3.51195900\n","Epoch: 279 | Lr: 0.00100000000000000002 |Train loss: 2.97816086|Test loss: 3.57555827\n","Epoch: 280 | Lr: 0.00100000000000000002 |Train loss: 2.95912083|Test loss: 3.41919676\n","Epoch: 281 | Lr: 0.00100000000000000002 |Train loss: 2.99162738|Test loss: 3.41820359\n","Epoch: 282 | Lr: 0.00100000000000000002 |Train loss: 3.00682475|Test loss: 3.46891522\n","Epoch: 283 | Lr: 0.00100000000000000002 |Train loss: 3.03457818|Test loss: 3.48887793\n","Epoch: 284 | Lr: 0.00100000000000000002 |Train loss: 2.99267664|Test loss: 3.44078414\n","Epoch: 285 | Lr: 0.00100000000000000002 |Train loss: 2.94137375|Test loss: 3.51455593\n","Epoch: 286 | Lr: 0.00100000000000000002 |Train loss: 3.00241222|Test loss: 3.65774512\n","Epoch: 287 | Lr: 0.00100000000000000002 |Train loss: 2.99676291|Test loss: 3.67889190\n","Epoch: 288 | Lr: 0.00100000000000000002 |Train loss: 2.93795397|Test loss: 3.58328589\n","Epoch: 289 | Lr: 0.00100000000000000002 |Train loss: 2.93899876|Test loss: 3.63165180\n","Epoch: 290 | Lr: 0.00100000000000000002 |Train loss: 2.95292882|Test loss: 3.63335244\n","Epoch: 291 | Lr: 0.00100000000000000002 |Train loss: 2.95920881|Test loss: 3.65667462\n","Epoch: 292 | Lr: 0.00100000000000000002 |Train loss: 2.98136419|Test loss: 3.51655857\n","Epoch: 293 | Lr: 0.00100000000000000002 |Train loss: 3.02287982|Test loss: 3.41312544\n","Epoch: 294 | Lr: 0.00100000000000000002 |Train loss: 3.12630763|Test loss: 3.62506731\n","Epoch: 295 | Lr: 0.00100000000000000002 |Train loss: 3.18672244|Test loss: 3.64164464\n","Epoch: 296 | Lr: 0.00100000000000000002 |Train loss: 3.00765683|Test loss: 3.42446645\n","Epoch: 297 | Lr: 0.00100000000000000002 |Train loss: 3.01537832|Test loss: 3.60862327\n","Epoch: 298 | Lr: 0.00100000000000000002 |Train loss: 3.01950147|Test loss: 3.57349435\n","Epoch: 299 | Lr: 0.00100000000000000002 |Train loss: 2.98615269|Test loss: 3.55062540\n","Epoch: 300 | Lr: 0.00100000000000000002 |Train loss: 2.97323549|Test loss: 3.50717187\n","Epoch: 301 | Lr: 0.00100000000000000002 |Train loss: 2.96097048|Test loss: 3.41794308\n","Epoch: 302 | Lr: 0.00100000000000000002 |Train loss: 2.96735907|Test loss: 3.47080914\n","Epoch: 303 | Lr: 0.00100000000000000002 |Train loss: 2.92859407|Test loss: 3.43039465\n","Epoch: 304 | Lr: 0.00100000000000000002 |Train loss: 2.90962307|Test loss: 3.42853006\n","Epoch: 305 | Lr: 0.00100000000000000002 |Train loss: 2.89546867|Test loss: 3.45940121\n","Epoch: 306 | Lr: 0.00100000000000000002 |Train loss: 2.90496983|Test loss: 3.49954367\n","Epoch: 307 | Lr: 0.00100000000000000002 |Train loss: 2.92915839|Test loss: 3.52429962\n","Epoch: 308 | Lr: 0.00100000000000000002 |Train loss: 2.99825541|Test loss: 3.48774481\n","Epoch: 309 | Lr: 0.00100000000000000002 |Train loss: 2.99327024|Test loss: 3.66230114\n","Epoch: 310 | Lr: 0.00100000000000000002 |Train loss: 3.00306104|Test loss: 3.62325374\n","Epoch: 311 | Lr: 0.00100000000000000002 |Train loss: 3.03367142|Test loss: 3.68380586\n","Epoch: 312 | Lr: 0.00100000000000000002 |Train loss: 2.98845510|Test loss: 3.75269834\n","Epoch: 313 | Lr: 0.00100000000000000002 |Train loss: 2.95354974|Test loss: 3.49873479\n","Epoch: 314 | Lr: 0.00100000000000000002 |Train loss: 2.98795531|Test loss: 3.45938381\n","Epoch: 315 | Lr: 0.00100000000000000002 |Train loss: 3.05920001|Test loss: 3.49073251\n","Epoch: 316 | Lr: 0.00100000000000000002 |Train loss: 3.05771585|Test loss: 3.43674644\n","Epoch: 317 | Lr: 0.00100000000000000002 |Train loss: 2.99505009|Test loss: 3.46919425\n","Epoch: 318 | Lr: 0.00100000000000000002 |Train loss: 2.94264054|Test loss: 3.47180605\n","Epoch: 319 | Lr: 0.00100000000000000002 |Train loss: 2.99481114|Test loss: 3.65473127\n","Epoch: 320 | Lr: 0.00100000000000000002 |Train loss: 3.00197252|Test loss: 3.73008172\n","Epoch: 321 | Lr: 0.00100000000000000002 |Train loss: 2.98472089|Test loss: 3.65480836\n","Epoch: 322 | Lr: 0.00100000000000000002 |Train loss: 3.01942146|Test loss: 3.47589302\n","Epoch: 323 | Lr: 0.00100000000000000002 |Train loss: 2.95851876|Test loss: 3.42710344\n","Epoch: 324 | Lr: 0.00100000000000000002 |Train loss: 2.97743320|Test loss: 3.44641717\n","Epoch: 325 | Lr: 0.00100000000000000002 |Train loss: 2.92509768|Test loss: 3.45726124\n","Epoch: 326 | Lr: 0.00100000000000000002 |Train loss: 2.90125291|Test loss: 3.46560820\n","Epoch: 327 | Lr: 0.00100000000000000002 |Train loss: 2.86642865|Test loss: 3.48407046\n","Epoch: 328 | Lr: 0.00100000000000000002 |Train loss: 2.87181310|Test loss: 3.48073769\n","Epoch: 329 | Lr: 0.00100000000000000002 |Train loss: 2.87935642|Test loss: 3.50199795\n","Epoch: 330 | Lr: 0.00100000000000000002 |Train loss: 2.88271403|Test loss: 3.72213038\n","Epoch: 331 | Lr: 0.00100000000000000002 |Train loss: 2.93401468|Test loss: 3.60028092\n","Epoch: 332 | Lr: 0.00100000000000000002 |Train loss: 2.95216974|Test loss: 3.71629246\n","Epoch: 333 | Lr: 0.00100000000000000002 |Train loss: 2.88935439|Test loss: 3.60880876\n","Epoch: 334 | Lr: 0.00100000000000000002 |Train loss: 2.89529310|Test loss: 3.74666770\n","Epoch: 335 | Lr: 0.00100000000000000002 |Train loss: 2.96881578|Test loss: 3.58362428\n","Epoch: 336 | Lr: 0.00100000000000000002 |Train loss: 3.02235927|Test loss: 3.44256488\n","Epoch: 337 | Lr: 0.00100000000000000002 |Train loss: 3.08083431|Test loss: 3.45240211\n","Epoch: 338 | Lr: 0.00100000000000000002 |Train loss: 2.99694967|Test loss: 3.41962449\n","Epoch: 339 | Lr: 0.00100000000000000002 |Train loss: 3.04714513|Test loss: 3.54869660\n","Epoch: 340 | Lr: 0.00100000000000000002 |Train loss: 2.99716443|Test loss: 3.45559661\n","Epoch: 341 | Lr: 0.00100000000000000002 |Train loss: 2.94433759|Test loss: 3.59978660\n","Epoch: 342 | Lr: 0.00100000000000000002 |Train loss: 2.95467907|Test loss: 3.63098168\n","Epoch: 343 | Lr: 0.00100000000000000002 |Train loss: 2.90731017|Test loss: 3.65669052\n","Epoch: 344 | Lr: 0.00100000000000000002 |Train loss: 2.92480952|Test loss: 3.66179570\n","Epoch: 345 | Lr: 0.00100000000000000002 |Train loss: 2.93069734|Test loss: 3.44903914\n","Epoch: 346 | Lr: 0.00100000000000000002 |Train loss: 2.93767273|Test loss: 3.43441701\n","Epoch: 347 | Lr: 0.00100000000000000002 |Train loss: 2.96651606|Test loss: 3.49021769\n","Epoch: 348 | Lr: 0.00100000000000000002 |Train loss: 2.93337353|Test loss: 3.38301524\n","Epoch: 349 | Lr: 0.00100000000000000002 |Train loss: 2.87525862|Test loss: 3.45936497\n","Epoch: 350 | Lr: 0.00100000000000000002 |Train loss: 2.86958849|Test loss: 3.62079048\n","Epoch: 351 | Lr: 0.00100000000000000002 |Train loss: 2.88707892|Test loss: 3.66532954\n","Epoch: 352 | Lr: 0.00100000000000000002 |Train loss: 2.89175902|Test loss: 3.77173773\n","Epoch: 353 | Lr: 0.00100000000000000002 |Train loss: 2.89803859|Test loss: 3.77290924\n","Epoch: 354 | Lr: 0.00100000000000000002 |Train loss: 2.86875554|Test loss: 3.67531315\n","Epoch: 355 | Lr: 0.00100000000000000002 |Train loss: 2.88843822|Test loss: 3.48023566\n","Epoch: 356 | Lr: 0.00100000000000000002 |Train loss: 3.00987752|Test loss: 3.46028670\n","Epoch: 357 | Lr: 0.00100000000000000002 |Train loss: 2.97352926|Test loss: 3.46727252\n","Epoch: 358 | Lr: 0.00100000000000000002 |Train loss: 2.91613472|Test loss: 3.47908576\n","Epoch: 359 | Lr: 0.00100000000000000002 |Train loss: 2.86409885|Test loss: 3.47584136\n","Epoch: 360 | Lr: 0.00100000000000000002 |Train loss: 2.84465663|Test loss: 3.57063301\n","Epoch: 361 | Lr: 0.00100000000000000002 |Train loss: 2.90415917|Test loss: 3.55441244\n","Epoch: 362 | Lr: 0.00100000000000000002 |Train loss: 3.05524661|Test loss: 3.89719439\n","Epoch: 363 | Lr: 0.00100000000000000002 |Train loss: 2.94526319|Test loss: 3.62511563\n","Epoch: 364 | Lr: 0.00100000000000000002 |Train loss: 2.93821599|Test loss: 3.66431141\n","Epoch: 365 | Lr: 0.00100000000000000002 |Train loss: 2.92719394|Test loss: 3.77361774\n","Epoch: 366 | Lr: 0.00100000000000000002 |Train loss: 2.87283872|Test loss: 3.44289947\n","Epoch: 367 | Lr: 0.00100000000000000002 |Train loss: 2.88742447|Test loss: 3.41940252\n","Epoch: 368 | Lr: 0.00100000000000000002 |Train loss: 2.92414075|Test loss: 3.41536903\n","Epoch: 369 | Lr: 0.00100000000000000002 |Train loss: 2.85469524|Test loss: 3.47389030\n","Epoch: 370 | Lr: 0.00100000000000000002 |Train loss: 2.81480173|Test loss: 3.52382135\n","Epoch: 371 | Lr: 0.00100000000000000002 |Train loss: 2.79859968|Test loss: 3.55789749\n","Epoch: 372 | Lr: 0.00100000000000000002 |Train loss: 2.78737473|Test loss: 3.70240013\n","Epoch: 373 | Lr: 0.00100000000000000002 |Train loss: 2.79004709|Test loss: 3.60789410\n","Epoch: 374 | Lr: 0.00100000000000000002 |Train loss: 2.80565916|Test loss: 3.65110858\n","Epoch: 375 | Lr: 0.00100000000000000002 |Train loss: 2.80194016|Test loss: 3.79936814\n","Epoch: 376 | Lr: 0.00100000000000000002 |Train loss: 2.80834579|Test loss: 3.93697309\n","Epoch: 377 | Lr: 0.00100000000000000002 |Train loss: 2.78164411|Test loss: 3.75963807\n","Epoch: 378 | Lr: 0.00100000000000000002 |Train loss: 2.87881927|Test loss: 3.52570542\n","Epoch: 379 | Lr: 0.00100000000000000002 |Train loss: 2.97274452|Test loss: 3.45476087\n","Epoch: 380 | Lr: 0.00100000000000000002 |Train loss: 2.97240096|Test loss: 3.46028988\n","Epoch: 381 | Lr: 0.00100000000000000002 |Train loss: 3.01935534|Test loss: 3.52321815\n","Epoch: 382 | Lr: 0.00100000000000000002 |Train loss: 2.89755148|Test loss: 3.41332189\n","Epoch: 383 | Lr: 0.00100000000000000002 |Train loss: 2.82868278|Test loss: 3.70389724\n","Epoch: 384 | Lr: 0.00100000000000000002 |Train loss: 2.90214010|Test loss: 3.60161177\n","Epoch: 385 | Lr: 0.00100000000000000002 |Train loss: 2.90252697|Test loss: 3.71555297\n","Epoch: 386 | Lr: 0.00100000000000000002 |Train loss: 2.86306866|Test loss: 3.58110372\n","Epoch: 387 | Lr: 0.00100000000000000002 |Train loss: 2.87380326|Test loss: 3.51037161\n","Epoch: 388 | Lr: 0.00100000000000000002 |Train loss: 2.83326707|Test loss: 3.43544459\n","Epoch: 389 | Lr: 0.00100000000000000002 |Train loss: 2.87813564|Test loss: 3.44823321\n","Epoch: 390 | Lr: 0.00100000000000000002 |Train loss: 2.83135521|Test loss: 3.42969688\n","Epoch: 391 | Lr: 0.00100000000000000002 |Train loss: 2.81018730|Test loss: 3.40934110\n","Epoch: 392 | Lr: 0.00100000000000000002 |Train loss: 2.77483654|Test loss: 3.55391375\n","Epoch: 393 | Lr: 0.00100000000000000002 |Train loss: 2.75864222|Test loss: 3.59743945\n","Epoch: 394 | Lr: 0.00100000000000000002 |Train loss: 2.83296029|Test loss: 3.58619579\n","Epoch: 395 | Lr: 0.00100000000000000002 |Train loss: 2.84386086|Test loss: 3.92868964\n","Epoch: 396 | Lr: 0.00100000000000000002 |Train loss: 2.89731201|Test loss: 3.73532613\n","Epoch: 397 | Lr: 0.00100000000000000002 |Train loss: 2.85434977|Test loss: 3.78437630\n","Epoch: 398 | Lr: 0.00100000000000000002 |Train loss: 2.82965457|Test loss: 3.80180772\n","Epoch: 399 | Lr: 0.00100000000000000002 |Train loss: 2.92993156|Test loss: 3.44413646\n","Epoch: 400 | Lr: 0.00100000000000000002 |Train loss: 2.96442403|Test loss: 3.49043640\n","Epoch: 401 | Lr: 0.00100000000000000002 |Train loss: 2.83570860|Test loss: 3.40083758\n","Epoch: 402 | Lr: 0.00100000000000000002 |Train loss: 2.77352375|Test loss: 3.46369274\n","Epoch: 403 | Lr: 0.00100000000000000002 |Train loss: 2.78132035|Test loss: 3.42722050\n","Epoch: 404 | Lr: 0.00100000000000000002 |Train loss: 2.75372102|Test loss: 3.67902319\n","Epoch: 405 | Lr: 0.00100000000000000002 |Train loss: 2.76411593|Test loss: 3.67903233\n","Epoch: 406 | Lr: 0.00100000000000000002 |Train loss: 2.76532803|Test loss: 3.65224004\n","Epoch: 407 | Lr: 0.00100000000000000002 |Train loss: 2.76476282|Test loss: 3.59281365\n","Epoch: 408 | Lr: 0.00100000000000000002 |Train loss: 2.74196752|Test loss: 3.69753432\n","Epoch: 409 | Lr: 0.00100000000000000002 |Train loss: 2.70940224|Test loss: 3.66009919\n","Epoch: 410 | Lr: 0.00100000000000000002 |Train loss: 2.76992025|Test loss: 3.83994110\n","Epoch: 411 | Lr: 0.00100000000000000002 |Train loss: 2.76808381|Test loss: 3.51594647\n","Epoch: 412 | Lr: 0.00100000000000000002 |Train loss: 2.75120421|Test loss: 3.52950764\n","Epoch: 413 | Lr: 0.00100000000000000002 |Train loss: 2.87488651|Test loss: 3.37881056\n","Epoch: 414 | Lr: 0.00100000000000000002 |Train loss: 2.90845899|Test loss: 3.70876813\n","Epoch: 415 | Lr: 0.00100000000000000002 |Train loss: 2.94333074|Test loss: 3.53487102\n","Epoch: 416 | Lr: 0.00100000000000000002 |Train loss: 3.00033959|Test loss: 3.63111973\n","Epoch: 417 | Lr: 0.00100000000000000002 |Train loss: 2.87395275|Test loss: 3.49658855\n","Epoch: 418 | Lr: 0.00100000000000000002 |Train loss: 2.88196862|Test loss: 3.60493406\n","Epoch: 419 | Lr: 0.00100000000000000002 |Train loss: 2.81491174|Test loss: 3.72102396\n","Epoch: 420 | Lr: 0.00100000000000000002 |Train loss: 2.82537933|Test loss: 3.83759133\n","Epoch: 421 | Lr: 0.00100000000000000002 |Train loss: 2.76076031|Test loss: 3.89981167\n","Epoch: 422 | Lr: 0.00100000000000000002 |Train loss: 2.75010131|Test loss: 3.63182505\n","Epoch: 423 | Lr: 0.00100000000000000002 |Train loss: 2.85524396|Test loss: 3.37877560\n","Epoch: 424 | Lr: 0.00100000000000000002 |Train loss: 2.82720798|Test loss: 3.40189727\n","Epoch: 425 | Lr: 0.00100000000000000002 |Train loss: 2.84591440|Test loss: 3.37010908\n","Epoch: 426 | Lr: 0.00100000000000000002 |Train loss: 2.77876411|Test loss: 3.37882980\n","Epoch: 427 | Lr: 0.00100000000000000002 |Train loss: 2.74884256|Test loss: 3.47555868\n","Epoch: 428 | Lr: 0.00100000000000000002 |Train loss: 2.77007111|Test loss: 3.52638110\n","Epoch: 429 | Lr: 0.00100000000000000002 |Train loss: 2.80280248|Test loss: 3.69448884\n","Epoch: 430 | Lr: 0.00100000000000000002 |Train loss: 2.82499139|Test loss: 3.71464189\n","Epoch: 431 | Lr: 0.00100000000000000002 |Train loss: 2.79651497|Test loss: 3.89260872\n","Epoch: 432 | Lr: 0.00100000000000000002 |Train loss: 2.82220755|Test loss: 3.84266400\n","Epoch: 433 | Lr: 0.00100000000000000002 |Train loss: 2.81446820|Test loss: 3.51933559\n","Epoch: 434 | Lr: 0.00100000000000000002 |Train loss: 2.79819187|Test loss: 3.72126396\n","Epoch: 435 | Lr: 0.00100000000000000002 |Train loss: 2.79920153|Test loss: 3.43383090\n","Epoch: 436 | Lr: 0.00100000000000000002 |Train loss: 2.79229826|Test loss: 3.37297209\n","Epoch: 437 | Lr: 0.00100000000000000002 |Train loss: 2.77373175|Test loss: 3.42909543\n","Epoch: 438 | Lr: 0.00100000000000000002 |Train loss: 2.69015622|Test loss: 3.40050880\n","Epoch: 439 | Lr: 0.00100000000000000002 |Train loss: 2.67359012|Test loss: 3.47062651\n","Epoch: 440 | Lr: 0.00100000000000000002 |Train loss: 2.69433504|Test loss: 3.61323484\n","Epoch: 441 | Lr: 0.00100000000000000002 |Train loss: 2.69303825|Test loss: 3.79962762\n","Epoch: 442 | Lr: 0.00100000000000000002 |Train loss: 2.72496096|Test loss: 3.64797147\n","Epoch: 443 | Lr: 0.00100000000000000002 |Train loss: 2.70895443|Test loss: 3.66843597\n","Epoch: 444 | Lr: 0.00100000000000000002 |Train loss: 2.67203808|Test loss: 3.61719044\n","Epoch: 445 | Lr: 0.00100000000000000002 |Train loss: 2.67458502|Test loss: 3.61867356\n","Epoch: 446 | Lr: 0.00100000000000000002 |Train loss: 2.69488591|Test loss: 3.87829328\n","Epoch: 447 | Lr: 0.00100000000000000002 |Train loss: 2.67478921|Test loss: 3.75443474\n","Epoch: 448 | Lr: 0.00100000000000000002 |Train loss: 2.71621742|Test loss: 3.52315275\n","Epoch: 449 | Lr: 0.00100000000000000002 |Train loss: 2.77199968|Test loss: 3.62408137\n","Epoch: 450 | Lr: 0.00100000000000000002 |Train loss: 2.87848671|Test loss: 3.38728587\n","Epoch: 451 | Lr: 0.00100000000000000002 |Train loss: 2.94470412|Test loss: 3.43303609\n","Epoch: 452 | Lr: 0.00100000000000000002 |Train loss: 2.93975602|Test loss: 3.43643697\n","Epoch: 453 | Lr: 0.00100000000000000002 |Train loss: 2.93091899|Test loss: 3.36806989\n","Epoch: 454 | Lr: 0.00100000000000000002 |Train loss: 2.81773486|Test loss: 3.81939618\n","Epoch: 455 | Lr: 0.00100000000000000002 |Train loss: 2.75964542|Test loss: 3.91364074\n","Epoch: 456 | Lr: 0.00100000000000000002 |Train loss: 2.76945100|Test loss: 3.60090947\n","Epoch: 457 | Lr: 0.00100000000000000002 |Train loss: 2.68760147|Test loss: 3.48816315\n","Epoch: 458 | Lr: 0.00100000000000000002 |Train loss: 2.70840754|Test loss: 3.37382491\n","Epoch: 459 | Lr: 0.00100000000000000002 |Train loss: 2.75677224|Test loss: 3.37113492\n","Epoch: 460 | Lr: 0.00100000000000000002 |Train loss: 2.69297783|Test loss: 3.32981825\n","Epoch: 461 | Lr: 0.00100000000000000002 |Train loss: 2.67932651|Test loss: 3.33452296\n","Epoch: 462 | Lr: 0.00100000000000000002 |Train loss: 2.69003675|Test loss: 3.47296572\n","Epoch: 463 | Lr: 0.00100000000000000002 |Train loss: 2.72210594|Test loss: 3.60500550\n","Epoch: 464 | Lr: 0.00100000000000000002 |Train loss: 2.76917428|Test loss: 3.82681537\n","Epoch: 465 | Lr: 0.00100000000000000002 |Train loss: 2.83048900|Test loss: 3.74275637\n","Epoch: 466 | Lr: 0.00100000000000000002 |Train loss: 2.77657570|Test loss: 3.62821341\n","Epoch: 467 | Lr: 0.00100000000000000002 |Train loss: 2.69686498|Test loss: 3.89204582\n","Epoch: 468 | Lr: 0.00100000000000000002 |Train loss: 2.70643075|Test loss: 3.47766344\n","Epoch: 469 | Lr: 0.00100000000000000002 |Train loss: 2.65550598|Test loss: 3.42501410\n","Epoch: 470 | Lr: 0.00100000000000000002 |Train loss: 2.69238508|Test loss: 3.57241019\n","Epoch: 471 | Lr: 0.00100000000000000002 |Train loss: 2.66305057|Test loss: 3.47667925\n","Epoch: 472 | Lr: 0.00100000000000000002 |Train loss: 2.70681036|Test loss: 3.49118439\n","Epoch: 473 | Lr: 0.00100000000000000002 |Train loss: 2.65670206|Test loss: 3.83558798\n","Epoch: 474 | Lr: 0.00100000000000000002 |Train loss: 2.71346291|Test loss: 3.57244722\n","Epoch: 475 | Lr: 0.00100000000000000002 |Train loss: 2.66765390|Test loss: 3.47707915\n","Epoch: 476 | Lr: 0.00100000000000000002 |Train loss: 2.68334411|Test loss: 3.80965702\n","Epoch: 477 | Lr: 0.00100000000000000002 |Train loss: 2.81609891|Test loss: 3.80134265\n","Epoch: 478 | Lr: 0.00100000000000000002 |Train loss: 2.76930336|Test loss: 3.57002870\n","Epoch: 479 | Lr: 0.00100000000000000002 |Train loss: 2.71532941|Test loss: 3.90363955\n","Epoch: 480 | Lr: 0.00100000000000000002 |Train loss: 2.66873298|Test loss: 3.77509141\n","Epoch: 481 | Lr: 0.00100000000000000002 |Train loss: 2.69434561|Test loss: 3.66267037\n","Epoch: 482 | Lr: 0.00100000000000000002 |Train loss: 2.65247579|Test loss: 3.52508942\n","Epoch: 483 | Lr: 0.00100000000000000002 |Train loss: 2.65856723|Test loss: 3.33807429\n","Epoch: 484 | Lr: 0.00100000000000000002 |Train loss: 2.66085845|Test loss: 3.45272501\n","Epoch: 485 | Lr: 0.00100000000000000002 |Train loss: 2.63572894|Test loss: 3.43905234\n","Epoch: 486 | Lr: 0.00100000000000000002 |Train loss: 2.66831392|Test loss: 3.32826638\n","Epoch: 487 | Lr: 0.00100000000000000002 |Train loss: 2.66028841|Test loss: 3.32757624\n","Epoch: 488 | Lr: 0.00100000000000000002 |Train loss: 2.63453090|Test loss: 3.54618851\n","Epoch: 489 | Lr: 0.00100000000000000002 |Train loss: 2.60579437|Test loss: 3.60402576\n","Epoch: 490 | Lr: 0.00100000000000000002 |Train loss: 2.59181305|Test loss: 3.55157463\n","Epoch: 491 | Lr: 0.00100000000000000002 |Train loss: 2.62634720|Test loss: 3.40011048\n","Epoch: 492 | Lr: 0.00100000000000000002 |Train loss: 2.69001275|Test loss: 3.59883420\n","Epoch: 493 | Lr: 0.00100000000000000002 |Train loss: 2.78516430|Test loss: 3.56921840\n","Epoch: 494 | Lr: 0.00100000000000000002 |Train loss: 2.75988549|Test loss: 3.93867254\n","Epoch: 495 | Lr: 0.00100000000000000002 |Train loss: 2.85103188|Test loss: 3.82158971\n","Epoch: 496 | Lr: 0.00100000000000000002 |Train loss: 2.76738910|Test loss: 3.63992437\n","Epoch: 497 | Lr: 0.00100000000000000002 |Train loss: 2.71777487|Test loss: 3.83988587\n","Epoch: 498 | Lr: 0.00100000000000000002 |Train loss: 2.71777469|Test loss: 3.36554249\n","Epoch: 499 | Lr: 0.00100000000000000002 |Train loss: 2.67359595|Test loss: 3.31450772\n","Epoch: 500 | Lr: 0.00100000000000000002 |Train loss: 2.68785038|Test loss: 3.32368183\n","Epoch: 501 | Lr: 0.00100000000000000002 |Train loss: 2.65726519|Test loss: 3.41054026\n","Epoch: 502 | Lr: 0.00100000000000000002 |Train loss: 2.58651920|Test loss: 3.39323902\n","Epoch: 503 | Lr: 0.00100000000000000002 |Train loss: 2.62665411|Test loss: 3.44643521\n","Epoch: 504 | Lr: 0.00100000000000000002 |Train loss: 2.61985775|Test loss: 3.55172261\n","Epoch: 505 | Lr: 0.00100000000000000002 |Train loss: 2.66523510|Test loss: 3.68390775\n","Epoch: 506 | Lr: 0.00100000000000000002 |Train loss: 2.67668583|Test loss: 3.88959368\n","Epoch: 507 | Lr: 0.00100000000000000002 |Train loss: 2.70023962|Test loss: 3.82795008\n","Epoch: 508 | Lr: 0.00100000000000000002 |Train loss: 2.68303243|Test loss: 3.66345541\n","Epoch: 509 | Lr: 0.00100000000000000002 |Train loss: 2.65838208|Test loss: 3.88058138\n","Epoch: 510 | Lr: 0.00100000000000000002 |Train loss: 2.68505218|Test loss: 3.40397445\n","Epoch: 511 | Lr: 0.00100000000000000002 |Train loss: 2.77058645|Test loss: 3.40038196\n","Epoch: 512 | Lr: 0.00100000000000000002 |Train loss: 2.64244525|Test loss: 3.35150329\n","Epoch: 513 | Lr: 0.00100000000000000002 |Train loss: 2.59352533|Test loss: 3.31782707\n","Epoch: 514 | Lr: 0.00100000000000000002 |Train loss: 2.67173258|Test loss: 3.66421676\n","Epoch: 515 | Lr: 0.00100000000000000002 |Train loss: 2.63109779|Test loss: 3.55757960\n","Epoch: 516 | Lr: 0.00100000000000000002 |Train loss: 2.60713567|Test loss: 3.63585830\n","Epoch: 517 | Lr: 0.00100000000000000002 |Train loss: 2.56101996|Test loss: 3.88703839\n","Epoch: 518 | Lr: 0.00100000000000000002 |Train loss: 2.58489023|Test loss: 3.66953540\n","Epoch: 519 | Lr: 0.00100000000000000002 |Train loss: 2.59354063|Test loss: 3.72990910\n","Epoch: 520 | Lr: 0.00100000000000000002 |Train loss: 2.58844340|Test loss: 3.62125619\n","Epoch: 521 | Lr: 0.00100000000000000002 |Train loss: 2.57813489|Test loss: 3.73910618\n","Epoch: 522 | Lr: 0.00100000000000000002 |Train loss: 2.65922767|Test loss: 3.46943895\n","Epoch: 523 | Lr: 0.00100000000000000002 |Train loss: 2.72083026|Test loss: 3.22902489\n","Epoch: 524 | Lr: 0.00100000000000000002 |Train loss: 2.72337878|Test loss: 3.31515781\n","Epoch: 525 | Lr: 0.00100000000000000002 |Train loss: 2.67923490|Test loss: 3.27674270\n","Epoch: 526 | Lr: 0.00100000000000000002 |Train loss: 2.60221626|Test loss: 3.44368807\n","Epoch: 527 | Lr: 0.00100000000000000002 |Train loss: 2.70050667|Test loss: 3.48854224\n","Epoch: 528 | Lr: 0.00100000000000000002 |Train loss: 2.61569532|Test loss: 3.73749248\n","Epoch: 529 | Lr: 0.00100000000000000002 |Train loss: 2.58711791|Test loss: 3.66996980\n","Epoch: 530 | Lr: 0.00100000000000000002 |Train loss: 2.58086425|Test loss: 3.81159457\n","Epoch: 531 | Lr: 0.00100000000000000002 |Train loss: 2.58142183|Test loss: 3.63526416\n","Epoch: 532 | Lr: 0.00100000000000000002 |Train loss: 2.64983797|Test loss: 3.65320865\n","Epoch: 533 | Lr: 0.00100000000000000002 |Train loss: 2.66177062|Test loss: 3.25094978\n","Epoch: 534 | Lr: 0.00100000000000000002 |Train loss: 2.68232999|Test loss: 3.27737149\n","Epoch: 535 | Lr: 0.00100000000000000002 |Train loss: 2.63409803|Test loss: 3.30404655\n","Epoch: 536 | Lr: 0.00100000000000000002 |Train loss: 2.56653120|Test loss: 3.37060603\n","Epoch: 537 | Lr: 0.00100000000000000002 |Train loss: 2.55878264|Test loss: 3.26817536\n","Epoch: 538 | Lr: 0.00100000000000000002 |Train loss: 2.61692343|Test loss: 3.64400109\n","Epoch: 539 | Lr: 0.00100000000000000002 |Train loss: 2.63323005|Test loss: 3.77647765\n","Epoch: 540 | Lr: 0.00100000000000000002 |Train loss: 2.59657693|Test loss: 4.03450338\n","Epoch: 541 | Lr: 0.00100000000000000002 |Train loss: 2.59215420|Test loss: 3.80275019\n","Epoch: 542 | Lr: 0.00100000000000000002 |Train loss: 2.57333501|Test loss: 3.70008286\n","Epoch: 543 | Lr: 0.00100000000000000002 |Train loss: 2.55099654|Test loss: 3.60088952\n","Epoch: 544 | Lr: 0.00100000000000000002 |Train loss: 2.63775432|Test loss: 3.27508529\n","Epoch: 545 | Lr: 0.00100000000000000002 |Train loss: 2.67185748|Test loss: 3.30273644\n","Epoch: 546 | Lr: 0.00100000000000000002 |Train loss: 2.69651083|Test loss: 3.37241840\n","Epoch: 547 | Lr: 0.00100000000000000002 |Train loss: 2.61102808|Test loss: 3.39213133\n","Epoch: 548 | Lr: 0.00100000000000000002 |Train loss: 2.57934974|Test loss: 3.32184013\n","Epoch: 549 | Lr: 0.00100000000000000002 |Train loss: 2.70365882|Test loss: 3.59280348\n","Epoch: 550 | Lr: 0.00100000000000000002 |Train loss: 2.65337425|Test loss: 3.76954468\n","Epoch: 551 | Lr: 0.00100000000000000002 |Train loss: 2.63168218|Test loss: 3.55640101\n","Epoch: 552 | Lr: 0.00100000000000000002 |Train loss: 2.57657516|Test loss: 3.42937414\n","Epoch: 553 | Lr: 0.00100000000000000002 |Train loss: 2.60388289|Test loss: 3.39433877\n","Epoch: 554 | Lr: 0.00100000000000000002 |Train loss: 2.59790917|Test loss: 3.36668126\n","Epoch: 555 | Lr: 0.00100000000000000002 |Train loss: 2.58177980|Test loss: 3.39472429\n","Epoch: 556 | Lr: 0.00100000000000000002 |Train loss: 2.58517838|Test loss: 3.24238626\n","Epoch: 557 | Lr: 0.00100000000000000002 |Train loss: 2.56376312|Test loss: 3.45744061\n","Epoch: 558 | Lr: 0.00100000000000000002 |Train loss: 2.63518002|Test loss: 3.65431770\n","Epoch: 559 | Lr: 0.00100000000000000002 |Train loss: 2.62846575|Test loss: 3.69026780\n","Epoch: 560 | Lr: 0.00100000000000000002 |Train loss: 2.58296855|Test loss: 3.72400578\n","Epoch: 561 | Lr: 0.00100000000000000002 |Train loss: 2.56148628|Test loss: 3.73445257\n","Epoch: 562 | Lr: 0.00100000000000000002 |Train loss: 2.53206523|Test loss: 3.45716691\n","Epoch: 563 | Lr: 0.00100000000000000002 |Train loss: 2.51234072|Test loss: 3.61360661\n","Epoch: 564 | Lr: 0.00100000000000000002 |Train loss: 2.55544184|Test loss: 3.63295301\n","Epoch: 565 | Lr: 0.00100000000000000002 |Train loss: 2.55354150|Test loss: 3.23467048\n","Epoch: 566 | Lr: 0.00100000000000000002 |Train loss: 2.57837206|Test loss: 3.63364792\n","Epoch: 567 | Lr: 0.00100000000000000002 |Train loss: 2.63052148|Test loss: 3.31405671\n","Epoch: 568 | Lr: 0.00100000000000000002 |Train loss: 2.59270114|Test loss: 3.34436361\n","Epoch: 569 | Lr: 0.00100000000000000002 |Train loss: 2.63662269|Test loss: 3.35481032\n","Epoch: 570 | Lr: 0.00100000000000000002 |Train loss: 2.62637166|Test loss: 3.48005247\n","Epoch: 571 | Lr: 0.00100000000000000002 |Train loss: 2.73530553|Test loss: 3.64286764\n","Epoch: 572 | Lr: 0.00100000000000000002 |Train loss: 2.68187380|Test loss: 3.52313662\n","Epoch: 573 | Lr: 0.00100000000000000002 |Train loss: 2.60813077|Test loss: 3.89440902\n","Epoch: 574 | Lr: 0.00100000000000000002 |Train loss: 2.52562300|Test loss: 3.72989996\n","Epoch: 575 | Lr: 0.00100000000000000002 |Train loss: 2.48998181|Test loss: 3.61324732\n","Epoch: 576 | Lr: 0.00100000000000000002 |Train loss: 2.56223009|Test loss: 3.42616296\n","Epoch: 577 | Lr: 0.00100000000000000002 |Train loss: 2.52677693|Test loss: 3.35500789\n","Epoch: 578 | Lr: 0.00100000000000000002 |Train loss: 2.53067865|Test loss: 3.20846375\n","Epoch: 579 | Lr: 0.00100000000000000002 |Train loss: 2.56037406|Test loss: 3.29465405\n","Epoch: 580 | Lr: 0.00100000000000000002 |Train loss: 2.49795578|Test loss: 3.25817180\n","Epoch: 581 | Lr: 0.00100000000000000002 |Train loss: 2.48903646|Test loss: 3.45036364\n","Epoch: 582 | Lr: 0.00100000000000000002 |Train loss: 2.47052677|Test loss: 3.28021526\n","Epoch: 583 | Lr: 0.00100000000000000002 |Train loss: 2.46771409|Test loss: 3.50403500\n","Epoch: 584 | Lr: 0.00100000000000000002 |Train loss: 2.62968951|Test loss: 3.40774051\n","Epoch: 585 | Lr: 0.00100000000000000002 |Train loss: 2.54904282|Test loss: 3.47336753\n","Epoch: 586 | Lr: 0.00100000000000000002 |Train loss: 2.53479858|Test loss: 3.39489929\n","Epoch: 587 | Lr: 0.00100000000000000002 |Train loss: 2.54250147|Test loss: 3.66172989\n","Epoch: 588 | Lr: 0.00100000000000000002 |Train loss: 2.52735968|Test loss: 3.70398108\n","Epoch: 589 | Lr: 0.00100000000000000002 |Train loss: 2.56709296|Test loss: 3.60328380\n","Epoch: 590 | Lr: 0.00100000000000000002 |Train loss: 2.48594630|Test loss: 3.81053146\n","Epoch: 591 | Lr: 0.00100000000000000002 |Train loss: 2.49628472|Test loss: 3.43343655\n","Epoch: 592 | Lr: 0.00100000000000000002 |Train loss: 2.54318116|Test loss: 3.28552349\n","Epoch: 593 | Lr: 0.00100000000000000002 |Train loss: 2.71692010|Test loss: 3.23829643\n","Epoch: 594 | Lr: 0.00100000000000000002 |Train loss: 2.67117184|Test loss: 3.36192369\n","Epoch: 595 | Lr: 0.00100000000000000002 |Train loss: 2.62408902|Test loss: 3.42957322\n","Epoch: 596 | Lr: 0.00100000000000000002 |Train loss: 2.58465594|Test loss: 3.24076748\n","Epoch: 597 | Lr: 0.00100000000000000002 |Train loss: 2.54621404|Test loss: 3.41801143\n","Epoch: 598 | Lr: 0.00100000000000000002 |Train loss: 2.60637770|Test loss: 3.34505788\n","Epoch: 599 | Lr: 0.00100000000000000002 |Train loss: 2.51850353|Test loss: 3.53031532\n","Epoch: 600 | Lr: 0.00100000000000000002 |Train loss: 2.49704736|Test loss: 3.60567689\n","Epoch: 601 | Lr: 0.00100000000000000002 |Train loss: 2.48551931|Test loss: 3.58987761\n","Epoch: 602 | Lr: 0.00100000000000000002 |Train loss: 2.49922492|Test loss: 4.46456623\n","Epoch: 603 | Lr: 0.00100000000000000002 |Train loss: 2.55138385|Test loss: 3.79285717\n","Epoch: 604 | Lr: 0.00100000000000000002 |Train loss: 2.52373614|Test loss: 3.38753438\n","Epoch: 605 | Lr: 0.00100000000000000002 |Train loss: 2.71741637|Test loss: 3.32053463\n","Epoch: 606 | Lr: 0.00100000000000000002 |Train loss: 2.74491302|Test loss: 3.39263201\n","Epoch: 607 | Lr: 0.00100000000000000002 |Train loss: 2.57023066|Test loss: 3.27820595\n","Epoch: 608 | Lr: 0.00100000000000000002 |Train loss: 2.48991984|Test loss: 3.29637567\n","Epoch: 609 | Lr: 0.00100000000000000002 |Train loss: 2.46188883|Test loss: 3.33453035\n","Epoch: 610 | Lr: 0.00100000000000000002 |Train loss: 2.46671055|Test loss: 3.25888618\n","Epoch: 611 | Lr: 0.00100000000000000002 |Train loss: 2.42615672|Test loss: 3.41302713\n","Epoch: 612 | Lr: 0.00100000000000000002 |Train loss: 2.45572823|Test loss: 3.32006820\n","Epoch: 613 | Lr: 0.00100000000000000002 |Train loss: 2.46283408|Test loss: 3.47534943\n","Epoch: 614 | Lr: 0.00100000000000000002 |Train loss: 2.46014561|Test loss: 3.65408858\n","Epoch: 615 | Lr: 0.00100000000000000002 |Train loss: 2.51273616|Test loss: 3.63623969\n","Epoch: 616 | Lr: 0.00100000000000000002 |Train loss: 2.48293269|Test loss: 3.56004167\n","Epoch: 617 | Lr: 0.00100000000000000002 |Train loss: 2.56028992|Test loss: 3.19580793\n","Epoch: 618 | Lr: 0.00100000000000000002 |Train loss: 2.65407437|Test loss: 3.29800463\n","Epoch: 619 | Lr: 0.00100000000000000002 |Train loss: 2.59279436|Test loss: 3.44676836\n","Epoch: 620 | Lr: 0.00100000000000000002 |Train loss: 2.51335661|Test loss: 3.14817580\n","Epoch: 621 | Lr: 0.00100000000000000002 |Train loss: 2.47884508|Test loss: 3.22840031\n","Epoch: 622 | Lr: 0.00100000000000000002 |Train loss: 2.48501815|Test loss: 3.29317498\n","Epoch: 623 | Lr: 0.00100000000000000002 |Train loss: 2.56183473|Test loss: 3.39458068\n","Epoch: 624 | Lr: 0.00100000000000000002 |Train loss: 2.58616233|Test loss: 3.58526850\n","Epoch: 625 | Lr: 0.00100000000000000002 |Train loss: 2.59120729|Test loss: 3.60363984\n","Epoch: 626 | Lr: 0.00100000000000000002 |Train loss: 2.52710917|Test loss: 3.66935714\n","Epoch: 627 | Lr: 0.00100000000000000002 |Train loss: 2.48822415|Test loss: 3.45880278\n","Epoch: 628 | Lr: 0.00100000000000000002 |Train loss: 2.47361873|Test loss: 3.43854729\n","Epoch: 629 | Lr: 0.00100000000000000002 |Train loss: 2.53262951|Test loss: 3.25001216\n","Epoch: 630 | Lr: 0.00100000000000000002 |Train loss: 2.51069818|Test loss: 3.25584404\n","Epoch: 631 | Lr: 0.00100000000000000002 |Train loss: 2.53020183|Test loss: 3.35441446\n","Epoch: 632 | Lr: 0.00100000000000000002 |Train loss: 2.45050716|Test loss: 3.26912189\n","Epoch: 633 | Lr: 0.00100000000000000002 |Train loss: 2.43466814|Test loss: 3.28481412\n","Epoch: 634 | Lr: 0.00100000000000000002 |Train loss: 2.55648200|Test loss: 3.52680604\n","Epoch: 635 | Lr: 0.00100000000000000002 |Train loss: 2.56086797|Test loss: 3.52223237\n","Epoch: 636 | Lr: 0.00100000000000000002 |Train loss: 2.49404556|Test loss: 3.41291944\n","Epoch: 637 | Lr: 0.00100000000000000002 |Train loss: 2.41756584|Test loss: 3.45734406\n","Epoch: 638 | Lr: 0.00100000000000000002 |Train loss: 2.45750278|Test loss: 3.60316801\n","Epoch: 639 | Lr: 0.00100000000000000002 |Train loss: 2.49836159|Test loss: 3.57463257\n","Epoch: 640 | Lr: 0.00100000000000000002 |Train loss: 2.45283373|Test loss: 3.43657907\n","Epoch: 641 | Lr: 0.00100000000000000002 |Train loss: 2.40554508|Test loss: 3.22748915\n","Epoch: 642 | Lr: 0.00100000000000000002 |Train loss: 2.42627402|Test loss: 3.19760625\n","Epoch: 643 | Lr: 0.00100000000000000002 |Train loss: 2.46601661|Test loss: 3.24066194\n","Epoch: 644 | Lr: 0.00100000000000000002 |Train loss: 2.47144028|Test loss: 3.41561254\n","Epoch: 645 | Lr: 0.00100000000000000002 |Train loss: 2.45072303|Test loss: 3.54763611\n","Epoch: 646 | Lr: 0.00100000000000000002 |Train loss: 2.43003136|Test loss: 3.28201294\n","Epoch: 647 | Lr: 0.00100000000000000002 |Train loss: 2.43124982|Test loss: 3.28809436\n","Epoch: 648 | Lr: 0.00100000000000000002 |Train loss: 2.51846967|Test loss: 3.37314963\n","Epoch: 649 | Lr: 0.00100000000000000002 |Train loss: 2.59721569|Test loss: 3.67220823\n","Epoch: 650 | Lr: 0.00100000000000000002 |Train loss: 2.55657691|Test loss: 3.67767485\n","Epoch: 651 | Lr: 0.00100000000000000002 |Train loss: 2.48394092|Test loss: 3.74696080\n","Epoch: 652 | Lr: 0.00100000000000000002 |Train loss: 2.50595244|Test loss: 3.43173051\n","Epoch: 653 | Lr: 0.00100000000000000002 |Train loss: 2.60650625|Test loss: 3.34885589\n","Epoch: 654 | Lr: 0.00100000000000000002 |Train loss: 2.68541235|Test loss: 3.37292449\n","Epoch: 655 | Lr: 0.00100000000000000002 |Train loss: 2.60429959|Test loss: 3.29258108\n","Epoch: 656 | Lr: 0.00100000000000000002 |Train loss: 2.49679001|Test loss: 3.25003751\n","Epoch: 657 | Lr: 0.00100000000000000002 |Train loss: 2.68554101|Test loss: 3.61425304\n","Epoch: 658 | Lr: 0.00100000000000000002 |Train loss: 2.53710143|Test loss: 3.63132707\n","Epoch: 659 | Lr: 0.00100000000000000002 |Train loss: 2.50818038|Test loss: 3.50533064\n","Epoch: 660 | Lr: 0.00100000000000000002 |Train loss: 2.42172442|Test loss: 3.32978304\n","Epoch: 661 | Lr: 0.00100000000000000002 |Train loss: 2.45023263|Test loss: 3.42749834\n","Epoch: 662 | Lr: 0.00100000000000000002 |Train loss: 2.47138828|Test loss: 3.31471960\n","Epoch: 663 | Lr: 0.00100000000000000002 |Train loss: 2.52313683|Test loss: 3.10695338\n","Epoch: 664 | Lr: 0.00100000000000000002 |Train loss: 2.51709753|Test loss: 3.15489419\n","Epoch: 665 | Lr: 0.00100000000000000002 |Train loss: 2.55145375|Test loss: 3.23333406\n","Epoch: 666 | Lr: 0.00100000000000000002 |Train loss: 2.50422732|Test loss: 3.26429526\n","Epoch: 667 | Lr: 0.00100000000000000002 |Train loss: 2.53695714|Test loss: 3.27208622\n","Epoch: 668 | Lr: 0.00100000000000000002 |Train loss: 2.64974624|Test loss: 3.70526973\n","Epoch: 669 | Lr: 0.00100000000000000002 |Train loss: 2.69065209|Test loss: 3.62042721\n","Epoch: 670 | Lr: 0.00100000000000000002 |Train loss: 2.55034037|Test loss: 3.47800493\n","Epoch: 671 | Lr: 0.00100000000000000002 |Train loss: 2.46977383|Test loss: 3.33295067\n","Epoch: 672 | Lr: 0.00100000000000000002 |Train loss: 2.43828062|Test loss: 3.40472031\n","Epoch: 673 | Lr: 0.00100000000000000002 |Train loss: 2.42922479|Test loss: 3.28516237\n","Epoch: 674 | Lr: 0.00100000000000000002 |Train loss: 2.42763746|Test loss: 3.32958810\n","Epoch: 675 | Lr: 0.00100000000000000002 |Train loss: 2.42962164|Test loss: 3.22016168\n","Epoch: 676 | Lr: 0.00100000000000000002 |Train loss: 2.46683598|Test loss: 3.50546662\n","Epoch: 677 | Lr: 0.00100000000000000002 |Train loss: 2.51998927|Test loss: 3.57991529\n","Epoch: 678 | Lr: 0.00100000000000000002 |Train loss: 2.44248976|Test loss: 3.28809635\n","Epoch: 679 | Lr: 0.00100000000000000002 |Train loss: 2.43266139|Test loss: 3.26325202\n","Epoch: 680 | Lr: 0.00100000000000000002 |Train loss: 2.41875251|Test loss: 3.40024845\n","Epoch: 681 | Lr: 0.00100000000000000002 |Train loss: 2.40170596|Test loss: 3.38761306\n","Epoch: 682 | Lr: 0.00100000000000000002 |Train loss: 2.37766985|Test loss: 3.23444072\n","Epoch: 683 | Lr: 0.00100000000000000002 |Train loss: 2.35843954|Test loss: 3.30439997\n","Epoch: 684 | Lr: 0.00100000000000000002 |Train loss: 2.37992058|Test loss: 3.20857175\n","Epoch: 685 | Lr: 0.00100000000000000002 |Train loss: 2.39164575|Test loss: 3.31924478\n","Epoch: 686 | Lr: 0.00100000000000000002 |Train loss: 2.40480119|Test loss: 3.38219078\n","Epoch: 687 | Lr: 0.00100000000000000002 |Train loss: 2.46066002|Test loss: 3.68963703\n","Epoch: 688 | Lr: 0.00100000000000000002 |Train loss: 2.45769886|Test loss: 3.44619854\n","Epoch: 689 | Lr: 0.00100000000000000002 |Train loss: 2.41737064|Test loss: 3.48403589\n","Epoch: 690 | Lr: 0.00100000000000000002 |Train loss: 2.42831763|Test loss: 3.43885660\n","Epoch: 691 | Lr: 0.00100000000000000002 |Train loss: 2.42147497|Test loss: 3.92891947\n","Epoch: 692 | Lr: 0.00100000000000000002 |Train loss: 2.51444473|Test loss: 3.65052644\n","Epoch: 693 | Lr: 0.00100000000000000002 |Train loss: 2.48619207|Test loss: 3.16848214\n","Epoch: 694 | Lr: 0.00100000000000000002 |Train loss: 2.61609465|Test loss: 3.20131191\n","Epoch: 695 | Lr: 0.00100000000000000002 |Train loss: 2.62904501|Test loss: 3.30330213\n","Epoch: 696 | Lr: 0.00100000000000000002 |Train loss: 2.54656106|Test loss: 3.37287410\n","Epoch: 697 | Lr: 0.00100000000000000002 |Train loss: 2.47893540|Test loss: 3.12326535\n","Epoch: 698 | Lr: 0.00100000000000000002 |Train loss: 2.46737468|Test loss: 3.30165466\n","Epoch: 699 | Lr: 0.00100000000000000002 |Train loss: 2.49599377|Test loss: 3.71082910\n","Epoch: 700 | Lr: 0.00100000000000000002 |Train loss: 2.58975496|Test loss: 3.66634289\n","Epoch: 701 | Lr: 0.00100000000000000002 |Train loss: 2.50592174|Test loss: 3.45693763\n","Epoch: 702 | Lr: 0.00100000000000000002 |Train loss: 2.47031613|Test loss: 3.29603465\n","Epoch: 703 | Lr: 0.00100000000000000002 |Train loss: 2.49895020|Test loss: 3.17695093\n","Epoch: 704 | Lr: 0.00100000000000000002 |Train loss: 2.56882596|Test loss: 3.33946204\n","Epoch: 705 | Lr: 0.00100000000000000002 |Train loss: 2.56323989|Test loss: 3.24417591\n","Epoch: 706 | Lr: 0.00100000000000000002 |Train loss: 2.56630141|Test loss: 3.28224715\n","Epoch: 707 | Lr: 0.00100000000000000002 |Train loss: 2.55977025|Test loss: 3.51133657\n","Epoch: 708 | Lr: 0.00100000000000000002 |Train loss: 2.61776912|Test loss: 3.61669556\n","Epoch: 709 | Lr: 0.00100000000000000002 |Train loss: 2.55380972|Test loss: 3.28836377\n","Epoch: 710 | Lr: 0.00100000000000000002 |Train loss: 2.45589590|Test loss: 3.23197007\n","Epoch: 711 | Lr: 0.00100000000000000002 |Train loss: 2.41780160|Test loss: 3.30186423\n","Epoch: 712 | Lr: 0.00100000000000000002 |Train loss: 2.42333647|Test loss: 3.24327954\n","Epoch: 713 | Lr: 0.00100000000000000002 |Train loss: 2.41854833|Test loss: 3.23301363\n","Epoch: 714 | Lr: 0.00100000000000000002 |Train loss: 2.38096017|Test loss: 3.28408909\n","Epoch: 715 | Lr: 0.00100000000000000002 |Train loss: 2.50671452|Test loss: 3.54176251\n","Epoch: 716 | Lr: 0.00100000000000000002 |Train loss: 2.50707879|Test loss: 3.54798818\n","Epoch: 717 | Lr: 0.00100000000000000002 |Train loss: 2.48105997|Test loss: 3.41013543\n","Epoch: 718 | Lr: 0.00100000000000000002 |Train loss: 2.43301487|Test loss: 3.32547371\n","Epoch: 719 | Lr: 0.00100000000000000002 |Train loss: 2.38769104|Test loss: 3.28710922\n","Epoch: 720 | Lr: 0.00100000000000000002 |Train loss: 2.42032184|Test loss: 3.31261977\n","Epoch: 721 | Lr: 0.00100000000000000002 |Train loss: 2.45335885|Test loss: 3.24332881\n","Epoch: 722 | Lr: 0.00100000000000000002 |Train loss: 2.43008834|Test loss: 3.25258485\n","Epoch: 723 | Lr: 0.00100000000000000002 |Train loss: 2.37644454|Test loss: 3.26322714\n","Epoch: 724 | Lr: 0.00100000000000000002 |Train loss: 2.38132981|Test loss: 3.47874673\n","Epoch: 725 | Lr: 0.00100000000000000002 |Train loss: 2.36400406|Test loss: 3.27420155\n","Epoch: 726 | Lr: 0.00100000000000000002 |Train loss: 2.38829990|Test loss: 3.18293198\n","Epoch: 727 | Lr: 0.00100000000000000002 |Train loss: 2.50196413|Test loss: 3.29545196\n","Epoch: 728 | Lr: 0.00100000000000000002 |Train loss: 2.55170602|Test loss: 3.50156593\n","Epoch: 729 | Lr: 0.00100000000000000002 |Train loss: 2.66483746|Test loss: 3.51710788\n","Epoch: 730 | Lr: 0.00100000000000000002 |Train loss: 2.56732643|Test loss: 3.43949270\n","Epoch: 731 | Lr: 0.00100000000000000002 |Train loss: 2.49644856|Test loss: 3.24810910\n","Epoch: 732 | Lr: 0.00100000000000000002 |Train loss: 2.45466306|Test loss: 3.34004076\n","Epoch: 733 | Lr: 0.00100000000000000002 |Train loss: 2.44164546|Test loss: 3.25194581\n","Epoch: 734 | Lr: 0.00100000000000000002 |Train loss: 2.41536836|Test loss: 3.17575614\n","Epoch: 735 | Lr: 0.00100000000000000002 |Train loss: 2.43869621|Test loss: 3.31270997\n","Epoch: 736 | Lr: 0.00100000000000000002 |Train loss: 2.45893639|Test loss: 3.57769179\n","Epoch: 737 | Lr: 0.00100000000000000002 |Train loss: 2.47743324|Test loss: 3.32358376\n","Epoch: 738 | Lr: 0.00100000000000000002 |Train loss: 2.45683219|Test loss: 3.34733899\n","Epoch: 739 | Lr: 0.00100000000000000002 |Train loss: 2.40064941|Test loss: 3.34314720\n","Epoch: 740 | Lr: 0.00100000000000000002 |Train loss: 2.42799211|Test loss: 3.27732118\n","Epoch: 741 | Lr: 0.00100000000000000002 |Train loss: 2.40864903|Test loss: 3.24317670\n","Epoch: 742 | Lr: 0.00100000000000000002 |Train loss: 2.48746828|Test loss: 3.27250528\n","Epoch: 743 | Lr: 0.00100000000000000002 |Train loss: 2.46318692|Test loss: 3.33648523\n","Epoch: 744 | Lr: 0.00100000000000000002 |Train loss: 2.37065073|Test loss: 3.32224234\n","Epoch: 745 | Lr: 0.00100000000000000002 |Train loss: 2.37701170|Test loss: 3.34998878\n","Epoch: 746 | Lr: 0.00100000000000000002 |Train loss: 2.36757765|Test loss: 3.39375480\n","Epoch: 747 | Lr: 0.00100000000000000002 |Train loss: 2.36971257|Test loss: 3.37700701\n","Epoch: 748 | Lr: 0.00100000000000000002 |Train loss: 2.36176032|Test loss: 3.42896660\n","Epoch: 749 | Lr: 0.00100000000000000002 |Train loss: 2.34231027|Test loss: 3.45269624\n","Epoch: 750 | Lr: 0.00100000000000000002 |Train loss: 2.32966832|Test loss: 3.42715724\n","Epoch: 751 | Lr: 0.00100000000000000002 |Train loss: 2.31681559|Test loss: 3.30486361\n","Epoch: 752 | Lr: 0.00100000000000000002 |Train loss: 2.31899405|Test loss: 3.31558903\n","Epoch: 753 | Lr: 0.00100000000000000002 |Train loss: 2.36352648|Test loss: 3.41515048\n","Epoch: 754 | Lr: 0.00100000000000000002 |Train loss: 2.34482559|Test loss: 3.19654695\n","Epoch: 755 | Lr: 0.00100000000000000002 |Train loss: 2.41698413|Test loss: 3.12844308\n","Epoch: 756 | Lr: 0.00100000000000000002 |Train loss: 2.37951789|Test loss: 3.13718406\n","Epoch: 757 | Lr: 0.00100000000000000002 |Train loss: 2.36010005|Test loss: 3.15228224\n","Epoch: 758 | Lr: 0.00100000000000000002 |Train loss: 2.34782326|Test loss: 3.21698594\n","Epoch: 759 | Lr: 0.00100000000000000002 |Train loss: 2.37176021|Test loss: 3.19520640\n","Epoch: 760 | Lr: 0.00100000000000000002 |Train loss: 2.73353459|Test loss: 3.27916567\n","Epoch: 761 | Lr: 0.00100000000000000002 |Train loss: 2.76067479|Test loss: 3.47654907\n","Epoch: 762 | Lr: 0.00100000000000000002 |Train loss: 2.64226395|Test loss: 3.77200683\n","Epoch: 763 | Lr: 0.00100000000000000002 |Train loss: 2.57806267|Test loss: 3.81475377\n","Epoch: 764 | Lr: 0.00100000000000000002 |Train loss: 2.45501753|Test loss: 3.29795591\n","Epoch: 765 | Lr: 0.00100000000000000002 |Train loss: 2.45404847|Test loss: 3.23904252\n","Epoch: 766 | Lr: 0.00100000000000000002 |Train loss: 2.46153440|Test loss: 3.21974564\n","Epoch: 767 | Lr: 0.00100000000000000002 |Train loss: 2.46026820|Test loss: 3.14926950\n","Epoch: 768 | Lr: 0.00100000000000000002 |Train loss: 2.45804439|Test loss: 3.28259857\n","Epoch: 769 | Lr: 0.00100000000000000002 |Train loss: 2.41309096|Test loss: 3.26335835\n","Epoch: 770 | Lr: 0.00100000000000000002 |Train loss: 2.46163601|Test loss: 3.40501571\n","Epoch: 771 | Lr: 0.00100000000000000002 |Train loss: 2.57224639|Test loss: 3.65480828\n","Epoch: 772 | Lr: 0.00100000000000000002 |Train loss: 2.49615926|Test loss: 3.43159143\n","Epoch: 773 | Lr: 0.00100000000000000002 |Train loss: 2.37398281|Test loss: 3.27227648\n","Epoch: 774 | Lr: 0.00100000000000000002 |Train loss: 2.40727915|Test loss: 3.17049718\n","Epoch: 775 | Lr: 0.00100000000000000002 |Train loss: 2.38905736|Test loss: 3.15666580\n","Epoch: 776 | Lr: 0.00100000000000000002 |Train loss: 2.38802497|Test loss: 3.17359749\n","Epoch: 777 | Lr: 0.00100000000000000002 |Train loss: 2.36354790|Test loss: 3.16910044\n","Epoch: 778 | Lr: 0.00100000000000000002 |Train loss: 2.36551957|Test loss: 3.26164341\n","Epoch: 779 | Lr: 0.00100000000000000002 |Train loss: 2.41729989|Test loss: 3.32359441\n","Epoch: 780 | Lr: 0.00100000000000000002 |Train loss: 2.44252161|Test loss: 3.58130558\n","Epoch: 781 | Lr: 0.00100000000000000002 |Train loss: 2.52393633|Test loss: 3.57087072\n","Epoch: 782 | Lr: 0.00100000000000000002 |Train loss: 2.46729275|Test loss: 3.30476149\n","Epoch: 783 | Lr: 0.00100000000000000002 |Train loss: 2.41421980|Test loss: 3.33713277\n","Epoch: 784 | Lr: 0.00100000000000000002 |Train loss: 2.47000935|Test loss: 3.32943988\n","Epoch: 785 | Lr: 0.00100000000000000002 |Train loss: 2.41687308|Test loss: 3.22304320\n","Epoch: 786 | Lr: 0.00100000000000000002 |Train loss: 2.40853480|Test loss: 3.18035229\n","Epoch: 787 | Lr: 0.00100000000000000002 |Train loss: 2.39268686|Test loss: 3.15998069\n","Epoch: 788 | Lr: 0.00100000000000000002 |Train loss: 2.42916578|Test loss: 3.50222047\n","Epoch: 789 | Lr: 0.00100000000000000002 |Train loss: 2.52631609|Test loss: 3.68590426\n","Epoch: 790 | Lr: 0.00100000000000000002 |Train loss: 2.45237293|Test loss: 3.32518284\n","Epoch: 791 | Lr: 0.00100000000000000002 |Train loss: 2.39551069|Test loss: 3.32597343\n","Epoch: 792 | Lr: 0.00100000000000000002 |Train loss: 2.39331331|Test loss: 3.24001614\n","Epoch: 793 | Lr: 0.00100000000000000002 |Train loss: 2.42385926|Test loss: 3.15010516\n","Epoch: 794 | Lr: 0.00100000000000000002 |Train loss: 2.50699759|Test loss: 3.31218505\n","Epoch: 795 | Lr: 0.00100000000000000002 |Train loss: 2.40942007|Test loss: 3.53192012\n","Epoch: 796 | Lr: 0.00100000000000000002 |Train loss: 2.37040093|Test loss: 3.32052406\n","Epoch: 797 | Lr: 0.00100000000000000002 |Train loss: 2.34612099|Test loss: 3.29256336\n","Epoch: 798 | Lr: 0.00100000000000000002 |Train loss: 2.39522441|Test loss: 3.11333974\n","Epoch: 799 | Lr: 0.00100000000000000002 |Train loss: 2.39612273|Test loss: 3.34090161\n","Epoch: 800 | Lr: 0.00100000000000000002 |Train loss: 2.37139479|Test loss: 3.45403767\n","Epoch: 801 | Lr: 0.00100000000000000002 |Train loss: 2.35692064|Test loss: 3.49832209\n","Epoch: 802 | Lr: 0.00100000000000000002 |Train loss: 2.37543160|Test loss: 3.42845352\n","Epoch: 803 | Lr: 0.00100000000000000002 |Train loss: 2.34482753|Test loss: 3.51028911\n","Epoch: 804 | Lr: 0.00100000000000000002 |Train loss: 2.36990291|Test loss: 3.35799233\n","Epoch: 805 | Lr: 0.00100000000000000002 |Train loss: 2.46385805|Test loss: 3.27876973\n","Epoch: 806 | Lr: 0.00100000000000000002 |Train loss: 2.44182030|Test loss: 3.28399857\n","Epoch: 807 | Lr: 0.00100000000000000002 |Train loss: 2.40864879|Test loss: 3.31731693\n","Epoch: 808 | Lr: 0.00100000000000000002 |Train loss: 2.33498726|Test loss: 3.25592573\n","Epoch: 809 | Lr: 0.00100000000000000002 |Train loss: 2.33024633|Test loss: 3.20136738\n","Epoch: 810 | Lr: 0.00100000000000000002 |Train loss: 2.31733587|Test loss: 3.22602057\n","Epoch: 811 | Lr: 0.00100000000000000002 |Train loss: 2.29839573|Test loss: 3.24457391\n","Epoch: 812 | Lr: 0.00100000000000000002 |Train loss: 2.32650221|Test loss: 3.28461496\n","Epoch: 813 | Lr: 0.00100000000000000002 |Train loss: 2.33147046|Test loss: 3.27216101\n","Epoch: 814 | Lr: 0.00100000000000000002 |Train loss: 2.32169252|Test loss: 3.36018682\n","Epoch: 815 | Lr: 0.00100000000000000002 |Train loss: 2.30643652|Test loss: 3.53343248\n","Epoch: 816 | Lr: 0.00100000000000000002 |Train loss: 2.31882668|Test loss: 3.37314955\n","Epoch: 817 | Lr: 0.00100000000000000002 |Train loss: 2.33417352|Test loss: 3.28837331\n","Epoch: 818 | Lr: 0.00100000000000000002 |Train loss: 2.48206528|Test loss: 3.18964243\n","Epoch: 819 | Lr: 0.00100000000000000002 |Train loss: 2.58989880|Test loss: 3.26422962\n","Epoch: 820 | Lr: 0.00100000000000000002 |Train loss: 2.42608905|Test loss: 3.23622354\n","Epoch: 821 | Lr: 0.00100000000000000002 |Train loss: 2.42379626|Test loss: 3.34603492\n","Epoch: 822 | Lr: 0.00100000000000000002 |Train loss: 2.42858454|Test loss: 3.23516870\n","Epoch: 823 | Lr: 0.00100000000000000002 |Train loss: 2.51212690|Test loss: 3.52958417\n","Epoch: 824 | Lr: 0.00100000000000000002 |Train loss: 2.53886805|Test loss: 3.64503940\n","Epoch: 825 | Lr: 0.00100000000000000002 |Train loss: 2.41446825|Test loss: 3.33084687\n","Epoch: 826 | Lr: 0.00100000000000000002 |Train loss: 2.34825244|Test loss: 3.23714606\n","Epoch: 827 | Lr: 0.00100000000000000002 |Train loss: 2.36648021|Test loss: 3.20042562\n","Epoch: 828 | Lr: 0.00100000000000000002 |Train loss: 2.37097367|Test loss: 3.13006433\n","Epoch: 829 | Lr: 0.00100000000000000002 |Train loss: 2.39058133|Test loss: 3.23636564\n","Epoch: 830 | Lr: 0.00100000000000000002 |Train loss: 2.32698590|Test loss: 3.25350738\n","Epoch: 831 | Lr: 0.00100000000000000002 |Train loss: 2.36289291|Test loss: 3.59845503\n","Epoch: 832 | Lr: 0.00100000000000000002 |Train loss: 2.39593421|Test loss: 3.55769213\n","Epoch: 833 | Lr: 0.00100000000000000002 |Train loss: 2.34792513|Test loss: 3.45794956\n","Epoch: 834 | Lr: 0.00100000000000000002 |Train loss: 2.33572873|Test loss: 3.36698238\n","Epoch: 835 | Lr: 0.00100000000000000002 |Train loss: 2.35492357|Test loss: 3.13607550\n","Epoch: 836 | Lr: 0.00100000000000000002 |Train loss: 2.42126224|Test loss: 3.24208387\n","Epoch: 837 | Lr: 0.00100000000000000002 |Train loss: 2.45206354|Test loss: 3.16932845\n","Epoch: 838 | Lr: 0.00100000000000000002 |Train loss: 2.39086698|Test loss: 3.11026295\n","Epoch: 839 | Lr: 0.00100000000000000002 |Train loss: 2.35083826|Test loss: 3.19226011\n","Epoch: 840 | Lr: 0.00100000000000000002 |Train loss: 2.37511269|Test loss: 3.30888494\n","Epoch: 841 | Lr: 0.00100000000000000002 |Train loss: 2.34719332|Test loss: 3.24262595\n","Epoch: 842 | Lr: 0.00100000000000000002 |Train loss: 2.45750089|Test loss: 3.42985654\n","Epoch: 843 | Lr: 0.00100000000000000002 |Train loss: 2.39704392|Test loss: 3.59953570\n","Epoch: 844 | Lr: 0.00100000000000000002 |Train loss: 2.42168717|Test loss: 3.83001844\n","Epoch: 845 | Lr: 0.00100000000000000002 |Train loss: 2.42199012|Test loss: 3.48816665\n","Epoch: 846 | Lr: 0.00100000000000000002 |Train loss: 2.43874756|Test loss: 3.49521184\n","Epoch: 847 | Lr: 0.00100000000000000002 |Train loss: 2.46241595|Test loss: 3.15575798\n","Epoch: 848 | Lr: 0.00100000000000000002 |Train loss: 2.44383860|Test loss: 3.16489164\n","Epoch: 849 | Lr: 0.00100000000000000002 |Train loss: 2.42947779|Test loss: 3.16146811\n","Epoch: 850 | Lr: 0.00100000000000000002 |Train loss: 2.37504409|Test loss: 3.08151031\n","Epoch: 851 | Lr: 0.00100000000000000002 |Train loss: 2.39410319|Test loss: 3.37829971\n","Epoch: 852 | Lr: 0.00100000000000000002 |Train loss: 2.48172308|Test loss: 3.54071418\n","Epoch: 853 | Lr: 0.00100000000000000002 |Train loss: 2.45011604|Test loss: 3.27332727\n","Epoch: 854 | Lr: 0.00100000000000000002 |Train loss: 2.35585179|Test loss: 3.38988614\n","Epoch: 855 | Lr: 0.00100000000000000002 |Train loss: 2.32568544|Test loss: 3.24383386\n","Epoch: 856 | Lr: 0.00100000000000000002 |Train loss: 2.36036754|Test loss: 3.12948767\n","Epoch: 857 | Lr: 0.00100000000000000002 |Train loss: 2.42283591|Test loss: 3.37906965\n","Epoch: 858 | Lr: 0.00100000000000000002 |Train loss: 2.37292572|Test loss: 3.18183343\n","Epoch: 859 | Lr: 0.00100000000000000002 |Train loss: 2.33629979|Test loss: 3.13332224\n","Epoch: 860 | Lr: 0.00100000000000000002 |Train loss: 2.39141635|Test loss: 3.38052360\n","Epoch: 861 | Lr: 0.00100000000000000002 |Train loss: 2.44430385|Test loss: 3.41253058\n","Epoch: 862 | Lr: 0.00100000000000000002 |Train loss: 2.41370700|Test loss: 3.44002899\n","Epoch: 863 | Lr: 0.00100000000000000002 |Train loss: 2.34081233|Test loss: 3.48624992\n","Epoch: 864 | Lr: 0.00100000000000000002 |Train loss: 2.33353292|Test loss: 3.21468202\n","Epoch: 865 | Lr: 0.00100000000000000002 |Train loss: 2.41730671|Test loss: 3.19874771\n","Epoch: 866 | Lr: 0.00100000000000000002 |Train loss: 2.43985061|Test loss: 3.21665756\n","Epoch: 867 | Lr: 0.00100000000000000002 |Train loss: 2.40295398|Test loss: 3.28173621\n","Epoch: 868 | Lr: 0.00100000000000000002 |Train loss: 2.31807923|Test loss: 3.38257766\n","Epoch: 869 | Lr: 0.00100000000000000002 |Train loss: 2.35594926|Test loss: 3.42866667\n","Epoch: 870 | Lr: 0.00100000000000000002 |Train loss: 2.31566118|Test loss: 3.46271149\n","Epoch: 871 | Lr: 0.00100000000000000002 |Train loss: 2.28485967|Test loss: 3.39546609\n","Epoch: 872 | Lr: 0.00100000000000000002 |Train loss: 2.30505734|Test loss: 3.20836902\n","Epoch: 873 | Lr: 0.00100000000000000002 |Train loss: 2.32294260|Test loss: 3.36411158\n","Epoch: 874 | Lr: 0.00100000000000000002 |Train loss: 2.35637741|Test loss: 3.17097545\n","Epoch: 875 | Lr: 0.00100000000000000002 |Train loss: 2.35085322|Test loss: 3.25259018\n","Epoch: 876 | Lr: 0.00100000000000000002 |Train loss: 2.33625108|Test loss: 3.24951148\n","Epoch: 877 | Lr: 0.00100000000000000002 |Train loss: 2.33286858|Test loss: 3.35361711\n","Epoch: 878 | Lr: 0.00100000000000000002 |Train loss: 2.41457110|Test loss: 3.34521786\n","Epoch: 879 | Lr: 0.00100000000000000002 |Train loss: 2.46854216|Test loss: 3.73905253\n","Epoch: 880 | Lr: 0.00100000000000000002 |Train loss: 2.43542365|Test loss: 3.33677538\n","Epoch: 881 | Lr: 0.00100000000000000002 |Train loss: 2.38357004|Test loss: 3.14856704\n","Epoch: 882 | Lr: 0.00100000000000000002 |Train loss: 2.33804965|Test loss: 3.31190451\n","Epoch: 883 | Lr: 0.00100000000000000002 |Train loss: 2.32799213|Test loss: 3.32299471\n","Epoch: 884 | Lr: 0.00100000000000000002 |Train loss: 2.29646960|Test loss: 3.28717526\n","Epoch: 885 | Lr: 0.00100000000000000002 |Train loss: 2.27596487|Test loss: 3.15088646\n","Epoch: 886 | Lr: 0.00100000000000000002 |Train loss: 2.27941729|Test loss: 3.15454491\n","Epoch: 887 | Lr: 0.00100000000000000002 |Train loss: 2.26415589|Test loss: 3.20483279\n","Epoch: 888 | Lr: 0.00100000000000000002 |Train loss: 2.26965329|Test loss: 3.48788079\n","Epoch: 889 | Lr: 0.00100000000000000002 |Train loss: 2.30630253|Test loss: 3.51357778\n","Epoch: 890 | Lr: 0.00100000000000000002 |Train loss: 2.36330820|Test loss: 3.32200225\n","Epoch: 891 | Lr: 0.00100000000000000002 |Train loss: 2.30752276|Test loss: 3.40853739\n","Epoch: 892 | Lr: 0.00100000000000000002 |Train loss: 2.29582090|Test loss: 3.50099333\n","Epoch: 893 | Lr: 0.00100000000000000002 |Train loss: 2.26496843|Test loss: 3.35050186\n","Epoch: 894 | Lr: 0.00100000000000000002 |Train loss: 2.32863573|Test loss: 3.41451192\n","Epoch: 895 | Lr: 0.00100000000000000002 |Train loss: 2.36991407|Test loss: 3.19542376\n","Epoch: 896 | Lr: 0.00100000000000000002 |Train loss: 2.32481625|Test loss: 3.16892258\n","Epoch: 897 | Lr: 0.00100000000000000002 |Train loss: 2.32437147|Test loss: 3.14548373\n","Epoch: 898 | Lr: 0.00100000000000000002 |Train loss: 2.34450164|Test loss: 3.13451656\n","Epoch: 899 | Lr: 0.00100000000000000002 |Train loss: 2.32287836|Test loss: 3.23478484\n","Epoch: 900 | Lr: 0.00100000000000000002 |Train loss: 2.32879442|Test loss: 3.23450875\n","Epoch: 901 | Lr: 0.00100000000000000002 |Train loss: 2.37505844|Test loss: 3.45413518\n","Epoch: 902 | Lr: 0.00100000000000000002 |Train loss: 2.37579970|Test loss: 3.54899518\n","Epoch: 903 | Lr: 0.00100000000000000002 |Train loss: 2.50824959|Test loss: 3.46878465\n","Epoch: 904 | Lr: 0.00100000000000000002 |Train loss: 2.36726487|Test loss: 3.36711693\n","Epoch: 905 | Lr: 0.00100000000000000002 |Train loss: 2.32107959|Test loss: 3.57897735\n","Epoch: 906 | Lr: 0.00100000000000000002 |Train loss: 2.27708592|Test loss: 3.41941841\n","Epoch: 907 | Lr: 0.00100000000000000002 |Train loss: 2.26612001|Test loss: 3.16570759\n","Epoch: 908 | Lr: 0.00100000000000000002 |Train loss: 2.47533963|Test loss: 3.11138765\n","Epoch: 909 | Lr: 0.00100000000000000002 |Train loss: 2.36531736|Test loss: 3.17387581\n","Epoch: 910 | Lr: 0.00100000000000000002 |Train loss: 2.30372972|Test loss: 3.19754450\n","Epoch: 911 | Lr: 0.00100000000000000002 |Train loss: 2.23364961|Test loss: 3.17311104\n","Epoch: 912 | Lr: 0.00100000000000000002 |Train loss: 2.22596083|Test loss: 3.26171645\n","Epoch: 913 | Lr: 0.00100000000000000002 |Train loss: 2.23467954|Test loss: 3.23778303\n","Epoch: 914 | Lr: 0.00100000000000000002 |Train loss: 2.22225776|Test loss: 3.38348341\n","Epoch: 915 | Lr: 0.00100000000000000002 |Train loss: 2.24150090|Test loss: 3.54055595\n","Epoch: 916 | Lr: 0.00100000000000000002 |Train loss: 2.24752568|Test loss: 3.54318047\n","Epoch: 917 | Lr: 0.00100000000000000002 |Train loss: 2.23064875|Test loss: 3.20982965\n","Epoch: 918 | Lr: 0.00100000000000000002 |Train loss: 2.21041472|Test loss: 3.08642538\n","Epoch: 919 | Lr: 0.00100000000000000002 |Train loss: 2.25663346|Test loss: 3.05244191\n","Epoch: 920 | Lr: 0.00100000000000000002 |Train loss: 2.29163565|Test loss: 3.26728853\n","Epoch: 921 | Lr: 0.00100000000000000002 |Train loss: 2.25043702|Test loss: 3.27334197\n","Epoch: 922 | Lr: 0.00100000000000000002 |Train loss: 2.26511051|Test loss: 3.30145152\n","Epoch: 923 | Lr: 0.00100000000000000002 |Train loss: 2.27247007|Test loss: 3.21145916\n","Epoch: 924 | Lr: 0.00100000000000000002 |Train loss: 2.35050943|Test loss: 3.09925461\n","Epoch: 925 | Lr: 0.00100000000000000002 |Train loss: 2.33496796|Test loss: 3.15169668\n","Epoch: 926 | Lr: 0.00100000000000000002 |Train loss: 2.31029996|Test loss: 3.14441975\n","Epoch: 927 | Lr: 0.00100000000000000002 |Train loss: 2.40760231|Test loss: 3.50432309\n","Epoch: 928 | Lr: 0.00100000000000000002 |Train loss: 2.40550150|Test loss: 3.45153483\n","Epoch: 929 | Lr: 0.00100000000000000002 |Train loss: 2.37346080|Test loss: 3.15291278\n","Epoch: 930 | Lr: 0.00100000000000000002 |Train loss: 2.28509035|Test loss: 3.39413341\n","Epoch: 931 | Lr: 0.00100000000000000002 |Train loss: 2.35576680|Test loss: 3.54805954\n","Epoch: 932 | Lr: 0.00100000000000000002 |Train loss: 2.26704362|Test loss: 3.38931338\n","Epoch: 933 | Lr: 0.00100000000000000002 |Train loss: 2.24312431|Test loss: 3.29727340\n","Epoch: 934 | Lr: 0.00100000000000000002 |Train loss: 2.31423054|Test loss: 3.10243122\n","Epoch: 935 | Lr: 0.00100000000000000002 |Train loss: 2.51048454|Test loss: 3.13723954\n","Epoch: 936 | Lr: 0.00100000000000000002 |Train loss: 2.49222636|Test loss: 3.31572413\n","Epoch: 937 | Lr: 0.00100000000000000002 |Train loss: 2.38497889|Test loss: 3.31794937\n","Epoch: 938 | Lr: 0.00100000000000000002 |Train loss: 2.33631718|Test loss: 3.27601234\n","Epoch: 939 | Lr: 0.00100000000000000002 |Train loss: 2.37805437|Test loss: 3.56965486\n","Epoch: 940 | Lr: 0.00100000000000000002 |Train loss: 2.38700671|Test loss: 3.32017771\n","Epoch: 941 | Lr: 0.00100000000000000002 |Train loss: 2.36878030|Test loss: 3.48683397\n","Epoch: 942 | Lr: 0.00100000000000000002 |Train loss: 2.31835224|Test loss: 3.29260262\n","Epoch: 943 | Lr: 0.00100000000000000002 |Train loss: 2.28380105|Test loss: 3.27230175\n","Epoch: 944 | Lr: 0.00100000000000000002 |Train loss: 2.37504036|Test loss: 3.09559639\n","Epoch: 945 | Lr: 0.00100000000000000002 |Train loss: 2.39600156|Test loss: 3.17489425\n","Epoch: 946 | Lr: 0.00100000000000000002 |Train loss: 2.34232001|Test loss: 3.06954074\n","Epoch: 947 | Lr: 0.00100000000000000002 |Train loss: 2.34041834|Test loss: 3.51017396\n","Epoch: 948 | Lr: 0.00100000000000000002 |Train loss: 2.36100783|Test loss: 3.40285293\n","Epoch: 949 | Lr: 0.00100000000000000002 |Train loss: 2.32803539|Test loss: 3.24322637\n","Epoch: 950 | Lr: 0.00100000000000000002 |Train loss: 2.30103948|Test loss: 3.09855580\n","Epoch: 951 | Lr: 0.00100000000000000002 |Train loss: 2.28612415|Test loss: 3.06549040\n","Epoch: 952 | Lr: 0.00100000000000000002 |Train loss: 2.29210090|Test loss: 3.18662214\n","Epoch: 953 | Lr: 0.00100000000000000002 |Train loss: 2.31570058|Test loss: 3.24387805\n","Epoch: 954 | Lr: 0.00100000000000000002 |Train loss: 2.28222241|Test loss: 3.30022232\n","Epoch: 955 | Lr: 0.00100000000000000002 |Train loss: 2.27514748|Test loss: 3.16770323\n","Epoch: 956 | Lr: 0.00100000000000000002 |Train loss: 2.27127911|Test loss: 3.12461789\n","Epoch: 957 | Lr: 0.00100000000000000002 |Train loss: 2.31664593|Test loss: 3.57063166\n","Epoch: 958 | Lr: 0.00100000000000000002 |Train loss: 2.37496019|Test loss: 3.72260308\n","Epoch: 959 | Lr: 0.00100000000000000002 |Train loss: 2.41982871|Test loss: 3.24136511\n","Epoch: 960 | Lr: 0.00100000000000000002 |Train loss: 2.31769856|Test loss: 3.11950850\n","Epoch: 961 | Lr: 0.00100000000000000002 |Train loss: 2.32423460|Test loss: 3.18352159\n","Epoch: 962 | Lr: 0.00100000000000000002 |Train loss: 2.38363433|Test loss: 3.20587365\n","Epoch: 963 | Lr: 0.00100000000000000002 |Train loss: 2.31530274|Test loss: 3.16798290\n","Epoch: 964 | Lr: 0.00100000000000000002 |Train loss: 2.29938619|Test loss: 3.15254577\n","Epoch: 965 | Lr: 0.00100000000000000002 |Train loss: 2.30546363|Test loss: 3.21450337\n","Epoch: 966 | Lr: 0.00100000000000000002 |Train loss: 2.30677532|Test loss: 3.38530564\n","Epoch: 967 | Lr: 0.00100000000000000002 |Train loss: 2.31715633|Test loss: 3.58070445\n","Epoch: 968 | Lr: 0.00100000000000000002 |Train loss: 2.26814794|Test loss: 3.34785509\n","Epoch: 969 | Lr: 0.00100000000000000002 |Train loss: 2.22331123|Test loss: 3.34162625\n","Epoch: 970 | Lr: 0.00100000000000000002 |Train loss: 2.21455943|Test loss: 3.20533204\n","Epoch: 971 | Lr: 0.00100000000000000002 |Train loss: 2.22662954|Test loss: 3.11782519\n","Epoch: 972 | Lr: 0.00100000000000000002 |Train loss: 2.25318447|Test loss: 3.16028611\n","Epoch: 973 | Lr: 0.00100000000000000002 |Train loss: 2.24479862|Test loss: 3.17749548\n","Epoch: 974 | Lr: 0.00100000000000000002 |Train loss: 2.24423455|Test loss: 3.17486962\n","Epoch: 975 | Lr: 0.00100000000000000002 |Train loss: 2.21525055|Test loss: 3.24110389\n","Epoch: 976 | Lr: 0.00100000000000000002 |Train loss: 2.23138969|Test loss: 3.24548149\n","Epoch: 977 | Lr: 0.00100000000000000002 |Train loss: 2.22423180|Test loss: 3.45571057\n","Epoch: 978 | Lr: 0.00100000000000000002 |Train loss: 2.24312091|Test loss: 3.26366854\n","Epoch: 979 | Lr: 0.00100000000000000002 |Train loss: 2.23173730|Test loss: 3.34930317\n","Epoch: 980 | Lr: 0.00100000000000000002 |Train loss: 2.24050675|Test loss: 3.42021243\n","Epoch: 981 | Lr: 0.00100000000000000002 |Train loss: 2.29278862|Test loss: 3.29821587\n","Epoch: 982 | Lr: 0.00100000000000000002 |Train loss: 2.31968306|Test loss: 3.13886611\n","Epoch: 983 | Lr: 0.00100000000000000002 |Train loss: 2.32789358|Test loss: 3.11360383\n","Epoch: 984 | Lr: 0.00100000000000000002 |Train loss: 2.26053557|Test loss: 3.24835181\n","Epoch: 985 | Lr: 0.00100000000000000002 |Train loss: 2.24649868|Test loss: 3.21229474\n","Epoch: 986 | Lr: 0.00100000000000000002 |Train loss: 2.25238479|Test loss: 3.17368507\n","Epoch: 987 | Lr: 0.00100000000000000002 |Train loss: 2.27201417|Test loss: 3.57975125\n","Epoch: 988 | Lr: 0.00100000000000000002 |Train loss: 2.34741807|Test loss: 3.45980883\n","Epoch: 989 | Lr: 0.00100000000000000002 |Train loss: 2.26660310|Test loss: 3.19553272\n","Epoch: 990 | Lr: 0.00100000000000000002 |Train loss: 2.21480019|Test loss: 3.34533509\n","Epoch: 991 | Lr: 0.00100000000000000002 |Train loss: 2.22152118|Test loss: 3.41716647\n","Epoch: 992 | Lr: 0.00100000000000000002 |Train loss: 2.22804802|Test loss: 3.20059864\n","Epoch: 993 | Lr: 0.00100000000000000002 |Train loss: 2.34357565|Test loss: 3.12027685\n","Epoch: 994 | Lr: 0.00100000000000000002 |Train loss: 2.27509132|Test loss: 3.12900980\n","Epoch: 995 | Lr: 0.00100000000000000002 |Train loss: 2.30111856|Test loss: 3.13471468\n","Epoch: 996 | Lr: 0.00100000000000000002 |Train loss: 2.29755175|Test loss: 3.23694905\n","Epoch: 997 | Lr: 0.00100000000000000002 |Train loss: 2.29549042|Test loss: 3.15299877\n","Epoch: 998 | Lr: 0.00100000000000000002 |Train loss: 2.26753278|Test loss: 3.12992064\n","Epoch: 999 | Lr: 0.00100000000000000002 |Train loss: 2.30768332|Test loss: 3.30606111\n","Epoch: 1000 | Lr: 0.00100000000000000002 |Train loss: 2.31224945|Test loss: 3.42333921\n","\n","Training finished.\n","\n"]}]},{"cell_type":"code","source":["time_step = 5\n","feature_matrix = np.load('feature_matrix.npy')\n","corrlation = np.load('correlation_4.npy').astype(np.float32)\n","feature_matrix,target = normalization(feature_matrix)\n","feature_matrix = torch.tensor(feature_matrix.astype(np.float32))\n","adj = torch.tensor(corrlation)\n","target = torch.tensor(target.astype(np.float32))\n","features, results = get_features(time_step, feature_matrix)\n","train_idx = int(0.8*features.shape[0])\n","train_feature, train_result = features[:train_idx,:,:], results[:train_idx,:,:]\n","test_feature, test_result = features[train_idx:,:,:], results[train_idx:,:,:]"],"metadata":{"id":"P-tP4xrd9dfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_val_loss = np.inf\n","epochs = 1000\n","train_mean, test_mean = np.zeros((epochs,1)), np.zeros((epochs,1))\n","model = Generator(time_step*5+50, 32, 1).to(device)#time_step*5: feature nums, 32: hid layer, 1:output\n","loss = nn.MSELoss()\n","optimizer = optim.AdamW(model.parameters(),lr=0.001)\n","for epoch in tqdm_notebook(range(1,epochs + 1)):\n","    train_mean_loss, test_mean_loss, n, n1 = np.zeros((train_feature.shape[0],1)), np.zeros((test_feature.shape[0],1)), train_feature.shape[0], test_feature.shape[0]\n","    for i in range(n):\n","      #train_loss\n","      noise = torch.randn(train_feature.shape[1], 50)\n","      noise = torch.concat([noise, train_feature[i]], dim = 1) \n","      train = model(noise, adj)\n","      train_loss = loss(train, train_result[i])\n","      optimizer.zero_grad()\n","      train_loss.backward()\n","      optimizer.step()\n","      train_mean_loss[i] = train_loss.detach().numpy()\n","    for i in range(n1):\n","      noise2 = torch.randn(test_feature.shape[1], 50)\n","      noise2 = torch.concat([noise2, test_feature[i]], dim = 1)\n","      test = model(noise2, adj)\n","      test_loss = loss(test, test_result[i])\n","      test_mean_loss[i] = test_loss.detach().numpy()\n","    train_mean[epoch - 1], test_mean[epoch - 1] = train_mean_loss.mean(), test_mean_loss.mean()\n","    if mean_loss.mean() < min_val_loss:\n","      min_val_loss = mean_loss.mean()\n","    print('Epoch: {:03d} | Lr: {:.20f} |Train loss: {:.8f}|Test loss: {:.8f}'.\\\n","          format(epoch, optimizer.param_groups[0]['lr'], train_mean_loss.mean(), test_mean_loss.mean()))\n","print('\\nTraining finished.\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["124ffe1f9c4d452e956f0688ede67b9a","57ab8e1b4f9a4d0dafca068e860cdc91","650484bf2815451a8a8243fdbd8f86c0","efe8c1ad340b4476954f5ac1e2564341","a2a2552593a04307b157078f0a52df9c","2a95dee0a47348ce8bde3107072953a1","561afc96194a43a883c50b2767b4bd6b","6a733f2274ca42419eaec596d6e3313a","9a1eb3cfda51416e96b21631244dd5fb","6ed71de301464558bc5f9519f1eb03de","ca17199815bb4380946f1b09065d666a"]},"id":"5uPD5hC59dk0","executionInfo":{"status":"ok","timestamp":1661112862050,"user_tz":240,"elapsed":482987,"user":{"displayName":"Bowen Han","userId":"18105580727989418474"}},"outputId":"4989d261-d25c-4345-d8e0-92eb10007d55"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"124ffe1f9c4d452e956f0688ede67b9a"},"application/json":{"n":0,"total":1000,"elapsed":0.04411029815673828,"ncols":null,"nrows":null,"prefix":"","ascii":false,"unit":"it","unit_scale":false,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1000,"initial":0,"colour":null}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 4.72029203|Test loss: 4.70033948\n","Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 3.94052432|Test loss: 3.84058642\n","Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 3.76674881|Test loss: 3.80361199\n","Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 3.63752900|Test loss: 3.75171733\n","Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 3.61822426|Test loss: 3.74272887\n","Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 3.58386453|Test loss: 3.76500058\n","Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 3.55360880|Test loss: 3.67423010\n","Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 3.55163592|Test loss: 3.68677600\n","Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 3.52698169|Test loss: 3.67937930\n","Epoch: 010 | Lr: 0.00100000000000000002 |Train loss: 3.52045252|Test loss: 3.69238106\n","Epoch: 011 | Lr: 0.00100000000000000002 |Train loss: 3.54159373|Test loss: 3.81574535\n","Epoch: 012 | Lr: 0.00100000000000000002 |Train loss: 3.50858432|Test loss: 3.73571396\n","Epoch: 013 | Lr: 0.00100000000000000002 |Train loss: 3.46516045|Test loss: 3.64190165\n","Epoch: 014 | Lr: 0.00100000000000000002 |Train loss: 3.49674733|Test loss: 3.66906937\n","Epoch: 015 | Lr: 0.00100000000000000002 |Train loss: 3.44950251|Test loss: 3.61945208\n","Epoch: 016 | Lr: 0.00100000000000000002 |Train loss: 3.42735072|Test loss: 3.59053985\n","Epoch: 017 | Lr: 0.00100000000000000002 |Train loss: 3.40643642|Test loss: 3.64578533\n","Epoch: 018 | Lr: 0.00100000000000000002 |Train loss: 3.41708755|Test loss: 3.62149906\n","Epoch: 019 | Lr: 0.00100000000000000002 |Train loss: 3.38962317|Test loss: 3.59221443\n","Epoch: 020 | Lr: 0.00100000000000000002 |Train loss: 3.35631380|Test loss: 3.57949368\n","Epoch: 021 | Lr: 0.00100000000000000002 |Train loss: 3.33431429|Test loss: 3.58530450\n","Epoch: 022 | Lr: 0.00100000000000000002 |Train loss: 3.38018314|Test loss: 3.60138138\n","Epoch: 023 | Lr: 0.00100000000000000002 |Train loss: 3.32621419|Test loss: 3.62110130\n","Epoch: 024 | Lr: 0.00100000000000000002 |Train loss: 3.32783085|Test loss: 3.58510486\n","Epoch: 025 | Lr: 0.00100000000000000002 |Train loss: 3.30795290|Test loss: 3.59154113\n","Epoch: 026 | Lr: 0.00100000000000000002 |Train loss: 3.28725557|Test loss: 3.58116635\n","Epoch: 027 | Lr: 0.00100000000000000002 |Train loss: 3.30268035|Test loss: 3.55164218\n","Epoch: 028 | Lr: 0.00100000000000000002 |Train loss: 3.30949646|Test loss: 3.56115993\n","Epoch: 029 | Lr: 0.00100000000000000002 |Train loss: 3.32368624|Test loss: 3.54398394\n","Epoch: 030 | Lr: 0.00100000000000000002 |Train loss: 3.41588414|Test loss: 3.68279894\n","Epoch: 031 | Lr: 0.00100000000000000002 |Train loss: 3.34669495|Test loss: 3.60504977\n","Epoch: 032 | Lr: 0.00100000000000000002 |Train loss: 3.32383730|Test loss: 3.56774958\n","Epoch: 033 | Lr: 0.00100000000000000002 |Train loss: 3.28809549|Test loss: 3.56262231\n","Epoch: 034 | Lr: 0.00100000000000000002 |Train loss: 3.27601701|Test loss: 3.54282673\n","Epoch: 035 | Lr: 0.00100000000000000002 |Train loss: 3.33698229|Test loss: 3.61297178\n","Epoch: 036 | Lr: 0.00100000000000000002 |Train loss: 3.26805838|Test loss: 3.55677700\n","Epoch: 037 | Lr: 0.00100000000000000002 |Train loss: 3.24700812|Test loss: 3.54340323\n","Epoch: 038 | Lr: 0.00100000000000000002 |Train loss: 3.23319759|Test loss: 3.53411659\n","Epoch: 039 | Lr: 0.00100000000000000002 |Train loss: 3.22023557|Test loss: 3.55700636\n","Epoch: 040 | Lr: 0.00100000000000000002 |Train loss: 3.31140806|Test loss: 3.61636122\n","Epoch: 041 | Lr: 0.00100000000000000002 |Train loss: 3.32513462|Test loss: 3.55729206\n","Epoch: 042 | Lr: 0.00100000000000000002 |Train loss: 3.22982063|Test loss: 3.51318010\n","Epoch: 043 | Lr: 0.00100000000000000002 |Train loss: 3.25015640|Test loss: 3.50971667\n","Epoch: 044 | Lr: 0.00100000000000000002 |Train loss: 3.23316228|Test loss: 3.54610260\n","Epoch: 045 | Lr: 0.00100000000000000002 |Train loss: 3.22044698|Test loss: 3.57175779\n","Epoch: 046 | Lr: 0.00100000000000000002 |Train loss: 3.25684875|Test loss: 3.49524530\n","Epoch: 047 | Lr: 0.00100000000000000002 |Train loss: 3.27912939|Test loss: 3.58392636\n","Epoch: 048 | Lr: 0.00100000000000000002 |Train loss: 3.30844539|Test loss: 3.56726313\n","Epoch: 049 | Lr: 0.00100000000000000002 |Train loss: 3.24077638|Test loss: 3.55025053\n","Epoch: 050 | Lr: 0.00100000000000000002 |Train loss: 3.24320791|Test loss: 3.55120516\n","Epoch: 051 | Lr: 0.00100000000000000002 |Train loss: 3.22556208|Test loss: 3.52629948\n","Epoch: 052 | Lr: 0.00100000000000000002 |Train loss: 3.26676498|Test loss: 3.53009383\n","Epoch: 053 | Lr: 0.00100000000000000002 |Train loss: 3.26623760|Test loss: 3.57431006\n","Epoch: 054 | Lr: 0.00100000000000000002 |Train loss: 3.22597345|Test loss: 3.50498462\n","Epoch: 055 | Lr: 0.00100000000000000002 |Train loss: 3.20125260|Test loss: 3.50699337\n","Epoch: 056 | Lr: 0.00100000000000000002 |Train loss: 3.18365033|Test loss: 3.52182341\n","Epoch: 057 | Lr: 0.00100000000000000002 |Train loss: 3.17774187|Test loss: 3.50281715\n","Epoch: 058 | Lr: 0.00100000000000000002 |Train loss: 3.25154301|Test loss: 3.56512968\n","Epoch: 059 | Lr: 0.00100000000000000002 |Train loss: 3.21204040|Test loss: 3.51851416\n","Epoch: 060 | Lr: 0.00100000000000000002 |Train loss: 3.18857318|Test loss: 3.49342934\n","Epoch: 061 | Lr: 0.00100000000000000002 |Train loss: 3.16847658|Test loss: 3.48785400\n","Epoch: 062 | Lr: 0.00100000000000000002 |Train loss: 3.15699631|Test loss: 3.48952134\n","Epoch: 063 | Lr: 0.00100000000000000002 |Train loss: 3.15311712|Test loss: 3.48486352\n","Epoch: 064 | Lr: 0.00100000000000000002 |Train loss: 3.17012246|Test loss: 3.48703257\n","Epoch: 065 | Lr: 0.00100000000000000002 |Train loss: 3.19088791|Test loss: 3.50096536\n","Epoch: 066 | Lr: 0.00100000000000000002 |Train loss: 3.21330392|Test loss: 3.53049914\n","Epoch: 067 | Lr: 0.00100000000000000002 |Train loss: 3.21583138|Test loss: 3.49164065\n","Epoch: 068 | Lr: 0.00100000000000000002 |Train loss: 3.18757868|Test loss: 3.49674082\n","Epoch: 069 | Lr: 0.00100000000000000002 |Train loss: 3.17627996|Test loss: 3.52558192\n","Epoch: 070 | Lr: 0.00100000000000000002 |Train loss: 3.14778405|Test loss: 3.50645105\n","Epoch: 071 | Lr: 0.00100000000000000002 |Train loss: 3.22426993|Test loss: 3.50373801\n","Epoch: 072 | Lr: 0.00100000000000000002 |Train loss: 3.19522280|Test loss: 3.53350695\n","Epoch: 073 | Lr: 0.00100000000000000002 |Train loss: 3.14679319|Test loss: 3.48391461\n","Epoch: 074 | Lr: 0.00100000000000000002 |Train loss: 3.17582830|Test loss: 3.48689834\n","Epoch: 075 | Lr: 0.00100000000000000002 |Train loss: 3.17939798|Test loss: 3.52334897\n","Epoch: 076 | Lr: 0.00100000000000000002 |Train loss: 3.16638370|Test loss: 3.53350822\n","Epoch: 077 | Lr: 0.00100000000000000002 |Train loss: 3.22146980|Test loss: 3.53626823\n","Epoch: 078 | Lr: 0.00100000000000000002 |Train loss: 3.25226237|Test loss: 3.53220185\n","Epoch: 079 | Lr: 0.00100000000000000002 |Train loss: 3.16205174|Test loss: 3.48042933\n","Epoch: 080 | Lr: 0.00100000000000000002 |Train loss: 3.15894687|Test loss: 3.48712317\n","Epoch: 081 | Lr: 0.00100000000000000002 |Train loss: 3.13066101|Test loss: 3.45339179\n","Epoch: 082 | Lr: 0.00100000000000000002 |Train loss: 3.13636571|Test loss: 3.47060625\n","Epoch: 083 | Lr: 0.00100000000000000002 |Train loss: 3.16353538|Test loss: 3.55926347\n","Epoch: 084 | Lr: 0.00100000000000000002 |Train loss: 3.16623292|Test loss: 3.48218711\n","Epoch: 085 | Lr: 0.00100000000000000002 |Train loss: 3.13802423|Test loss: 3.44917369\n","Epoch: 086 | Lr: 0.00100000000000000002 |Train loss: 3.16642865|Test loss: 3.50740774\n","Epoch: 087 | Lr: 0.00100000000000000002 |Train loss: 3.16882189|Test loss: 3.46063813\n","Epoch: 088 | Lr: 0.00100000000000000002 |Train loss: 3.12767557|Test loss: 3.48899269\n","Epoch: 089 | Lr: 0.00100000000000000002 |Train loss: 3.15292221|Test loss: 3.48450851\n","Epoch: 090 | Lr: 0.00100000000000000002 |Train loss: 3.10968049|Test loss: 3.45042149\n","Epoch: 091 | Lr: 0.00100000000000000002 |Train loss: 3.11982153|Test loss: 3.45007404\n","Epoch: 092 | Lr: 0.00100000000000000002 |Train loss: 3.09807070|Test loss: 3.49942803\n","Epoch: 093 | Lr: 0.00100000000000000002 |Train loss: 3.08153482|Test loss: 3.44928678\n","Epoch: 094 | Lr: 0.00100000000000000002 |Train loss: 3.08322740|Test loss: 3.47807066\n","Epoch: 095 | Lr: 0.00100000000000000002 |Train loss: 3.16902373|Test loss: 3.45369013\n","Epoch: 096 | Lr: 0.00100000000000000002 |Train loss: 3.09138087|Test loss: 3.45000045\n","Epoch: 097 | Lr: 0.00100000000000000002 |Train loss: 3.11088761|Test loss: 3.45824711\n","Epoch: 098 | Lr: 0.00100000000000000002 |Train loss: 3.11540882|Test loss: 3.49515851\n","Epoch: 099 | Lr: 0.00100000000000000002 |Train loss: 3.11212073|Test loss: 3.45800718\n","Epoch: 100 | Lr: 0.00100000000000000002 |Train loss: 3.12331750|Test loss: 3.47377229\n","Epoch: 101 | Lr: 0.00100000000000000002 |Train loss: 3.12232113|Test loss: 3.46108898\n","Epoch: 102 | Lr: 0.00100000000000000002 |Train loss: 3.08909504|Test loss: 3.45628659\n","Epoch: 103 | Lr: 0.00100000000000000002 |Train loss: 3.07828633|Test loss: 3.44226638\n","Epoch: 104 | Lr: 0.00100000000000000002 |Train loss: 3.08282562|Test loss: 3.48199431\n","Epoch: 105 | Lr: 0.00100000000000000002 |Train loss: 3.05464129|Test loss: 3.44452318\n","Epoch: 106 | Lr: 0.00100000000000000002 |Train loss: 3.09392562|Test loss: 3.43722796\n","Epoch: 107 | Lr: 0.00100000000000000002 |Train loss: 3.10299176|Test loss: 3.48057342\n","Epoch: 108 | Lr: 0.00100000000000000002 |Train loss: 3.10528954|Test loss: 3.48071321\n","Epoch: 109 | Lr: 0.00100000000000000002 |Train loss: 3.07272234|Test loss: 3.43105912\n","Epoch: 110 | Lr: 0.00100000000000000002 |Train loss: 3.11530284|Test loss: 3.44324199\n","Epoch: 111 | Lr: 0.00100000000000000002 |Train loss: 3.08234310|Test loss: 3.46686029\n","Epoch: 112 | Lr: 0.00100000000000000002 |Train loss: 3.03606236|Test loss: 3.43103512\n","Epoch: 113 | Lr: 0.00100000000000000002 |Train loss: 3.07472815|Test loss: 3.45404601\n","Epoch: 114 | Lr: 0.00100000000000000002 |Train loss: 3.07897959|Test loss: 3.42354075\n","Epoch: 115 | Lr: 0.00100000000000000002 |Train loss: 3.00936160|Test loss: 3.44801974\n","Epoch: 116 | Lr: 0.00100000000000000002 |Train loss: 3.01632637|Test loss: 3.43114662\n","Epoch: 117 | Lr: 0.00100000000000000002 |Train loss: 2.98961022|Test loss: 3.39195204\n","Epoch: 118 | Lr: 0.00100000000000000002 |Train loss: 2.95647230|Test loss: 3.44515411\n","Epoch: 119 | Lr: 0.00100000000000000002 |Train loss: 2.96201261|Test loss: 3.45177086\n","Epoch: 120 | Lr: 0.00100000000000000002 |Train loss: 2.97446760|Test loss: 3.41728322\n","Epoch: 121 | Lr: 0.00100000000000000002 |Train loss: 3.01936756|Test loss: 3.47177005\n","Epoch: 122 | Lr: 0.00100000000000000002 |Train loss: 3.02310954|Test loss: 3.41352979\n","Epoch: 123 | Lr: 0.00100000000000000002 |Train loss: 2.95567306|Test loss: 3.51169642\n","Epoch: 124 | Lr: 0.00100000000000000002 |Train loss: 2.96629906|Test loss: 3.44429795\n","Epoch: 125 | Lr: 0.00100000000000000002 |Train loss: 2.95174177|Test loss: 3.45892326\n","Epoch: 126 | Lr: 0.00100000000000000002 |Train loss: 3.00536154|Test loss: 3.33645082\n","Epoch: 127 | Lr: 0.00100000000000000002 |Train loss: 3.01498493|Test loss: 3.37386934\n","Epoch: 128 | Lr: 0.00100000000000000002 |Train loss: 2.94826013|Test loss: 3.51094309\n","Epoch: 129 | Lr: 0.00100000000000000002 |Train loss: 2.97285042|Test loss: 3.54686578\n","Epoch: 130 | Lr: 0.00100000000000000002 |Train loss: 2.89959518|Test loss: 3.53554940\n","Epoch: 131 | Lr: 0.00100000000000000002 |Train loss: 2.83949037|Test loss: 3.54992263\n","Epoch: 132 | Lr: 0.00100000000000000002 |Train loss: 2.82412211|Test loss: 3.52262918\n","Epoch: 133 | Lr: 0.00100000000000000002 |Train loss: 2.89888821|Test loss: 3.48044284\n","Epoch: 134 | Lr: 0.00100000000000000002 |Train loss: 2.90538720|Test loss: 3.32742802\n","Epoch: 135 | Lr: 0.00100000000000000002 |Train loss: 2.88613933|Test loss: 3.41702286\n","Epoch: 136 | Lr: 0.00100000000000000002 |Train loss: 2.92660771|Test loss: 3.55701367\n","Epoch: 137 | Lr: 0.00100000000000000002 |Train loss: 2.91183579|Test loss: 3.55945118\n","Epoch: 138 | Lr: 0.00100000000000000002 |Train loss: 2.88949811|Test loss: 3.49702303\n","Epoch: 139 | Lr: 0.00100000000000000002 |Train loss: 2.85215467|Test loss: 3.59347924\n","Epoch: 140 | Lr: 0.00100000000000000002 |Train loss: 2.81450939|Test loss: 3.48878249\n","Epoch: 141 | Lr: 0.00100000000000000002 |Train loss: 2.83005091|Test loss: 3.68924054\n","Epoch: 142 | Lr: 0.00100000000000000002 |Train loss: 2.78011260|Test loss: 3.61613027\n","Epoch: 143 | Lr: 0.00100000000000000002 |Train loss: 2.89501029|Test loss: 3.54679553\n","Epoch: 144 | Lr: 0.00100000000000000002 |Train loss: 2.86644020|Test loss: 3.41129231\n","Epoch: 145 | Lr: 0.00100000000000000002 |Train loss: 2.85377228|Test loss: 3.33699179\n","Epoch: 146 | Lr: 0.00100000000000000002 |Train loss: 2.93166361|Test loss: 3.36141205\n","Epoch: 147 | Lr: 0.00100000000000000002 |Train loss: 2.83596585|Test loss: 3.52155900\n","Epoch: 148 | Lr: 0.00100000000000000002 |Train loss: 2.90861849|Test loss: 3.59943255\n","Epoch: 149 | Lr: 0.00100000000000000002 |Train loss: 2.93037208|Test loss: 3.35747059\n","Epoch: 150 | Lr: 0.00100000000000000002 |Train loss: 2.76416415|Test loss: 3.30253760\n","Epoch: 151 | Lr: 0.00100000000000000002 |Train loss: 2.78130066|Test loss: 3.32821918\n","Epoch: 152 | Lr: 0.00100000000000000002 |Train loss: 2.78337429|Test loss: 3.45071236\n","Epoch: 153 | Lr: 0.00100000000000000002 |Train loss: 2.88558139|Test loss: 3.62079080\n","Epoch: 154 | Lr: 0.00100000000000000002 |Train loss: 2.88365130|Test loss: 3.43713665\n","Epoch: 155 | Lr: 0.00100000000000000002 |Train loss: 2.78138415|Test loss: 3.41987491\n","Epoch: 156 | Lr: 0.00100000000000000002 |Train loss: 2.72893806|Test loss: 3.41615264\n","Epoch: 157 | Lr: 0.00100000000000000002 |Train loss: 2.73278916|Test loss: 3.41759539\n","Epoch: 158 | Lr: 0.00100000000000000002 |Train loss: 2.72230889|Test loss: 3.34955851\n","Epoch: 159 | Lr: 0.00100000000000000002 |Train loss: 2.70971537|Test loss: 3.38282037\n","Epoch: 160 | Lr: 0.00100000000000000002 |Train loss: 2.77752099|Test loss: 3.53389597\n","Epoch: 161 | Lr: 0.00100000000000000002 |Train loss: 2.85961562|Test loss: 3.58947738\n","Epoch: 162 | Lr: 0.00100000000000000002 |Train loss: 2.85736485|Test loss: 3.53390503\n","Epoch: 163 | Lr: 0.00100000000000000002 |Train loss: 2.79045097|Test loss: 3.35284535\n","Epoch: 164 | Lr: 0.00100000000000000002 |Train loss: 2.81248655|Test loss: 3.34803104\n","Epoch: 165 | Lr: 0.00100000000000000002 |Train loss: 2.76592696|Test loss: 3.41324409\n","Epoch: 166 | Lr: 0.00100000000000000002 |Train loss: 2.76394786|Test loss: 3.50542641\n","Epoch: 167 | Lr: 0.00100000000000000002 |Train loss: 2.82690805|Test loss: 3.43983396\n","Epoch: 168 | Lr: 0.00100000000000000002 |Train loss: 2.75928950|Test loss: 3.34878850\n","Epoch: 169 | Lr: 0.00100000000000000002 |Train loss: 2.71240757|Test loss: 3.37485639\n","Epoch: 170 | Lr: 0.00100000000000000002 |Train loss: 2.69323321|Test loss: 3.38710078\n","Epoch: 171 | Lr: 0.00100000000000000002 |Train loss: 2.67994283|Test loss: 3.46123838\n","Epoch: 172 | Lr: 0.00100000000000000002 |Train loss: 2.68133988|Test loss: 3.42065907\n","Epoch: 173 | Lr: 0.00100000000000000002 |Train loss: 2.69075255|Test loss: 3.44372010\n","Epoch: 174 | Lr: 0.00100000000000000002 |Train loss: 2.73823516|Test loss: 3.50696262\n","Epoch: 175 | Lr: 0.00100000000000000002 |Train loss: 2.77383264|Test loss: 3.50677061\n","Epoch: 176 | Lr: 0.00100000000000000002 |Train loss: 2.78555648|Test loss: 3.40388831\n","Epoch: 177 | Lr: 0.00100000000000000002 |Train loss: 2.72993245|Test loss: 3.34017920\n","Epoch: 178 | Lr: 0.00100000000000000002 |Train loss: 2.75451758|Test loss: 3.35577035\n","Epoch: 179 | Lr: 0.00100000000000000002 |Train loss: 2.69425299|Test loss: 3.37588724\n","Epoch: 180 | Lr: 0.00100000000000000002 |Train loss: 2.72019541|Test loss: 3.44658216\n","Epoch: 181 | Lr: 0.00100000000000000002 |Train loss: 2.73557051|Test loss: 3.44818314\n","Epoch: 182 | Lr: 0.00100000000000000002 |Train loss: 2.68917944|Test loss: 3.43407599\n","Epoch: 183 | Lr: 0.00100000000000000002 |Train loss: 2.68806318|Test loss: 3.41271249\n","Epoch: 184 | Lr: 0.00100000000000000002 |Train loss: 2.67735483|Test loss: 3.46100601\n","Epoch: 185 | Lr: 0.00100000000000000002 |Train loss: 2.66511144|Test loss: 3.42438817\n","Epoch: 186 | Lr: 0.00100000000000000002 |Train loss: 2.66867640|Test loss: 3.34814644\n","Epoch: 187 | Lr: 0.00100000000000000002 |Train loss: 2.68758599|Test loss: 3.36636869\n","Epoch: 188 | Lr: 0.00100000000000000002 |Train loss: 2.69214767|Test loss: 3.44546437\n","Epoch: 189 | Lr: 0.00100000000000000002 |Train loss: 2.73573051|Test loss: 3.53529692\n","Epoch: 190 | Lr: 0.00100000000000000002 |Train loss: 2.73292166|Test loss: 3.50883881\n","Epoch: 191 | Lr: 0.00100000000000000002 |Train loss: 2.74643070|Test loss: 3.54764605\n","Epoch: 192 | Lr: 0.00100000000000000002 |Train loss: 2.76886686|Test loss: 3.40246765\n","Epoch: 193 | Lr: 0.00100000000000000002 |Train loss: 2.89677384|Test loss: 3.35698708\n","Epoch: 194 | Lr: 0.00100000000000000002 |Train loss: 2.74802705|Test loss: 3.37738180\n","Epoch: 195 | Lr: 0.00100000000000000002 |Train loss: 2.72258216|Test loss: 3.45532489\n","Epoch: 196 | Lr: 0.00100000000000000002 |Train loss: 2.75090037|Test loss: 3.51237583\n","Epoch: 197 | Lr: 0.00100000000000000002 |Train loss: 2.78608737|Test loss: 3.45773625\n","Epoch: 198 | Lr: 0.00100000000000000002 |Train loss: 2.71762850|Test loss: 3.36179566\n","Epoch: 199 | Lr: 0.00100000000000000002 |Train loss: 2.70602508|Test loss: 3.31313809\n","Epoch: 200 | Lr: 0.00100000000000000002 |Train loss: 2.71293718|Test loss: 3.34562937\n","Epoch: 201 | Lr: 0.00100000000000000002 |Train loss: 2.68998094|Test loss: 3.39960814\n","Epoch: 202 | Lr: 0.00100000000000000002 |Train loss: 2.68602685|Test loss: 3.45293379\n","Epoch: 203 | Lr: 0.00100000000000000002 |Train loss: 2.71606974|Test loss: 3.40816442\n","Epoch: 204 | Lr: 0.00100000000000000002 |Train loss: 2.69082107|Test loss: 3.32790867\n","Epoch: 205 | Lr: 0.00100000000000000002 |Train loss: 2.69947157|Test loss: 3.32251143\n","Epoch: 206 | Lr: 0.00100000000000000002 |Train loss: 2.70632857|Test loss: 3.31227374\n","Epoch: 207 | Lr: 0.00100000000000000002 |Train loss: 2.68616225|Test loss: 3.37986279\n","Epoch: 208 | Lr: 0.00100000000000000002 |Train loss: 2.67881904|Test loss: 3.40380287\n","Epoch: 209 | Lr: 0.00100000000000000002 |Train loss: 2.66584412|Test loss: 3.40042885\n","Epoch: 210 | Lr: 0.00100000000000000002 |Train loss: 2.64991575|Test loss: 3.38537884\n","Epoch: 211 | Lr: 0.00100000000000000002 |Train loss: 2.65383472|Test loss: 3.35741178\n","Epoch: 212 | Lr: 0.00100000000000000002 |Train loss: 2.65412893|Test loss: 3.41435440\n","Epoch: 213 | Lr: 0.00100000000000000002 |Train loss: 2.68144647|Test loss: 3.40942891\n","Epoch: 214 | Lr: 0.00100000000000000002 |Train loss: 2.65698864|Test loss: 3.37169584\n","Epoch: 215 | Lr: 0.00100000000000000002 |Train loss: 2.66117607|Test loss: 3.43124755\n","Epoch: 216 | Lr: 0.00100000000000000002 |Train loss: 2.64847142|Test loss: 3.43462745\n","Epoch: 217 | Lr: 0.00100000000000000002 |Train loss: 2.64676958|Test loss: 3.45933882\n","Epoch: 218 | Lr: 0.00100000000000000002 |Train loss: 2.64431540|Test loss: 3.35192283\n","Epoch: 219 | Lr: 0.00100000000000000002 |Train loss: 2.70158480|Test loss: 3.29523253\n","Epoch: 220 | Lr: 0.00100000000000000002 |Train loss: 2.70677098|Test loss: 3.28631997\n","Epoch: 221 | Lr: 0.00100000000000000002 |Train loss: 2.68582940|Test loss: 3.39251574\n","Epoch: 222 | Lr: 0.00100000000000000002 |Train loss: 2.71067760|Test loss: 3.45788884\n","Epoch: 223 | Lr: 0.00100000000000000002 |Train loss: 2.72289030|Test loss: 3.46161421\n","Epoch: 224 | Lr: 0.00100000000000000002 |Train loss: 2.70918751|Test loss: 3.36142373\n","Epoch: 225 | Lr: 0.00100000000000000002 |Train loss: 2.69144235|Test loss: 3.30380321\n","Epoch: 226 | Lr: 0.00100000000000000002 |Train loss: 2.68257809|Test loss: 3.28318469\n","Epoch: 227 | Lr: 0.00100000000000000002 |Train loss: 2.65686564|Test loss: 3.36669874\n","Epoch: 228 | Lr: 0.00100000000000000002 |Train loss: 2.66902632|Test loss: 3.40816077\n","Epoch: 229 | Lr: 0.00100000000000000002 |Train loss: 2.66508897|Test loss: 3.43632015\n","Epoch: 230 | Lr: 0.00100000000000000002 |Train loss: 2.64634667|Test loss: 3.39109675\n","Epoch: 231 | Lr: 0.00100000000000000002 |Train loss: 2.64169321|Test loss: 3.35597587\n","Epoch: 232 | Lr: 0.00100000000000000002 |Train loss: 2.64718211|Test loss: 3.28024069\n","Epoch: 233 | Lr: 0.00100000000000000002 |Train loss: 2.65823623|Test loss: 3.30111845\n","Epoch: 234 | Lr: 0.00100000000000000002 |Train loss: 2.65901993|Test loss: 3.31124155\n","Epoch: 235 | Lr: 0.00100000000000000002 |Train loss: 2.65590596|Test loss: 3.42847522\n","Epoch: 236 | Lr: 0.00100000000000000002 |Train loss: 2.68864954|Test loss: 3.48330824\n","Epoch: 237 | Lr: 0.00100000000000000002 |Train loss: 2.69873027|Test loss: 3.36959259\n","Epoch: 238 | Lr: 0.00100000000000000002 |Train loss: 2.66286900|Test loss: 3.36737418\n","Epoch: 239 | Lr: 0.00100000000000000002 |Train loss: 2.72554596|Test loss: 3.32197396\n","Epoch: 240 | Lr: 0.00100000000000000002 |Train loss: 2.65411097|Test loss: 3.35908922\n","Epoch: 241 | Lr: 0.00100000000000000002 |Train loss: 2.65300355|Test loss: 3.39006821\n","Epoch: 242 | Lr: 0.00100000000000000002 |Train loss: 2.64427050|Test loss: 3.42967192\n","Epoch: 243 | Lr: 0.00100000000000000002 |Train loss: 2.65139955|Test loss: 3.40937336\n","Epoch: 244 | Lr: 0.00100000000000000002 |Train loss: 2.64458309|Test loss: 3.33047438\n","Epoch: 245 | Lr: 0.00100000000000000002 |Train loss: 2.66355437|Test loss: 3.28076212\n","Epoch: 246 | Lr: 0.00100000000000000002 |Train loss: 2.69754078|Test loss: 3.29722158\n","Epoch: 247 | Lr: 0.00100000000000000002 |Train loss: 2.68883185|Test loss: 3.41471378\n","Epoch: 248 | Lr: 0.00100000000000000002 |Train loss: 2.69352112|Test loss: 3.41423043\n","Epoch: 249 | Lr: 0.00100000000000000002 |Train loss: 2.70634017|Test loss: 3.46349629\n","Epoch: 250 | Lr: 0.00100000000000000002 |Train loss: 2.67658716|Test loss: 3.36744467\n","Epoch: 251 | Lr: 0.00100000000000000002 |Train loss: 2.63166004|Test loss: 3.30636851\n","Epoch: 252 | Lr: 0.00100000000000000002 |Train loss: 2.67608484|Test loss: 3.25969974\n","Epoch: 253 | Lr: 0.00100000000000000002 |Train loss: 2.69972714|Test loss: 3.28989283\n","Epoch: 254 | Lr: 0.00100000000000000002 |Train loss: 2.66858160|Test loss: 3.45149358\n","Epoch: 255 | Lr: 0.00100000000000000002 |Train loss: 2.74918246|Test loss: 3.50204420\n","Epoch: 256 | Lr: 0.00100000000000000002 |Train loss: 2.71898031|Test loss: 3.36165833\n","Epoch: 257 | Lr: 0.00100000000000000002 |Train loss: 2.67437230|Test loss: 3.24852530\n","Epoch: 258 | Lr: 0.00100000000000000002 |Train loss: 2.69183163|Test loss: 3.28775152\n","Epoch: 259 | Lr: 0.00100000000000000002 |Train loss: 2.63595370|Test loss: 3.36897715\n","Epoch: 260 | Lr: 0.00100000000000000002 |Train loss: 2.63704828|Test loss: 3.34893608\n","Epoch: 261 | Lr: 0.00100000000000000002 |Train loss: 2.63124396|Test loss: 3.34707840\n","Epoch: 262 | Lr: 0.00100000000000000002 |Train loss: 2.60917169|Test loss: 3.31930757\n","Epoch: 263 | Lr: 0.00100000000000000002 |Train loss: 2.60890528|Test loss: 3.31126897\n","Epoch: 264 | Lr: 0.00100000000000000002 |Train loss: 2.60885088|Test loss: 3.28992621\n","Epoch: 265 | Lr: 0.00100000000000000002 |Train loss: 2.61202085|Test loss: 3.32380684\n","Epoch: 266 | Lr: 0.00100000000000000002 |Train loss: 2.62182442|Test loss: 3.35652256\n","Epoch: 267 | Lr: 0.00100000000000000002 |Train loss: 2.63848533|Test loss: 3.42616208\n","Epoch: 268 | Lr: 0.00100000000000000002 |Train loss: 2.66090127|Test loss: 3.40378761\n","Epoch: 269 | Lr: 0.00100000000000000002 |Train loss: 2.63283181|Test loss: 3.28116488\n","Epoch: 270 | Lr: 0.00100000000000000002 |Train loss: 2.62995913|Test loss: 3.25387605\n","Epoch: 271 | Lr: 0.00100000000000000002 |Train loss: 2.63711190|Test loss: 3.29683606\n","Epoch: 272 | Lr: 0.00100000000000000002 |Train loss: 2.60656951|Test loss: 3.35446000\n","Epoch: 273 | Lr: 0.00100000000000000002 |Train loss: 2.61206867|Test loss: 3.37492593\n","Epoch: 274 | Lr: 0.00100000000000000002 |Train loss: 2.63031147|Test loss: 3.33349323\n","Epoch: 275 | Lr: 0.00100000000000000002 |Train loss: 2.59317718|Test loss: 3.28789202\n","Epoch: 276 | Lr: 0.00100000000000000002 |Train loss: 2.59931924|Test loss: 3.28018228\n","Epoch: 277 | Lr: 0.00100000000000000002 |Train loss: 2.58996373|Test loss: 3.30521981\n","Epoch: 278 | Lr: 0.00100000000000000002 |Train loss: 2.59222653|Test loss: 3.30516545\n","Epoch: 279 | Lr: 0.00100000000000000002 |Train loss: 2.58974379|Test loss: 3.33873733\n","Epoch: 280 | Lr: 0.00100000000000000002 |Train loss: 2.61267869|Test loss: 3.41324608\n","Epoch: 281 | Lr: 0.00100000000000000002 |Train loss: 2.66413122|Test loss: 3.39855202\n","Epoch: 282 | Lr: 0.00100000000000000002 |Train loss: 2.61624650|Test loss: 3.34726350\n","Epoch: 283 | Lr: 0.00100000000000000002 |Train loss: 2.65896084|Test loss: 3.28174877\n","Epoch: 284 | Lr: 0.00100000000000000002 |Train loss: 2.68485955|Test loss: 3.30106918\n","Epoch: 285 | Lr: 0.00100000000000000002 |Train loss: 2.72274629|Test loss: 3.35510540\n","Epoch: 286 | Lr: 0.00100000000000000002 |Train loss: 2.72357567|Test loss: 3.39449112\n","Epoch: 287 | Lr: 0.00100000000000000002 |Train loss: 2.69574116|Test loss: 3.45734239\n","Epoch: 288 | Lr: 0.00100000000000000002 |Train loss: 2.68442257|Test loss: 3.39539679\n","Epoch: 289 | Lr: 0.00100000000000000002 |Train loss: 2.63408432|Test loss: 3.36049867\n","Epoch: 290 | Lr: 0.00100000000000000002 |Train loss: 2.63646020|Test loss: 3.33380818\n","Epoch: 291 | Lr: 0.00100000000000000002 |Train loss: 2.66628180|Test loss: 3.28292386\n","Epoch: 292 | Lr: 0.00100000000000000002 |Train loss: 2.70830570|Test loss: 3.35654537\n","Epoch: 293 | Lr: 0.00100000000000000002 |Train loss: 2.74830804|Test loss: 3.44042397\n","Epoch: 294 | Lr: 0.00100000000000000002 |Train loss: 2.76045378|Test loss: 3.44482525\n","Epoch: 295 | Lr: 0.00100000000000000002 |Train loss: 2.70799563|Test loss: 3.44716843\n","Epoch: 296 | Lr: 0.00100000000000000002 |Train loss: 2.63774957|Test loss: 3.35921367\n","Epoch: 297 | Lr: 0.00100000000000000002 |Train loss: 2.62063150|Test loss: 3.34684173\n","Epoch: 298 | Lr: 0.00100000000000000002 |Train loss: 2.65555849|Test loss: 3.39175765\n","Epoch: 299 | Lr: 0.00100000000000000002 |Train loss: 2.62190499|Test loss: 3.40421931\n","Epoch: 300 | Lr: 0.00100000000000000002 |Train loss: 2.61107618|Test loss: 3.43402878\n","Epoch: 301 | Lr: 0.00100000000000000002 |Train loss: 2.61876017|Test loss: 3.39452489\n","Epoch: 302 | Lr: 0.00100000000000000002 |Train loss: 2.62555969|Test loss: 3.27095858\n","Epoch: 303 | Lr: 0.00100000000000000002 |Train loss: 2.66477857|Test loss: 3.24887943\n","Epoch: 304 | Lr: 0.00100000000000000002 |Train loss: 2.66343659|Test loss: 3.30467478\n","Epoch: 305 | Lr: 0.00100000000000000002 |Train loss: 2.62339417|Test loss: 3.37480632\n","Epoch: 306 | Lr: 0.00100000000000000002 |Train loss: 2.62247664|Test loss: 3.33961296\n","Epoch: 307 | Lr: 0.00100000000000000002 |Train loss: 2.60619394|Test loss: 3.31157422\n","Epoch: 308 | Lr: 0.00100000000000000002 |Train loss: 2.58659705|Test loss: 3.27422754\n","Epoch: 309 | Lr: 0.00100000000000000002 |Train loss: 2.58756075|Test loss: 3.26416453\n","Epoch: 310 | Lr: 0.00100000000000000002 |Train loss: 2.62235236|Test loss: 3.28929774\n","Epoch: 311 | Lr: 0.00100000000000000002 |Train loss: 2.59487156|Test loss: 3.33604455\n","Epoch: 312 | Lr: 0.00100000000000000002 |Train loss: 2.59376363|Test loss: 3.36893423\n","Epoch: 313 | Lr: 0.00100000000000000002 |Train loss: 2.59875498|Test loss: 3.33092268\n","Epoch: 314 | Lr: 0.00100000000000000002 |Train loss: 2.57739383|Test loss: 3.36298331\n","Epoch: 315 | Lr: 0.00100000000000000002 |Train loss: 2.58273931|Test loss: 3.33810019\n","Epoch: 316 | Lr: 0.00100000000000000002 |Train loss: 2.59389122|Test loss: 3.34802723\n","Epoch: 317 | Lr: 0.00100000000000000002 |Train loss: 2.60305254|Test loss: 3.28072770\n","Epoch: 318 | Lr: 0.00100000000000000002 |Train loss: 2.61351691|Test loss: 3.29699556\n","Epoch: 319 | Lr: 0.00100000000000000002 |Train loss: 2.60943743|Test loss: 3.29347563\n","Epoch: 320 | Lr: 0.00100000000000000002 |Train loss: 2.61463855|Test loss: 3.38659938\n","Epoch: 321 | Lr: 0.00100000000000000002 |Train loss: 2.61309874|Test loss: 3.39708908\n","Epoch: 322 | Lr: 0.00100000000000000002 |Train loss: 2.61855370|Test loss: 3.30958708\n","Epoch: 323 | Lr: 0.00100000000000000002 |Train loss: 2.57706022|Test loss: 3.30245773\n","Epoch: 324 | Lr: 0.00100000000000000002 |Train loss: 2.59454119|Test loss: 3.24954772\n","Epoch: 325 | Lr: 0.00100000000000000002 |Train loss: 2.58936717|Test loss: 3.26789149\n","Epoch: 326 | Lr: 0.00100000000000000002 |Train loss: 2.57692774|Test loss: 3.34353693\n","Epoch: 327 | Lr: 0.00100000000000000002 |Train loss: 2.60022336|Test loss: 3.35379950\n","Epoch: 328 | Lr: 0.00100000000000000002 |Train loss: 2.64306561|Test loss: 3.41985106\n","Epoch: 329 | Lr: 0.00100000000000000002 |Train loss: 2.63744638|Test loss: 3.37217824\n","Epoch: 330 | Lr: 0.00100000000000000002 |Train loss: 2.61098284|Test loss: 3.35319901\n","Epoch: 331 | Lr: 0.00100000000000000002 |Train loss: 2.64548033|Test loss: 3.35954825\n","Epoch: 332 | Lr: 0.00100000000000000002 |Train loss: 2.63857541|Test loss: 3.32158017\n","Epoch: 333 | Lr: 0.00100000000000000002 |Train loss: 2.61685723|Test loss: 3.36821834\n","Epoch: 334 | Lr: 0.00100000000000000002 |Train loss: 2.62163001|Test loss: 3.34608221\n","Epoch: 335 | Lr: 0.00100000000000000002 |Train loss: 2.62826830|Test loss: 3.29312929\n","Epoch: 336 | Lr: 0.00100000000000000002 |Train loss: 2.63869085|Test loss: 3.27481055\n","Epoch: 337 | Lr: 0.00100000000000000002 |Train loss: 2.62407319|Test loss: 3.26900880\n","Epoch: 338 | Lr: 0.00100000000000000002 |Train loss: 2.61913975|Test loss: 3.32794682\n","Epoch: 339 | Lr: 0.00100000000000000002 |Train loss: 2.61908615|Test loss: 3.38073572\n","Epoch: 340 | Lr: 0.00100000000000000002 |Train loss: 2.63695025|Test loss: 3.32945387\n","Epoch: 341 | Lr: 0.00100000000000000002 |Train loss: 2.63689615|Test loss: 3.33815368\n","Epoch: 342 | Lr: 0.00100000000000000002 |Train loss: 2.61878721|Test loss: 3.37785260\n","Epoch: 343 | Lr: 0.00100000000000000002 |Train loss: 2.60767527|Test loss: 3.36357832\n","Epoch: 344 | Lr: 0.00100000000000000002 |Train loss: 2.60659178|Test loss: 3.40216144\n","Epoch: 345 | Lr: 0.00100000000000000002 |Train loss: 2.61898957|Test loss: 3.39935263\n","Epoch: 346 | Lr: 0.00100000000000000002 |Train loss: 2.67164069|Test loss: 3.24625429\n","Epoch: 347 | Lr: 0.00100000000000000002 |Train loss: 2.65933420|Test loss: 3.28296351\n","Epoch: 348 | Lr: 0.00100000000000000002 |Train loss: 2.60711104|Test loss: 3.32442125\n","Epoch: 349 | Lr: 0.00100000000000000002 |Train loss: 2.59498407|Test loss: 3.32011851\n","Epoch: 350 | Lr: 0.00100000000000000002 |Train loss: 2.58351052|Test loss: 3.34503468\n","Epoch: 351 | Lr: 0.00100000000000000002 |Train loss: 2.57277658|Test loss: 3.33122524\n","Epoch: 352 | Lr: 0.00100000000000000002 |Train loss: 2.55761341|Test loss: 3.33255720\n","Epoch: 353 | Lr: 0.00100000000000000002 |Train loss: 2.56920381|Test loss: 3.33001256\n","Epoch: 354 | Lr: 0.00100000000000000002 |Train loss: 2.56617820|Test loss: 3.36946432\n","Epoch: 355 | Lr: 0.00100000000000000002 |Train loss: 2.56764289|Test loss: 3.35792335\n","Epoch: 356 | Lr: 0.00100000000000000002 |Train loss: 2.60335267|Test loss: 3.36793613\n","Epoch: 357 | Lr: 0.00100000000000000002 |Train loss: 2.62006927|Test loss: 3.23098405\n","Epoch: 358 | Lr: 0.00100000000000000002 |Train loss: 2.63292974|Test loss: 3.21918019\n","Epoch: 359 | Lr: 0.00100000000000000002 |Train loss: 2.66608441|Test loss: 3.24688069\n","Epoch: 360 | Lr: 0.00100000000000000002 |Train loss: 2.64633864|Test loss: 3.39451583\n","Epoch: 361 | Lr: 0.00100000000000000002 |Train loss: 2.62265054|Test loss: 3.34018731\n","Epoch: 362 | Lr: 0.00100000000000000002 |Train loss: 2.59683947|Test loss: 3.29470499\n","Epoch: 363 | Lr: 0.00100000000000000002 |Train loss: 2.56428321|Test loss: 3.23067578\n","Epoch: 364 | Lr: 0.00100000000000000002 |Train loss: 2.56065820|Test loss: 3.26577115\n","Epoch: 365 | Lr: 0.00100000000000000002 |Train loss: 2.56377717|Test loss: 3.27851065\n","Epoch: 366 | Lr: 0.00100000000000000002 |Train loss: 2.55093992|Test loss: 3.29409901\n","Epoch: 367 | Lr: 0.00100000000000000002 |Train loss: 2.55563653|Test loss: 3.34630704\n","Epoch: 368 | Lr: 0.00100000000000000002 |Train loss: 2.57038677|Test loss: 3.34170985\n","Epoch: 369 | Lr: 0.00100000000000000002 |Train loss: 2.55236904|Test loss: 3.29790457\n","Epoch: 370 | Lr: 0.00100000000000000002 |Train loss: 2.54858577|Test loss: 3.24942851\n","Epoch: 371 | Lr: 0.00100000000000000002 |Train loss: 2.58485903|Test loss: 3.23762862\n","Epoch: 372 | Lr: 0.00100000000000000002 |Train loss: 2.56636924|Test loss: 3.24289409\n","Epoch: 373 | Lr: 0.00100000000000000002 |Train loss: 2.59008783|Test loss: 3.30251336\n","Epoch: 374 | Lr: 0.00100000000000000002 |Train loss: 2.60989066|Test loss: 3.39632535\n","Epoch: 375 | Lr: 0.00100000000000000002 |Train loss: 2.61803901|Test loss: 3.37652493\n","Epoch: 376 | Lr: 0.00100000000000000002 |Train loss: 2.60708588|Test loss: 3.32715901\n","Epoch: 377 | Lr: 0.00100000000000000002 |Train loss: 2.65989735|Test loss: 3.21851007\n","Epoch: 378 | Lr: 0.00100000000000000002 |Train loss: 2.63969197|Test loss: 3.26676559\n","Epoch: 379 | Lr: 0.00100000000000000002 |Train loss: 2.63592142|Test loss: 3.33650700\n","Epoch: 380 | Lr: 0.00100000000000000002 |Train loss: 2.62297684|Test loss: 3.34336917\n","Epoch: 381 | Lr: 0.00100000000000000002 |Train loss: 2.61719801|Test loss: 3.33700363\n","Epoch: 382 | Lr: 0.00100000000000000002 |Train loss: 2.59948961|Test loss: 3.38350765\n","Epoch: 383 | Lr: 0.00100000000000000002 |Train loss: 2.61661023|Test loss: 3.37527164\n","Epoch: 384 | Lr: 0.00100000000000000002 |Train loss: 2.59989127|Test loss: 3.42407020\n","Epoch: 385 | Lr: 0.00100000000000000002 |Train loss: 2.57561167|Test loss: 3.35987441\n","Epoch: 386 | Lr: 0.00100000000000000002 |Train loss: 2.58876934|Test loss: 3.32682649\n","Epoch: 387 | Lr: 0.00100000000000000002 |Train loss: 2.64052878|Test loss: 3.33333683\n","Epoch: 388 | Lr: 0.00100000000000000002 |Train loss: 2.64668719|Test loss: 3.33002424\n","Epoch: 389 | Lr: 0.00100000000000000002 |Train loss: 2.59190015|Test loss: 3.29464698\n","Epoch: 390 | Lr: 0.00100000000000000002 |Train loss: 2.56631092|Test loss: 3.26827375\n","Epoch: 391 | Lr: 0.00100000000000000002 |Train loss: 2.59993857|Test loss: 3.31908186\n","Epoch: 392 | Lr: 0.00100000000000000002 |Train loss: 2.58469532|Test loss: 3.37338964\n","Epoch: 393 | Lr: 0.00100000000000000002 |Train loss: 2.60416696|Test loss: 3.41482258\n","Epoch: 394 | Lr: 0.00100000000000000002 |Train loss: 2.58087840|Test loss: 3.34650318\n","Epoch: 395 | Lr: 0.00100000000000000002 |Train loss: 2.56755275|Test loss: 3.30092827\n","Epoch: 396 | Lr: 0.00100000000000000002 |Train loss: 2.58761611|Test loss: 3.20208764\n","Epoch: 397 | Lr: 0.00100000000000000002 |Train loss: 2.58972889|Test loss: 3.20867197\n","Epoch: 398 | Lr: 0.00100000000000000002 |Train loss: 2.56833671|Test loss: 3.29790775\n","Epoch: 399 | Lr: 0.00100000000000000002 |Train loss: 2.58219796|Test loss: 3.36527014\n","Epoch: 400 | Lr: 0.00100000000000000002 |Train loss: 2.58133519|Test loss: 3.38115263\n","Epoch: 401 | Lr: 0.00100000000000000002 |Train loss: 2.55892052|Test loss: 3.25972557\n","Epoch: 402 | Lr: 0.00100000000000000002 |Train loss: 2.54984254|Test loss: 3.25366211\n","Epoch: 403 | Lr: 0.00100000000000000002 |Train loss: 2.56889993|Test loss: 3.28388929\n","Epoch: 404 | Lr: 0.00100000000000000002 |Train loss: 2.57143255|Test loss: 3.30445933\n","Epoch: 405 | Lr: 0.00100000000000000002 |Train loss: 2.54433737|Test loss: 3.34417113\n","Epoch: 406 | Lr: 0.00100000000000000002 |Train loss: 2.55618413|Test loss: 3.33366752\n","Epoch: 407 | Lr: 0.00100000000000000002 |Train loss: 2.54885769|Test loss: 3.26241120\n","Epoch: 408 | Lr: 0.00100000000000000002 |Train loss: 2.55855034|Test loss: 3.25649659\n","Epoch: 409 | Lr: 0.00100000000000000002 |Train loss: 2.57914551|Test loss: 3.22111630\n","Epoch: 410 | Lr: 0.00100000000000000002 |Train loss: 2.55108084|Test loss: 3.27543314\n","Epoch: 411 | Lr: 0.00100000000000000002 |Train loss: 2.55905775|Test loss: 3.29925442\n","Epoch: 412 | Lr: 0.00100000000000000002 |Train loss: 2.56277299|Test loss: 3.33459345\n","Epoch: 413 | Lr: 0.00100000000000000002 |Train loss: 2.56628146|Test loss: 3.31349619\n","Epoch: 414 | Lr: 0.00100000000000000002 |Train loss: 2.55455430|Test loss: 3.29971242\n","Epoch: 415 | Lr: 0.00100000000000000002 |Train loss: 2.56717100|Test loss: 3.26485626\n","Epoch: 416 | Lr: 0.00100000000000000002 |Train loss: 2.59116999|Test loss: 3.30157948\n","Epoch: 417 | Lr: 0.00100000000000000002 |Train loss: 2.62001242|Test loss: 3.29091303\n","Epoch: 418 | Lr: 0.00100000000000000002 |Train loss: 2.62306128|Test loss: 3.36717844\n","Epoch: 419 | Lr: 0.00100000000000000002 |Train loss: 2.62644770|Test loss: 3.38510839\n","Epoch: 420 | Lr: 0.00100000000000000002 |Train loss: 2.64206431|Test loss: 3.36703094\n","Epoch: 421 | Lr: 0.00100000000000000002 |Train loss: 2.58506813|Test loss: 3.31168556\n","Epoch: 422 | Lr: 0.00100000000000000002 |Train loss: 2.57111984|Test loss: 3.29993447\n","Epoch: 423 | Lr: 0.00100000000000000002 |Train loss: 2.60749948|Test loss: 3.26989730\n","Epoch: 424 | Lr: 0.00100000000000000002 |Train loss: 2.63507988|Test loss: 3.29532441\n","Epoch: 425 | Lr: 0.00100000000000000002 |Train loss: 2.72434429|Test loss: 3.34629544\n","Epoch: 426 | Lr: 0.00100000000000000002 |Train loss: 2.67888051|Test loss: 3.30688421\n","Epoch: 427 | Lr: 0.00100000000000000002 |Train loss: 2.59467375|Test loss: 3.32488473\n","Epoch: 428 | Lr: 0.00100000000000000002 |Train loss: 2.57612058|Test loss: 3.31031648\n","Epoch: 429 | Lr: 0.00100000000000000002 |Train loss: 2.58773800|Test loss: 3.34064301\n","Epoch: 430 | Lr: 0.00100000000000000002 |Train loss: 2.56086963|Test loss: 3.35751867\n","Epoch: 431 | Lr: 0.00100000000000000002 |Train loss: 2.56578388|Test loss: 3.33919597\n","Epoch: 432 | Lr: 0.00100000000000000002 |Train loss: 2.56804099|Test loss: 3.27961715\n","Epoch: 433 | Lr: 0.00100000000000000002 |Train loss: 2.58659951|Test loss: 3.20737815\n","Epoch: 434 | Lr: 0.00100000000000000002 |Train loss: 2.58969218|Test loss: 3.24764578\n","Epoch: 435 | Lr: 0.00100000000000000002 |Train loss: 2.58024635|Test loss: 3.31245025\n","Epoch: 436 | Lr: 0.00100000000000000002 |Train loss: 2.57142681|Test loss: 3.31960495\n","Epoch: 437 | Lr: 0.00100000000000000002 |Train loss: 2.54731280|Test loss: 3.28187394\n","Epoch: 438 | Lr: 0.00100000000000000002 |Train loss: 2.53505792|Test loss: 3.21031038\n","Epoch: 439 | Lr: 0.00100000000000000002 |Train loss: 2.54207997|Test loss: 3.23362954\n","Epoch: 440 | Lr: 0.00100000000000000002 |Train loss: 2.53177905|Test loss: 3.24393908\n","Epoch: 441 | Lr: 0.00100000000000000002 |Train loss: 2.53040959|Test loss: 3.28243470\n","Epoch: 442 | Lr: 0.00100000000000000002 |Train loss: 2.53228607|Test loss: 3.36727786\n","Epoch: 443 | Lr: 0.00100000000000000002 |Train loss: 2.55285356|Test loss: 3.29013149\n","Epoch: 444 | Lr: 0.00100000000000000002 |Train loss: 2.52798299|Test loss: 3.23544661\n","Epoch: 445 | Lr: 0.00100000000000000002 |Train loss: 2.53836137|Test loss: 3.20653065\n","Epoch: 446 | Lr: 0.00100000000000000002 |Train loss: 2.54274513|Test loss: 3.22733267\n","Epoch: 447 | Lr: 0.00100000000000000002 |Train loss: 2.54616777|Test loss: 3.28965878\n","Epoch: 448 | Lr: 0.00100000000000000002 |Train loss: 2.55271967|Test loss: 3.29384168\n","Epoch: 449 | Lr: 0.00100000000000000002 |Train loss: 2.55261457|Test loss: 3.31202197\n","Epoch: 450 | Lr: 0.00100000000000000002 |Train loss: 2.56534783|Test loss: 3.24736571\n","Epoch: 451 | Lr: 0.00100000000000000002 |Train loss: 2.51961108|Test loss: 3.21679767\n","Epoch: 452 | Lr: 0.00100000000000000002 |Train loss: 2.52786056|Test loss: 3.22897911\n","Epoch: 453 | Lr: 0.00100000000000000002 |Train loss: 2.53390922|Test loss: 3.23026164\n","Epoch: 454 | Lr: 0.00100000000000000002 |Train loss: 2.53045019|Test loss: 3.27943691\n","Epoch: 455 | Lr: 0.00100000000000000002 |Train loss: 2.52948111|Test loss: 3.30807900\n","Epoch: 456 | Lr: 0.00100000000000000002 |Train loss: 2.55338001|Test loss: 3.25551701\n","Epoch: 457 | Lr: 0.00100000000000000002 |Train loss: 2.51942515|Test loss: 3.22406602\n","Epoch: 458 | Lr: 0.00100000000000000002 |Train loss: 2.52154380|Test loss: 3.23489277\n","Epoch: 459 | Lr: 0.00100000000000000002 |Train loss: 2.52782863|Test loss: 3.26445111\n","Epoch: 460 | Lr: 0.00100000000000000002 |Train loss: 2.52765046|Test loss: 3.26017666\n","Epoch: 461 | Lr: 0.00100000000000000002 |Train loss: 2.53152180|Test loss: 3.35787868\n","Epoch: 462 | Lr: 0.00100000000000000002 |Train loss: 2.55163207|Test loss: 3.32539010\n","Epoch: 463 | Lr: 0.00100000000000000002 |Train loss: 2.52609138|Test loss: 3.33927353\n","Epoch: 464 | Lr: 0.00100000000000000002 |Train loss: 2.53166320|Test loss: 3.34561666\n","Epoch: 465 | Lr: 0.00100000000000000002 |Train loss: 2.54877106|Test loss: 3.33772564\n","Epoch: 466 | Lr: 0.00100000000000000002 |Train loss: 2.54794961|Test loss: 3.36692858\n","Epoch: 467 | Lr: 0.00100000000000000002 |Train loss: 2.56686654|Test loss: 3.33415794\n","Epoch: 468 | Lr: 0.00100000000000000002 |Train loss: 2.54553260|Test loss: 3.29856435\n","Epoch: 469 | Lr: 0.00100000000000000002 |Train loss: 2.62028694|Test loss: 3.37340085\n","Epoch: 470 | Lr: 0.00100000000000000002 |Train loss: 2.67093309|Test loss: 3.29233106\n","Epoch: 471 | Lr: 0.00100000000000000002 |Train loss: 2.69286921|Test loss: 3.27902349\n","Epoch: 472 | Lr: 0.00100000000000000002 |Train loss: 2.65377549|Test loss: 3.26364589\n","Epoch: 473 | Lr: 0.00100000000000000002 |Train loss: 2.60759878|Test loss: 3.33769027\n","Epoch: 474 | Lr: 0.00100000000000000002 |Train loss: 2.63707821|Test loss: 3.27548639\n","Epoch: 475 | Lr: 0.00100000000000000002 |Train loss: 2.59191370|Test loss: 3.29480871\n","Epoch: 476 | Lr: 0.00100000000000000002 |Train loss: 2.56715912|Test loss: 3.32140740\n","Epoch: 477 | Lr: 0.00100000000000000002 |Train loss: 2.58481318|Test loss: 3.25639232\n","Epoch: 478 | Lr: 0.00100000000000000002 |Train loss: 2.58555263|Test loss: 3.24271290\n","Epoch: 479 | Lr: 0.00100000000000000002 |Train loss: 2.57912795|Test loss: 3.25237958\n","Epoch: 480 | Lr: 0.00100000000000000002 |Train loss: 2.55207135|Test loss: 3.34331830\n","Epoch: 481 | Lr: 0.00100000000000000002 |Train loss: 2.56414505|Test loss: 3.27314989\n","Epoch: 482 | Lr: 0.00100000000000000002 |Train loss: 2.53269627|Test loss: 3.24373015\n","Epoch: 483 | Lr: 0.00100000000000000002 |Train loss: 2.52262026|Test loss: 3.25429972\n","Epoch: 484 | Lr: 0.00100000000000000002 |Train loss: 2.55181925|Test loss: 3.26500638\n","Epoch: 485 | Lr: 0.00100000000000000002 |Train loss: 2.54008595|Test loss: 3.31170901\n","Epoch: 486 | Lr: 0.00100000000000000002 |Train loss: 2.53329728|Test loss: 3.31015658\n","Epoch: 487 | Lr: 0.00100000000000000002 |Train loss: 2.52157875|Test loss: 3.27311357\n","Epoch: 488 | Lr: 0.00100000000000000002 |Train loss: 2.50311526|Test loss: 3.25261569\n","Epoch: 489 | Lr: 0.00100000000000000002 |Train loss: 2.50397110|Test loss: 3.25464535\n","Epoch: 490 | Lr: 0.00100000000000000002 |Train loss: 2.50424451|Test loss: 3.25137432\n","Epoch: 491 | Lr: 0.00100000000000000002 |Train loss: 2.50113746|Test loss: 3.33992219\n","Epoch: 492 | Lr: 0.00100000000000000002 |Train loss: 2.52205475|Test loss: 3.29633959\n","Epoch: 493 | Lr: 0.00100000000000000002 |Train loss: 2.52865551|Test loss: 3.29091835\n","Epoch: 494 | Lr: 0.00100000000000000002 |Train loss: 2.52161626|Test loss: 3.23367397\n","Epoch: 495 | Lr: 0.00100000000000000002 |Train loss: 2.57910220|Test loss: 3.20140211\n","Epoch: 496 | Lr: 0.00100000000000000002 |Train loss: 2.57254124|Test loss: 3.23477125\n","Epoch: 497 | Lr: 0.00100000000000000002 |Train loss: 2.54197200|Test loss: 3.25579460\n","Epoch: 498 | Lr: 0.00100000000000000002 |Train loss: 2.53220659|Test loss: 3.30098351\n","Epoch: 499 | Lr: 0.00100000000000000002 |Train loss: 2.53709994|Test loss: 3.23191937\n","Epoch: 500 | Lr: 0.00100000000000000002 |Train loss: 2.50664101|Test loss: 3.24285507\n","Epoch: 501 | Lr: 0.00100000000000000002 |Train loss: 2.50435942|Test loss: 3.24290490\n","Epoch: 502 | Lr: 0.00100000000000000002 |Train loss: 2.52330170|Test loss: 3.27195533\n","Epoch: 503 | Lr: 0.00100000000000000002 |Train loss: 2.51458114|Test loss: 3.25069284\n","Epoch: 504 | Lr: 0.00100000000000000002 |Train loss: 2.48707902|Test loss: 3.25987164\n","Epoch: 505 | Lr: 0.00100000000000000002 |Train loss: 2.47968068|Test loss: 3.22234217\n","Epoch: 506 | Lr: 0.00100000000000000002 |Train loss: 2.49501449|Test loss: 3.26809104\n","Epoch: 507 | Lr: 0.00100000000000000002 |Train loss: 2.48047306|Test loss: 3.25768113\n","Epoch: 508 | Lr: 0.00100000000000000002 |Train loss: 2.48065950|Test loss: 3.28610746\n","Epoch: 509 | Lr: 0.00100000000000000002 |Train loss: 2.49045440|Test loss: 3.30043674\n","Epoch: 510 | Lr: 0.00100000000000000002 |Train loss: 2.51927294|Test loss: 3.38858207\n","Epoch: 511 | Lr: 0.00100000000000000002 |Train loss: 2.51579465|Test loss: 3.28842632\n","Epoch: 512 | Lr: 0.00100000000000000002 |Train loss: 2.59154137|Test loss: 3.29327408\n","Epoch: 513 | Lr: 0.00100000000000000002 |Train loss: 2.57059757|Test loss: 3.23688809\n","Epoch: 514 | Lr: 0.00100000000000000002 |Train loss: 2.55169404|Test loss: 3.28644538\n","Epoch: 515 | Lr: 0.00100000000000000002 |Train loss: 2.60166973|Test loss: 3.43908413\n","Epoch: 516 | Lr: 0.00100000000000000002 |Train loss: 2.62871031|Test loss: 3.34449522\n","Epoch: 517 | Lr: 0.00100000000000000002 |Train loss: 2.61796111|Test loss: 3.22619820\n","Epoch: 518 | Lr: 0.00100000000000000002 |Train loss: 2.57386609|Test loss: 3.23483245\n","Epoch: 519 | Lr: 0.00100000000000000002 |Train loss: 2.55949630|Test loss: 3.27141349\n","Epoch: 520 | Lr: 0.00100000000000000002 |Train loss: 2.52324947|Test loss: 3.28562101\n","Epoch: 521 | Lr: 0.00100000000000000002 |Train loss: 2.53205985|Test loss: 3.31849957\n","Epoch: 522 | Lr: 0.00100000000000000002 |Train loss: 2.54451187|Test loss: 3.30314175\n","Epoch: 523 | Lr: 0.00100000000000000002 |Train loss: 2.54125520|Test loss: 3.23433860\n","Epoch: 524 | Lr: 0.00100000000000000002 |Train loss: 2.55234309|Test loss: 3.22635674\n","Epoch: 525 | Lr: 0.00100000000000000002 |Train loss: 2.58602069|Test loss: 3.26118978\n","Epoch: 526 | Lr: 0.00100000000000000002 |Train loss: 2.67117767|Test loss: 3.32529402\n","Epoch: 527 | Lr: 0.00100000000000000002 |Train loss: 2.68948364|Test loss: 3.41101185\n","Epoch: 528 | Lr: 0.00100000000000000002 |Train loss: 2.65848329|Test loss: 3.39912669\n","Epoch: 529 | Lr: 0.00100000000000000002 |Train loss: 2.58254761|Test loss: 3.37084357\n","Epoch: 530 | Lr: 0.00100000000000000002 |Train loss: 2.55217493|Test loss: 3.32248028\n","Epoch: 531 | Lr: 0.00100000000000000002 |Train loss: 2.57925852|Test loss: 3.28926619\n","Epoch: 532 | Lr: 0.00100000000000000002 |Train loss: 2.61912910|Test loss: 3.23179730\n","Epoch: 533 | Lr: 0.00100000000000000002 |Train loss: 2.55547206|Test loss: 3.26486969\n","Epoch: 534 | Lr: 0.00100000000000000002 |Train loss: 2.53347796|Test loss: 3.29830440\n","Epoch: 535 | Lr: 0.00100000000000000002 |Train loss: 2.57102942|Test loss: 3.35945566\n","Epoch: 536 | Lr: 0.00100000000000000002 |Train loss: 2.54232955|Test loss: 3.27662412\n","Epoch: 537 | Lr: 0.00100000000000000002 |Train loss: 2.51798892|Test loss: 3.25555873\n","Epoch: 538 | Lr: 0.00100000000000000002 |Train loss: 2.54739579|Test loss: 3.21819981\n","Epoch: 539 | Lr: 0.00100000000000000002 |Train loss: 2.51120758|Test loss: 3.23560667\n","Epoch: 540 | Lr: 0.00100000000000000002 |Train loss: 2.52706168|Test loss: 3.24508095\n","Epoch: 541 | Lr: 0.00100000000000000002 |Train loss: 2.49852383|Test loss: 3.28172533\n","Epoch: 542 | Lr: 0.00100000000000000002 |Train loss: 2.52703063|Test loss: 3.33962409\n","Epoch: 543 | Lr: 0.00100000000000000002 |Train loss: 2.53392764|Test loss: 3.28643982\n","Epoch: 544 | Lr: 0.00100000000000000002 |Train loss: 2.53225521|Test loss: 3.27251458\n","Epoch: 545 | Lr: 0.00100000000000000002 |Train loss: 2.54227686|Test loss: 3.18792892\n","Epoch: 546 | Lr: 0.00100000000000000002 |Train loss: 2.58041302|Test loss: 3.17882347\n","Epoch: 547 | Lr: 0.00100000000000000002 |Train loss: 2.54280957|Test loss: 3.33312321\n","Epoch: 548 | Lr: 0.00100000000000000002 |Train loss: 2.55689196|Test loss: 3.38018974\n","Epoch: 549 | Lr: 0.00100000000000000002 |Train loss: 2.53747463|Test loss: 3.22235568\n","Epoch: 550 | Lr: 0.00100000000000000002 |Train loss: 2.48872759|Test loss: 3.21986032\n","Epoch: 551 | Lr: 0.00100000000000000002 |Train loss: 2.49097033|Test loss: 3.19697102\n","Epoch: 552 | Lr: 0.00100000000000000002 |Train loss: 2.48677297|Test loss: 3.23165067\n","Epoch: 553 | Lr: 0.00100000000000000002 |Train loss: 2.49044540|Test loss: 3.24289966\n","Epoch: 554 | Lr: 0.00100000000000000002 |Train loss: 2.48052041|Test loss: 3.25791836\n","Epoch: 555 | Lr: 0.00100000000000000002 |Train loss: 2.46517469|Test loss: 3.24222199\n","Epoch: 556 | Lr: 0.00100000000000000002 |Train loss: 2.46509075|Test loss: 3.25118526\n","Epoch: 557 | Lr: 0.00100000000000000002 |Train loss: 2.46561573|Test loss: 3.26481771\n","Epoch: 558 | Lr: 0.00100000000000000002 |Train loss: 2.46620633|Test loss: 3.26801149\n","Epoch: 559 | Lr: 0.00100000000000000002 |Train loss: 2.47849739|Test loss: 3.27425464\n","Epoch: 560 | Lr: 0.00100000000000000002 |Train loss: 2.48229464|Test loss: 3.25876919\n","Epoch: 561 | Lr: 0.00100000000000000002 |Train loss: 2.51547565|Test loss: 3.25821384\n","Epoch: 562 | Lr: 0.00100000000000000002 |Train loss: 2.58469852|Test loss: 3.29825783\n","Epoch: 563 | Lr: 0.00100000000000000002 |Train loss: 2.57900645|Test loss: 3.37566336\n","Epoch: 564 | Lr: 0.00100000000000000002 |Train loss: 2.57984251|Test loss: 3.39098064\n","Epoch: 565 | Lr: 0.00100000000000000002 |Train loss: 2.56511346|Test loss: 3.29779315\n","Epoch: 566 | Lr: 0.00100000000000000002 |Train loss: 2.58596611|Test loss: 3.33323868\n","Epoch: 567 | Lr: 0.00100000000000000002 |Train loss: 2.59410826|Test loss: 3.28331447\n","Epoch: 568 | Lr: 0.00100000000000000002 |Train loss: 2.62589063|Test loss: 3.25975649\n","Epoch: 569 | Lr: 0.00100000000000000002 |Train loss: 2.58752696|Test loss: 3.29873562\n","Epoch: 570 | Lr: 0.00100000000000000002 |Train loss: 2.57712613|Test loss: 3.30643288\n","Epoch: 571 | Lr: 0.00100000000000000002 |Train loss: 2.55656674|Test loss: 3.28052910\n","Epoch: 572 | Lr: 0.00100000000000000002 |Train loss: 2.51021522|Test loss: 3.21033255\n","Epoch: 573 | Lr: 0.00100000000000000002 |Train loss: 2.57699005|Test loss: 3.21187027\n","Epoch: 574 | Lr: 0.00100000000000000002 |Train loss: 2.53835104|Test loss: 3.28376261\n","Epoch: 575 | Lr: 0.00100000000000000002 |Train loss: 2.49750926|Test loss: 3.23109865\n","Epoch: 576 | Lr: 0.00100000000000000002 |Train loss: 2.49241873|Test loss: 3.27390440\n","Epoch: 577 | Lr: 0.00100000000000000002 |Train loss: 2.48486131|Test loss: 3.27908055\n","Epoch: 578 | Lr: 0.00100000000000000002 |Train loss: 2.48721351|Test loss: 3.24743478\n","Epoch: 579 | Lr: 0.00100000000000000002 |Train loss: 2.48899235|Test loss: 3.24741252\n","Epoch: 580 | Lr: 0.00100000000000000002 |Train loss: 2.47210356|Test loss: 3.23620065\n","Epoch: 581 | Lr: 0.00100000000000000002 |Train loss: 2.46300109|Test loss: 3.24133396\n","Epoch: 582 | Lr: 0.00100000000000000002 |Train loss: 2.47116144|Test loss: 3.21093464\n","Epoch: 583 | Lr: 0.00100000000000000002 |Train loss: 2.47483657|Test loss: 3.24961718\n","Epoch: 584 | Lr: 0.00100000000000000002 |Train loss: 2.48929721|Test loss: 3.31268875\n","Epoch: 585 | Lr: 0.00100000000000000002 |Train loss: 2.48585723|Test loss: 3.29451084\n","Epoch: 586 | Lr: 0.00100000000000000002 |Train loss: 2.46342623|Test loss: 3.27285020\n","Epoch: 587 | Lr: 0.00100000000000000002 |Train loss: 2.49100284|Test loss: 3.27205213\n","Epoch: 588 | Lr: 0.00100000000000000002 |Train loss: 2.50583041|Test loss: 3.25932089\n","Epoch: 589 | Lr: 0.00100000000000000002 |Train loss: 2.48394175|Test loss: 3.24361388\n","Epoch: 590 | Lr: 0.00100000000000000002 |Train loss: 2.51304481|Test loss: 3.25625722\n","Epoch: 591 | Lr: 0.00100000000000000002 |Train loss: 2.52182486|Test loss: 3.28586562\n","Epoch: 592 | Lr: 0.00100000000000000002 |Train loss: 2.52486875|Test loss: 3.30310059\n","Epoch: 593 | Lr: 0.00100000000000000002 |Train loss: 2.50909819|Test loss: 3.24651043\n","Epoch: 594 | Lr: 0.00100000000000000002 |Train loss: 2.48463414|Test loss: 3.25214179\n","Epoch: 595 | Lr: 0.00100000000000000002 |Train loss: 2.48822417|Test loss: 3.31533003\n","Epoch: 596 | Lr: 0.00100000000000000002 |Train loss: 2.51438699|Test loss: 3.26044615\n","Epoch: 597 | Lr: 0.00100000000000000002 |Train loss: 2.50938410|Test loss: 3.29148666\n","Epoch: 598 | Lr: 0.00100000000000000002 |Train loss: 2.53962012|Test loss: 3.29661918\n","Epoch: 599 | Lr: 0.00100000000000000002 |Train loss: 2.58818241|Test loss: 3.22979641\n","Epoch: 600 | Lr: 0.00100000000000000002 |Train loss: 2.56979720|Test loss: 3.20630225\n","Epoch: 601 | Lr: 0.00100000000000000002 |Train loss: 2.51871004|Test loss: 3.25907453\n","Epoch: 602 | Lr: 0.00100000000000000002 |Train loss: 2.50782466|Test loss: 3.31066386\n","Epoch: 603 | Lr: 0.00100000000000000002 |Train loss: 2.54016364|Test loss: 3.34328548\n","Epoch: 604 | Lr: 0.00100000000000000002 |Train loss: 2.51821589|Test loss: 3.28662475\n","Epoch: 605 | Lr: 0.00100000000000000002 |Train loss: 2.47055443|Test loss: 3.25147200\n","Epoch: 606 | Lr: 0.00100000000000000002 |Train loss: 2.47402436|Test loss: 3.23901677\n","Epoch: 607 | Lr: 0.00100000000000000002 |Train loss: 2.47784080|Test loss: 3.23303715\n","Epoch: 608 | Lr: 0.00100000000000000002 |Train loss: 2.46209309|Test loss: 3.20906035\n","Epoch: 609 | Lr: 0.00100000000000000002 |Train loss: 2.47177001|Test loss: 3.19698882\n","Epoch: 610 | Lr: 0.00100000000000000002 |Train loss: 2.48610667|Test loss: 3.24076668\n","Epoch: 611 | Lr: 0.00100000000000000002 |Train loss: 2.47371322|Test loss: 3.26695983\n","Epoch: 612 | Lr: 0.00100000000000000002 |Train loss: 2.50395892|Test loss: 3.24004817\n","Epoch: 613 | Lr: 0.00100000000000000002 |Train loss: 2.57143629|Test loss: 3.27663604\n","Epoch: 614 | Lr: 0.00100000000000000002 |Train loss: 2.55552574|Test loss: 3.35282516\n","Epoch: 615 | Lr: 0.00100000000000000002 |Train loss: 2.55579452|Test loss: 3.40128001\n","Epoch: 616 | Lr: 0.00100000000000000002 |Train loss: 2.53987036|Test loss: 3.35933216\n","Epoch: 617 | Lr: 0.00100000000000000002 |Train loss: 2.51266410|Test loss: 3.25383321\n","Epoch: 618 | Lr: 0.00100000000000000002 |Train loss: 2.54703687|Test loss: 3.24035954\n","Epoch: 619 | Lr: 0.00100000000000000002 |Train loss: 2.65819758|Test loss: 3.35815096\n","Epoch: 620 | Lr: 0.00100000000000000002 |Train loss: 2.53048519|Test loss: 3.28672504\n","Epoch: 621 | Lr: 0.00100000000000000002 |Train loss: 2.49297410|Test loss: 3.29638521\n","Epoch: 622 | Lr: 0.00100000000000000002 |Train loss: 2.54054840|Test loss: 3.30301881\n","Epoch: 623 | Lr: 0.00100000000000000002 |Train loss: 2.49624544|Test loss: 3.23969213\n","Epoch: 624 | Lr: 0.00100000000000000002 |Train loss: 2.46352150|Test loss: 3.25024390\n","Epoch: 625 | Lr: 0.00100000000000000002 |Train loss: 2.46502588|Test loss: 3.27265716\n","Epoch: 626 | Lr: 0.00100000000000000002 |Train loss: 2.50507766|Test loss: 3.34569001\n","Epoch: 627 | Lr: 0.00100000000000000002 |Train loss: 2.48346817|Test loss: 3.34104681\n","Epoch: 628 | Lr: 0.00100000000000000002 |Train loss: 2.46387770|Test loss: 3.29665796\n","Epoch: 629 | Lr: 0.00100000000000000002 |Train loss: 2.48631626|Test loss: 3.25149330\n","Epoch: 630 | Lr: 0.00100000000000000002 |Train loss: 2.51393493|Test loss: 3.24629442\n","Epoch: 631 | Lr: 0.00100000000000000002 |Train loss: 2.54305512|Test loss: 3.24214061\n","Epoch: 632 | Lr: 0.00100000000000000002 |Train loss: 2.52346083|Test loss: 3.23112440\n","Epoch: 633 | Lr: 0.00100000000000000002 |Train loss: 2.55409380|Test loss: 3.31560310\n","Epoch: 634 | Lr: 0.00100000000000000002 |Train loss: 2.59335524|Test loss: 3.47614622\n","Epoch: 635 | Lr: 0.00100000000000000002 |Train loss: 2.59619554|Test loss: 3.26038933\n","Epoch: 636 | Lr: 0.00100000000000000002 |Train loss: 2.50796602|Test loss: 3.20767848\n","Epoch: 637 | Lr: 0.00100000000000000002 |Train loss: 2.47701212|Test loss: 3.18759950\n","Epoch: 638 | Lr: 0.00100000000000000002 |Train loss: 2.45662757|Test loss: 3.24200630\n","Epoch: 639 | Lr: 0.00100000000000000002 |Train loss: 2.45050907|Test loss: 3.28481944\n","Epoch: 640 | Lr: 0.00100000000000000002 |Train loss: 2.45107559|Test loss: 3.24580288\n","Epoch: 641 | Lr: 0.00100000000000000002 |Train loss: 2.45217830|Test loss: 3.27144027\n","Epoch: 642 | Lr: 0.00100000000000000002 |Train loss: 2.43883709|Test loss: 3.22603075\n","Epoch: 643 | Lr: 0.00100000000000000002 |Train loss: 2.43912562|Test loss: 3.21858581\n","Epoch: 644 | Lr: 0.00100000000000000002 |Train loss: 2.43141049|Test loss: 3.24747221\n","Epoch: 645 | Lr: 0.00100000000000000002 |Train loss: 2.44709188|Test loss: 3.27003709\n","Epoch: 646 | Lr: 0.00100000000000000002 |Train loss: 2.44482142|Test loss: 3.30454429\n","Epoch: 647 | Lr: 0.00100000000000000002 |Train loss: 2.43962248|Test loss: 3.31468177\n","Epoch: 648 | Lr: 0.00100000000000000002 |Train loss: 2.45120680|Test loss: 3.33495744\n","Epoch: 649 | Lr: 0.00100000000000000002 |Train loss: 2.46572582|Test loss: 3.30380217\n","Epoch: 650 | Lr: 0.00100000000000000002 |Train loss: 2.47841018|Test loss: 3.28079836\n","Epoch: 651 | Lr: 0.00100000000000000002 |Train loss: 2.48626540|Test loss: 3.23412991\n","Epoch: 652 | Lr: 0.00100000000000000002 |Train loss: 2.49723468|Test loss: 3.30346290\n","Epoch: 653 | Lr: 0.00100000000000000002 |Train loss: 2.53283968|Test loss: 3.38470435\n","Epoch: 654 | Lr: 0.00100000000000000002 |Train loss: 2.58732637|Test loss: 3.32332953\n","Epoch: 655 | Lr: 0.00100000000000000002 |Train loss: 2.52680679|Test loss: 3.23876564\n","Epoch: 656 | Lr: 0.00100000000000000002 |Train loss: 2.53437348|Test loss: 3.19326687\n","Epoch: 657 | Lr: 0.00100000000000000002 |Train loss: 2.54726495|Test loss: 3.21648248\n","Epoch: 658 | Lr: 0.00100000000000000002 |Train loss: 2.49740509|Test loss: 3.30037411\n","Epoch: 659 | Lr: 0.00100000000000000002 |Train loss: 2.51289028|Test loss: 3.29373622\n","Epoch: 660 | Lr: 0.00100000000000000002 |Train loss: 2.51049689|Test loss: 3.21692872\n","Epoch: 661 | Lr: 0.00100000000000000002 |Train loss: 2.49512605|Test loss: 3.26345563\n","Epoch: 662 | Lr: 0.00100000000000000002 |Train loss: 2.50399182|Test loss: 3.24867773\n","Epoch: 663 | Lr: 0.00100000000000000002 |Train loss: 2.50095216|Test loss: 3.31259672\n","Epoch: 664 | Lr: 0.00100000000000000002 |Train loss: 2.52096782|Test loss: 3.32664959\n","Epoch: 665 | Lr: 0.00100000000000000002 |Train loss: 2.52248687|Test loss: 3.36499151\n","Epoch: 666 | Lr: 0.00100000000000000002 |Train loss: 2.50849901|Test loss: 3.28212134\n","Epoch: 667 | Lr: 0.00100000000000000002 |Train loss: 2.53134451|Test loss: 3.19500621\n","Epoch: 668 | Lr: 0.00100000000000000002 |Train loss: 2.63143158|Test loss: 3.21646110\n","Epoch: 669 | Lr: 0.00100000000000000002 |Train loss: 2.51660872|Test loss: 3.37737052\n","Epoch: 670 | Lr: 0.00100000000000000002 |Train loss: 2.52206055|Test loss: 3.28821349\n","Epoch: 671 | Lr: 0.00100000000000000002 |Train loss: 2.49162912|Test loss: 3.23063374\n","Epoch: 672 | Lr: 0.00100000000000000002 |Train loss: 2.46438164|Test loss: 3.24204548\n","Epoch: 673 | Lr: 0.00100000000000000002 |Train loss: 2.47417615|Test loss: 3.23470402\n","Epoch: 674 | Lr: 0.00100000000000000002 |Train loss: 2.45783039|Test loss: 3.24539630\n","Epoch: 675 | Lr: 0.00100000000000000002 |Train loss: 2.46670957|Test loss: 3.24217439\n","Epoch: 676 | Lr: 0.00100000000000000002 |Train loss: 2.44410040|Test loss: 3.23888755\n","Epoch: 677 | Lr: 0.00100000000000000002 |Train loss: 2.42245660|Test loss: 3.26130660\n","Epoch: 678 | Lr: 0.00100000000000000002 |Train loss: 2.43036592|Test loss: 3.25725166\n","Epoch: 679 | Lr: 0.00100000000000000002 |Train loss: 2.43548081|Test loss: 3.25245333\n","Epoch: 680 | Lr: 0.00100000000000000002 |Train loss: 2.44698177|Test loss: 3.26864139\n","Epoch: 681 | Lr: 0.00100000000000000002 |Train loss: 2.43502049|Test loss: 3.26314330\n","Epoch: 682 | Lr: 0.00100000000000000002 |Train loss: 2.46391690|Test loss: 3.22922071\n","Epoch: 683 | Lr: 0.00100000000000000002 |Train loss: 2.47426951|Test loss: 3.22712684\n","Epoch: 684 | Lr: 0.00100000000000000002 |Train loss: 2.48012847|Test loss: 3.24250547\n","Epoch: 685 | Lr: 0.00100000000000000002 |Train loss: 2.45563906|Test loss: 3.24160385\n","Epoch: 686 | Lr: 0.00100000000000000002 |Train loss: 2.47197040|Test loss: 3.25069467\n","Epoch: 687 | Lr: 0.00100000000000000002 |Train loss: 2.47939966|Test loss: 3.27487167\n","Epoch: 688 | Lr: 0.00100000000000000002 |Train loss: 2.52013369|Test loss: 3.37493277\n","Epoch: 689 | Lr: 0.00100000000000000002 |Train loss: 2.54353098|Test loss: 3.30699118\n","Epoch: 690 | Lr: 0.00100000000000000002 |Train loss: 2.54779993|Test loss: 3.32730802\n","Epoch: 691 | Lr: 0.00100000000000000002 |Train loss: 2.50229740|Test loss: 3.35537918\n","Epoch: 692 | Lr: 0.00100000000000000002 |Train loss: 2.56251818|Test loss: 3.26607140\n","Epoch: 693 | Lr: 0.00100000000000000002 |Train loss: 2.67939623|Test loss: 3.22552848\n","Epoch: 694 | Lr: 0.00100000000000000002 |Train loss: 2.56791164|Test loss: 3.30425342\n","Epoch: 695 | Lr: 0.00100000000000000002 |Train loss: 2.54559239|Test loss: 3.42516653\n","Epoch: 696 | Lr: 0.00100000000000000002 |Train loss: 2.54644096|Test loss: 3.31696892\n","Epoch: 697 | Lr: 0.00100000000000000002 |Train loss: 2.50478800|Test loss: 3.26036366\n","Epoch: 698 | Lr: 0.00100000000000000002 |Train loss: 2.47145142|Test loss: 3.25890501\n","Epoch: 699 | Lr: 0.00100000000000000002 |Train loss: 2.47596312|Test loss: 3.21991404\n","Epoch: 700 | Lr: 0.00100000000000000002 |Train loss: 2.45400194|Test loss: 3.28451387\n","Epoch: 701 | Lr: 0.00100000000000000002 |Train loss: 2.43530466|Test loss: 3.27402401\n","Epoch: 702 | Lr: 0.00100000000000000002 |Train loss: 2.43345408|Test loss: 3.23485104\n","Epoch: 703 | Lr: 0.00100000000000000002 |Train loss: 2.42758717|Test loss: 3.23034461\n","Epoch: 704 | Lr: 0.00100000000000000002 |Train loss: 2.43340206|Test loss: 3.21356662\n","Epoch: 705 | Lr: 0.00100000000000000002 |Train loss: 2.43187757|Test loss: 3.19692127\n","Epoch: 706 | Lr: 0.00100000000000000002 |Train loss: 2.42587183|Test loss: 3.25607840\n","Epoch: 707 | Lr: 0.00100000000000000002 |Train loss: 2.44232039|Test loss: 3.26182230\n","Epoch: 708 | Lr: 0.00100000000000000002 |Train loss: 2.42405585|Test loss: 3.25790366\n","Epoch: 709 | Lr: 0.00100000000000000002 |Train loss: 2.43502063|Test loss: 3.24091498\n","Epoch: 710 | Lr: 0.00100000000000000002 |Train loss: 2.43635378|Test loss: 3.26188596\n","Epoch: 711 | Lr: 0.00100000000000000002 |Train loss: 2.45401071|Test loss: 3.22137213\n","Epoch: 712 | Lr: 0.00100000000000000002 |Train loss: 2.44860202|Test loss: 3.26660426\n","Epoch: 713 | Lr: 0.00100000000000000002 |Train loss: 2.47340282|Test loss: 3.27763287\n","Epoch: 714 | Lr: 0.00100000000000000002 |Train loss: 2.47344013|Test loss: 3.30747207\n","Epoch: 715 | Lr: 0.00100000000000000002 |Train loss: 2.48655375|Test loss: 3.30551378\n","Epoch: 716 | Lr: 0.00100000000000000002 |Train loss: 2.46162480|Test loss: 3.34192459\n","Epoch: 717 | Lr: 0.00100000000000000002 |Train loss: 2.47559712|Test loss: 3.33739265\n","Epoch: 718 | Lr: 0.00100000000000000002 |Train loss: 2.53547303|Test loss: 3.23694984\n","Epoch: 719 | Lr: 0.00100000000000000002 |Train loss: 2.58955648|Test loss: 3.30913154\n","Epoch: 720 | Lr: 0.00100000000000000002 |Train loss: 2.56481532|Test loss: 3.35760069\n","Epoch: 721 | Lr: 0.00100000000000000002 |Train loss: 2.47659755|Test loss: 3.28455758\n","Epoch: 722 | Lr: 0.00100000000000000002 |Train loss: 2.44597707|Test loss: 3.26717869\n","Epoch: 723 | Lr: 0.00100000000000000002 |Train loss: 2.47641404|Test loss: 3.31938577\n","Epoch: 724 | Lr: 0.00100000000000000002 |Train loss: 2.46358633|Test loss: 3.23504051\n","Epoch: 725 | Lr: 0.00100000000000000002 |Train loss: 2.44730419|Test loss: 3.27770615\n","Epoch: 726 | Lr: 0.00100000000000000002 |Train loss: 2.42356141|Test loss: 3.27671655\n","Epoch: 727 | Lr: 0.00100000000000000002 |Train loss: 2.43505023|Test loss: 3.28394421\n","Epoch: 728 | Lr: 0.00100000000000000002 |Train loss: 2.44661534|Test loss: 3.28361797\n","Epoch: 729 | Lr: 0.00100000000000000002 |Train loss: 2.44515659|Test loss: 3.28523795\n","Epoch: 730 | Lr: 0.00100000000000000002 |Train loss: 2.49835497|Test loss: 3.26600703\n","Epoch: 731 | Lr: 0.00100000000000000002 |Train loss: 2.47567465|Test loss: 3.23948693\n","Epoch: 732 | Lr: 0.00100000000000000002 |Train loss: 2.44413761|Test loss: 3.22991848\n","Epoch: 733 | Lr: 0.00100000000000000002 |Train loss: 2.45519706|Test loss: 3.35009464\n","Epoch: 734 | Lr: 0.00100000000000000002 |Train loss: 2.46425428|Test loss: 3.28917019\n","Epoch: 735 | Lr: 0.00100000000000000002 |Train loss: 2.43146841|Test loss: 3.25419005\n","Epoch: 736 | Lr: 0.00100000000000000002 |Train loss: 2.42847474|Test loss: 3.27516794\n","Epoch: 737 | Lr: 0.00100000000000000002 |Train loss: 2.41229737|Test loss: 3.28038112\n","Epoch: 738 | Lr: 0.00100000000000000002 |Train loss: 2.42080297|Test loss: 3.24390276\n","Epoch: 739 | Lr: 0.00100000000000000002 |Train loss: 2.42581292|Test loss: 3.29725774\n","Epoch: 740 | Lr: 0.00100000000000000002 |Train loss: 2.41775614|Test loss: 3.30884369\n","Epoch: 741 | Lr: 0.00100000000000000002 |Train loss: 2.41055759|Test loss: 3.28508449\n","Epoch: 742 | Lr: 0.00100000000000000002 |Train loss: 2.42382805|Test loss: 3.32333151\n","Epoch: 743 | Lr: 0.00100000000000000002 |Train loss: 2.44118720|Test loss: 3.37125468\n","Epoch: 744 | Lr: 0.00100000000000000002 |Train loss: 2.44282647|Test loss: 3.38821777\n","Epoch: 745 | Lr: 0.00100000000000000002 |Train loss: 2.45010316|Test loss: 3.42525776\n","Epoch: 746 | Lr: 0.00100000000000000002 |Train loss: 2.47562609|Test loss: 3.46235196\n","Epoch: 747 | Lr: 0.00100000000000000002 |Train loss: 2.51290945|Test loss: 3.32879241\n","Epoch: 748 | Lr: 0.00100000000000000002 |Train loss: 2.59617819|Test loss: 3.23527964\n","Epoch: 749 | Lr: 0.00100000000000000002 |Train loss: 2.64563642|Test loss: 3.31856267\n","Epoch: 750 | Lr: 0.00100000000000000002 |Train loss: 2.51224552|Test loss: 3.24102402\n","Epoch: 751 | Lr: 0.00100000000000000002 |Train loss: 2.51994530|Test loss: 3.35007207\n","Epoch: 752 | Lr: 0.00100000000000000002 |Train loss: 2.47743287|Test loss: 3.27286927\n","Epoch: 753 | Lr: 0.00100000000000000002 |Train loss: 2.44025193|Test loss: 3.29851047\n","Epoch: 754 | Lr: 0.00100000000000000002 |Train loss: 2.44168073|Test loss: 3.26581597\n","Epoch: 755 | Lr: 0.00100000000000000002 |Train loss: 2.46132145|Test loss: 3.32603876\n","Epoch: 756 | Lr: 0.00100000000000000002 |Train loss: 2.43873040|Test loss: 3.30192629\n","Epoch: 757 | Lr: 0.00100000000000000002 |Train loss: 2.41305912|Test loss: 3.28751071\n","Epoch: 758 | Lr: 0.00100000000000000002 |Train loss: 2.41918202|Test loss: 3.35605295\n","Epoch: 759 | Lr: 0.00100000000000000002 |Train loss: 2.44753869|Test loss: 3.27199682\n","Epoch: 760 | Lr: 0.00100000000000000002 |Train loss: 2.49020100|Test loss: 3.23908846\n","Epoch: 761 | Lr: 0.00100000000000000002 |Train loss: 2.53952632|Test loss: 3.26326005\n","Epoch: 762 | Lr: 0.00100000000000000002 |Train loss: 2.47898583|Test loss: 3.30324038\n","Epoch: 763 | Lr: 0.00100000000000000002 |Train loss: 2.47956836|Test loss: 3.32770212\n","Epoch: 764 | Lr: 0.00100000000000000002 |Train loss: 2.47462076|Test loss: 3.30893882\n","Epoch: 765 | Lr: 0.00100000000000000002 |Train loss: 2.48750732|Test loss: 3.32184164\n","Epoch: 766 | Lr: 0.00100000000000000002 |Train loss: 2.48012163|Test loss: 3.29494111\n","Epoch: 767 | Lr: 0.00100000000000000002 |Train loss: 2.49386772|Test loss: 3.29213921\n","Epoch: 768 | Lr: 0.00100000000000000002 |Train loss: 2.47648915|Test loss: 3.32905507\n","Epoch: 769 | Lr: 0.00100000000000000002 |Train loss: 2.47945064|Test loss: 3.29416855\n","Epoch: 770 | Lr: 0.00100000000000000002 |Train loss: 2.43880312|Test loss: 3.33281581\n","Epoch: 771 | Lr: 0.00100000000000000002 |Train loss: 2.43518039|Test loss: 3.30956109\n","Epoch: 772 | Lr: 0.00100000000000000002 |Train loss: 2.48413567|Test loss: 3.22567217\n","Epoch: 773 | Lr: 0.00100000000000000002 |Train loss: 2.69513722|Test loss: 3.23818437\n","Epoch: 774 | Lr: 0.00100000000000000002 |Train loss: 2.54437284|Test loss: 3.31704140\n","Epoch: 775 | Lr: 0.00100000000000000002 |Train loss: 2.51926013|Test loss: 3.34448028\n","Epoch: 776 | Lr: 0.00100000000000000002 |Train loss: 2.47681051|Test loss: 3.32052493\n","Epoch: 777 | Lr: 0.00100000000000000002 |Train loss: 2.43749466|Test loss: 3.30825790\n","Epoch: 778 | Lr: 0.00100000000000000002 |Train loss: 2.44959339|Test loss: 3.32837423\n","Epoch: 779 | Lr: 0.00100000000000000002 |Train loss: 2.43146199|Test loss: 3.24994111\n","Epoch: 780 | Lr: 0.00100000000000000002 |Train loss: 2.41258425|Test loss: 3.31611578\n","Epoch: 781 | Lr: 0.00100000000000000002 |Train loss: 2.43439507|Test loss: 3.25300956\n","Epoch: 782 | Lr: 0.00100000000000000002 |Train loss: 2.42610027|Test loss: 3.29762737\n","Epoch: 783 | Lr: 0.00100000000000000002 |Train loss: 2.43436493|Test loss: 3.20474299\n","Epoch: 784 | Lr: 0.00100000000000000002 |Train loss: 2.42237365|Test loss: 3.25679048\n","Epoch: 785 | Lr: 0.00100000000000000002 |Train loss: 2.42082179|Test loss: 3.25102170\n","Epoch: 786 | Lr: 0.00100000000000000002 |Train loss: 2.40465903|Test loss: 3.26839558\n","Epoch: 787 | Lr: 0.00100000000000000002 |Train loss: 2.40542664|Test loss: 3.30118140\n","Epoch: 788 | Lr: 0.00100000000000000002 |Train loss: 2.41836194|Test loss: 3.34080974\n","Epoch: 789 | Lr: 0.00100000000000000002 |Train loss: 2.41166049|Test loss: 3.32635085\n","Epoch: 790 | Lr: 0.00100000000000000002 |Train loss: 2.39475435|Test loss: 3.30368773\n","Epoch: 791 | Lr: 0.00100000000000000002 |Train loss: 2.40110739|Test loss: 3.32732892\n","Epoch: 792 | Lr: 0.00100000000000000002 |Train loss: 2.41057867|Test loss: 3.26585579\n","Epoch: 793 | Lr: 0.00100000000000000002 |Train loss: 2.45809780|Test loss: 3.24620318\n","Epoch: 794 | Lr: 0.00100000000000000002 |Train loss: 2.45839878|Test loss: 3.27052649\n","Epoch: 795 | Lr: 0.00100000000000000002 |Train loss: 2.45498568|Test loss: 3.24767375\n","Epoch: 796 | Lr: 0.00100000000000000002 |Train loss: 2.47117305|Test loss: 3.29567448\n","Epoch: 797 | Lr: 0.00100000000000000002 |Train loss: 2.47031748|Test loss: 3.31207633\n","Epoch: 798 | Lr: 0.00100000000000000002 |Train loss: 2.45195431|Test loss: 3.30667917\n","Epoch: 799 | Lr: 0.00100000000000000002 |Train loss: 2.42058589|Test loss: 3.36986653\n","Epoch: 800 | Lr: 0.00100000000000000002 |Train loss: 2.40480717|Test loss: 3.31485526\n","Epoch: 801 | Lr: 0.00100000000000000002 |Train loss: 2.42000755|Test loss: 3.29737886\n","Epoch: 802 | Lr: 0.00100000000000000002 |Train loss: 2.48580952|Test loss: 3.30825766\n","Epoch: 803 | Lr: 0.00100000000000000002 |Train loss: 2.47209724|Test loss: 3.28975590\n","Epoch: 804 | Lr: 0.00100000000000000002 |Train loss: 2.46157908|Test loss: 3.28608688\n","Epoch: 805 | Lr: 0.00100000000000000002 |Train loss: 2.48903990|Test loss: 3.31457074\n","Epoch: 806 | Lr: 0.00100000000000000002 |Train loss: 2.50325819|Test loss: 3.20728842\n","Epoch: 807 | Lr: 0.00100000000000000002 |Train loss: 2.49082822|Test loss: 3.28948172\n","Epoch: 808 | Lr: 0.00100000000000000002 |Train loss: 2.47370774|Test loss: 3.33375239\n","Epoch: 809 | Lr: 0.00100000000000000002 |Train loss: 2.46743745|Test loss: 3.37749275\n","Epoch: 810 | Lr: 0.00100000000000000002 |Train loss: 2.47455424|Test loss: 3.32578325\n","Epoch: 811 | Lr: 0.00100000000000000002 |Train loss: 2.41059089|Test loss: 3.28653471\n","Epoch: 812 | Lr: 0.00100000000000000002 |Train loss: 2.42763835|Test loss: 3.21558285\n","Epoch: 813 | Lr: 0.00100000000000000002 |Train loss: 2.44506703|Test loss: 3.24482401\n","Epoch: 814 | Lr: 0.00100000000000000002 |Train loss: 2.45016160|Test loss: 3.30335116\n","Epoch: 815 | Lr: 0.00100000000000000002 |Train loss: 2.44386981|Test loss: 3.30106107\n","Epoch: 816 | Lr: 0.00100000000000000002 |Train loss: 2.42026762|Test loss: 3.22268709\n","Epoch: 817 | Lr: 0.00100000000000000002 |Train loss: 2.39117855|Test loss: 3.24661764\n","Epoch: 818 | Lr: 0.00100000000000000002 |Train loss: 2.41109788|Test loss: 3.25861271\n","Epoch: 819 | Lr: 0.00100000000000000002 |Train loss: 2.43815647|Test loss: 3.31041845\n","Epoch: 820 | Lr: 0.00100000000000000002 |Train loss: 2.42378064|Test loss: 3.27396409\n","Epoch: 821 | Lr: 0.00100000000000000002 |Train loss: 2.41180418|Test loss: 3.34689943\n","Epoch: 822 | Lr: 0.00100000000000000002 |Train loss: 2.41341486|Test loss: 3.33899562\n","Epoch: 823 | Lr: 0.00100000000000000002 |Train loss: 2.40709609|Test loss: 3.30974269\n","Epoch: 824 | Lr: 0.00100000000000000002 |Train loss: 2.42818461|Test loss: 3.27480356\n","Epoch: 825 | Lr: 0.00100000000000000002 |Train loss: 2.43337814|Test loss: 3.19426886\n","Epoch: 826 | Lr: 0.00100000000000000002 |Train loss: 2.44650245|Test loss: 3.33852442\n","Epoch: 827 | Lr: 0.00100000000000000002 |Train loss: 2.45707113|Test loss: 3.37275139\n","Epoch: 828 | Lr: 0.00100000000000000002 |Train loss: 2.45532505|Test loss: 3.26199206\n","Epoch: 829 | Lr: 0.00100000000000000002 |Train loss: 2.40321032|Test loss: 3.23590350\n","Epoch: 830 | Lr: 0.00100000000000000002 |Train loss: 2.38781697|Test loss: 3.22227502\n","Epoch: 831 | Lr: 0.00100000000000000002 |Train loss: 2.40638965|Test loss: 3.21233853\n","Epoch: 832 | Lr: 0.00100000000000000002 |Train loss: 2.38775100|Test loss: 3.19097042\n","Epoch: 833 | Lr: 0.00100000000000000002 |Train loss: 2.38050101|Test loss: 3.23072966\n","Epoch: 834 | Lr: 0.00100000000000000002 |Train loss: 2.39316148|Test loss: 3.25919978\n","Epoch: 835 | Lr: 0.00100000000000000002 |Train loss: 2.38806629|Test loss: 3.21570190\n","Epoch: 836 | Lr: 0.00100000000000000002 |Train loss: 2.35566245|Test loss: 3.25523909\n","Epoch: 837 | Lr: 0.00100000000000000002 |Train loss: 2.35412918|Test loss: 3.22893914\n","Epoch: 838 | Lr: 0.00100000000000000002 |Train loss: 2.37649167|Test loss: 3.26404254\n","Epoch: 839 | Lr: 0.00100000000000000002 |Train loss: 2.36437784|Test loss: 3.21728349\n","Epoch: 840 | Lr: 0.00100000000000000002 |Train loss: 2.34977025|Test loss: 3.25188065\n","Epoch: 841 | Lr: 0.00100000000000000002 |Train loss: 2.38848025|Test loss: 3.29761044\n","Epoch: 842 | Lr: 0.00100000000000000002 |Train loss: 2.38862256|Test loss: 3.38065004\n","Epoch: 843 | Lr: 0.00100000000000000002 |Train loss: 2.40777602|Test loss: 3.30990831\n","Epoch: 844 | Lr: 0.00100000000000000002 |Train loss: 2.38366759|Test loss: 3.28485815\n","Epoch: 845 | Lr: 0.00100000000000000002 |Train loss: 2.43085849|Test loss: 3.38288657\n","Epoch: 846 | Lr: 0.00100000000000000002 |Train loss: 2.43394836|Test loss: 3.31900406\n","Epoch: 847 | Lr: 0.00100000000000000002 |Train loss: 2.44526001|Test loss: 3.24736913\n","Epoch: 848 | Lr: 0.00100000000000000002 |Train loss: 2.48452705|Test loss: 3.38194386\n","Epoch: 849 | Lr: 0.00100000000000000002 |Train loss: 2.47719193|Test loss: 3.30808496\n","Epoch: 850 | Lr: 0.00100000000000000002 |Train loss: 2.41341577|Test loss: 3.23474177\n","Epoch: 851 | Lr: 0.00100000000000000002 |Train loss: 2.41733563|Test loss: 3.19594471\n","Epoch: 852 | Lr: 0.00100000000000000002 |Train loss: 2.42215951|Test loss: 3.21424659\n","Epoch: 853 | Lr: 0.00100000000000000002 |Train loss: 2.39732550|Test loss: 3.22912208\n","Epoch: 854 | Lr: 0.00100000000000000002 |Train loss: 2.42254514|Test loss: 3.26597794\n","Epoch: 855 | Lr: 0.00100000000000000002 |Train loss: 2.41332340|Test loss: 3.24783262\n","Epoch: 856 | Lr: 0.00100000000000000002 |Train loss: 2.37808963|Test loss: 3.28083817\n","Epoch: 857 | Lr: 0.00100000000000000002 |Train loss: 2.33932596|Test loss: 3.30392893\n","Epoch: 858 | Lr: 0.00100000000000000002 |Train loss: 2.34126868|Test loss: 3.26425529\n","Epoch: 859 | Lr: 0.00100000000000000002 |Train loss: 2.33827110|Test loss: 3.24618149\n","Epoch: 860 | Lr: 0.00100000000000000002 |Train loss: 2.35152892|Test loss: 3.29799143\n","Epoch: 861 | Lr: 0.00100000000000000002 |Train loss: 2.36185934|Test loss: 3.28773832\n","Epoch: 862 | Lr: 0.00100000000000000002 |Train loss: 2.36829501|Test loss: 3.29209860\n","Epoch: 863 | Lr: 0.00100000000000000002 |Train loss: 2.35223448|Test loss: 3.33899299\n","Epoch: 864 | Lr: 0.00100000000000000002 |Train loss: 2.35248367|Test loss: 3.34269563\n","Epoch: 865 | Lr: 0.00100000000000000002 |Train loss: 2.35928748|Test loss: 3.29888121\n","Epoch: 866 | Lr: 0.00100000000000000002 |Train loss: 2.39084810|Test loss: 3.22685401\n","Epoch: 867 | Lr: 0.00100000000000000002 |Train loss: 2.46179356|Test loss: 3.22706397\n","Epoch: 868 | Lr: 0.00100000000000000002 |Train loss: 2.50254097|Test loss: 3.21567734\n","Epoch: 869 | Lr: 0.00100000000000000002 |Train loss: 2.49612359|Test loss: 3.25808748\n","Epoch: 870 | Lr: 0.00100000000000000002 |Train loss: 2.47111694|Test loss: 3.35379394\n","Epoch: 871 | Lr: 0.00100000000000000002 |Train loss: 2.43711849|Test loss: 3.26930054\n","Epoch: 872 | Lr: 0.00100000000000000002 |Train loss: 2.36831218|Test loss: 3.25548697\n","Epoch: 873 | Lr: 0.00100000000000000002 |Train loss: 2.38365885|Test loss: 3.18881877\n","Epoch: 874 | Lr: 0.00100000000000000002 |Train loss: 2.38831570|Test loss: 3.22191326\n","Epoch: 875 | Lr: 0.00100000000000000002 |Train loss: 2.36556619|Test loss: 3.25173601\n","Epoch: 876 | Lr: 0.00100000000000000002 |Train loss: 2.37537871|Test loss: 3.26776179\n","Epoch: 877 | Lr: 0.00100000000000000002 |Train loss: 2.37639642|Test loss: 3.22324141\n","Epoch: 878 | Lr: 0.00100000000000000002 |Train loss: 2.35755366|Test loss: 3.24739321\n","Epoch: 879 | Lr: 0.00100000000000000002 |Train loss: 2.42162031|Test loss: 3.24723045\n","Epoch: 880 | Lr: 0.00100000000000000002 |Train loss: 2.43863501|Test loss: 3.24757449\n","Epoch: 881 | Lr: 0.00100000000000000002 |Train loss: 2.45900907|Test loss: 3.34357659\n","Epoch: 882 | Lr: 0.00100000000000000002 |Train loss: 2.47233035|Test loss: 3.28033177\n","Epoch: 883 | Lr: 0.00100000000000000002 |Train loss: 2.45281905|Test loss: 3.35348241\n","Epoch: 884 | Lr: 0.00100000000000000002 |Train loss: 2.42948788|Test loss: 3.41248759\n","Epoch: 885 | Lr: 0.00100000000000000002 |Train loss: 2.43051308|Test loss: 3.30772193\n","Epoch: 886 | Lr: 0.00100000000000000002 |Train loss: 2.41051010|Test loss: 3.31604743\n","Epoch: 887 | Lr: 0.00100000000000000002 |Train loss: 2.48414719|Test loss: 3.33969116\n","Epoch: 888 | Lr: 0.00100000000000000002 |Train loss: 2.53405170|Test loss: 3.27637585\n","Epoch: 889 | Lr: 0.00100000000000000002 |Train loss: 2.49166707|Test loss: 3.22148482\n","Epoch: 890 | Lr: 0.00100000000000000002 |Train loss: 2.39616913|Test loss: 3.27721310\n","Epoch: 891 | Lr: 0.00100000000000000002 |Train loss: 2.39808859|Test loss: 3.22447475\n","Epoch: 892 | Lr: 0.00100000000000000002 |Train loss: 2.38734718|Test loss: 3.23207490\n","Epoch: 893 | Lr: 0.00100000000000000002 |Train loss: 2.36217044|Test loss: 3.28637449\n","Epoch: 894 | Lr: 0.00100000000000000002 |Train loss: 2.35386366|Test loss: 3.30714798\n","Epoch: 895 | Lr: 0.00100000000000000002 |Train loss: 2.37210975|Test loss: 3.24986911\n","Epoch: 896 | Lr: 0.00100000000000000002 |Train loss: 2.32764300|Test loss: 3.28839445\n","Epoch: 897 | Lr: 0.00100000000000000002 |Train loss: 2.32748443|Test loss: 3.21184572\n","Epoch: 898 | Lr: 0.00100000000000000002 |Train loss: 2.32733307|Test loss: 3.25099357\n","Epoch: 899 | Lr: 0.00100000000000000002 |Train loss: 2.33647112|Test loss: 3.28301517\n","Epoch: 900 | Lr: 0.00100000000000000002 |Train loss: 2.34012157|Test loss: 3.28106284\n","Epoch: 901 | Lr: 0.00100000000000000002 |Train loss: 2.37499066|Test loss: 3.28288396\n","Epoch: 902 | Lr: 0.00100000000000000002 |Train loss: 2.40294474|Test loss: 3.22371848\n","Epoch: 903 | Lr: 0.00100000000000000002 |Train loss: 2.40088433|Test loss: 3.27952234\n","Epoch: 904 | Lr: 0.00100000000000000002 |Train loss: 2.44423133|Test loss: 3.17303737\n","Epoch: 905 | Lr: 0.00100000000000000002 |Train loss: 2.41167281|Test loss: 3.25593440\n","Epoch: 906 | Lr: 0.00100000000000000002 |Train loss: 2.42585697|Test loss: 3.29430779\n","Epoch: 907 | Lr: 0.00100000000000000002 |Train loss: 2.39182212|Test loss: 3.25689340\n","Epoch: 908 | Lr: 0.00100000000000000002 |Train loss: 2.34114238|Test loss: 3.20524168\n","Epoch: 909 | Lr: 0.00100000000000000002 |Train loss: 2.34598275|Test loss: 3.27571607\n","Epoch: 910 | Lr: 0.00100000000000000002 |Train loss: 2.35151410|Test loss: 3.21145447\n","Epoch: 911 | Lr: 0.00100000000000000002 |Train loss: 2.33423519|Test loss: 3.23257446\n","Epoch: 912 | Lr: 0.00100000000000000002 |Train loss: 2.32553742|Test loss: 3.25452518\n","Epoch: 913 | Lr: 0.00100000000000000002 |Train loss: 2.34251465|Test loss: 3.26546033\n","Epoch: 914 | Lr: 0.00100000000000000002 |Train loss: 2.33406893|Test loss: 3.25615637\n","Epoch: 915 | Lr: 0.00100000000000000002 |Train loss: 2.31310517|Test loss: 3.30127835\n","Epoch: 916 | Lr: 0.00100000000000000002 |Train loss: 2.33809278|Test loss: 3.23828546\n","Epoch: 917 | Lr: 0.00100000000000000002 |Train loss: 2.34807154|Test loss: 3.21113205\n","Epoch: 918 | Lr: 0.00100000000000000002 |Train loss: 2.35488876|Test loss: 3.30767941\n","Epoch: 919 | Lr: 0.00100000000000000002 |Train loss: 2.40870456|Test loss: 3.33480295\n","Epoch: 920 | Lr: 0.00100000000000000002 |Train loss: 2.41378311|Test loss: 3.26265375\n","Epoch: 921 | Lr: 0.00100000000000000002 |Train loss: 2.38640666|Test loss: 3.19767737\n","Epoch: 922 | Lr: 0.00100000000000000002 |Train loss: 2.51195767|Test loss: 3.31884670\n","Epoch: 923 | Lr: 0.00100000000000000002 |Train loss: 2.43856047|Test loss: 3.30392782\n","Epoch: 924 | Lr: 0.00100000000000000002 |Train loss: 2.38490246|Test loss: 3.22752921\n","Epoch: 925 | Lr: 0.00100000000000000002 |Train loss: 2.35110746|Test loss: 3.19185241\n","Epoch: 926 | Lr: 0.00100000000000000002 |Train loss: 2.32190367|Test loss: 3.17876673\n","Epoch: 927 | Lr: 0.00100000000000000002 |Train loss: 2.32363685|Test loss: 3.22095076\n","Epoch: 928 | Lr: 0.00100000000000000002 |Train loss: 2.34638760|Test loss: 3.24172091\n","Epoch: 929 | Lr: 0.00100000000000000002 |Train loss: 2.35565796|Test loss: 3.18766554\n","Epoch: 930 | Lr: 0.00100000000000000002 |Train loss: 2.35041217|Test loss: 3.18228308\n","Epoch: 931 | Lr: 0.00100000000000000002 |Train loss: 2.35805974|Test loss: 3.26421650\n","Epoch: 932 | Lr: 0.00100000000000000002 |Train loss: 2.38769817|Test loss: 3.31974188\n","Epoch: 933 | Lr: 0.00100000000000000002 |Train loss: 2.37308902|Test loss: 3.35150266\n","Epoch: 934 | Lr: 0.00100000000000000002 |Train loss: 2.37044108|Test loss: 3.27719879\n","Epoch: 935 | Lr: 0.00100000000000000002 |Train loss: 2.35434713|Test loss: 3.20007960\n","Epoch: 936 | Lr: 0.00100000000000000002 |Train loss: 2.40022385|Test loss: 3.24335893\n","Epoch: 937 | Lr: 0.00100000000000000002 |Train loss: 2.44365098|Test loss: 3.29472868\n","Epoch: 938 | Lr: 0.00100000000000000002 |Train loss: 2.45688230|Test loss: 3.25408236\n","Epoch: 939 | Lr: 0.00100000000000000002 |Train loss: 2.42816482|Test loss: 3.22565794\n","Epoch: 940 | Lr: 0.00100000000000000002 |Train loss: 2.37901302|Test loss: 3.18328540\n","Epoch: 941 | Lr: 0.00100000000000000002 |Train loss: 2.35709320|Test loss: 3.24809813\n","Epoch: 942 | Lr: 0.00100000000000000002 |Train loss: 2.38746331|Test loss: 3.22775825\n","Epoch: 943 | Lr: 0.00100000000000000002 |Train loss: 2.38120174|Test loss: 3.20841495\n","Epoch: 944 | Lr: 0.00100000000000000002 |Train loss: 2.38976918|Test loss: 3.40877930\n","Epoch: 945 | Lr: 0.00100000000000000002 |Train loss: 2.39830838|Test loss: 3.22867242\n","Epoch: 946 | Lr: 0.00100000000000000002 |Train loss: 2.36536113|Test loss: 3.27285099\n","Epoch: 947 | Lr: 0.00100000000000000002 |Train loss: 2.45473264|Test loss: 3.18451460\n","Epoch: 948 | Lr: 0.00100000000000000002 |Train loss: 2.37912705|Test loss: 3.17939138\n","Epoch: 949 | Lr: 0.00100000000000000002 |Train loss: 2.37169780|Test loss: 3.26882776\n","Epoch: 950 | Lr: 0.00100000000000000002 |Train loss: 2.34997561|Test loss: 3.19916550\n","Epoch: 951 | Lr: 0.00100000000000000002 |Train loss: 2.32485078|Test loss: 3.22779950\n","Epoch: 952 | Lr: 0.00100000000000000002 |Train loss: 2.30071898|Test loss: 3.20194658\n","Epoch: 953 | Lr: 0.00100000000000000002 |Train loss: 2.30360758|Test loss: 3.25191275\n","Epoch: 954 | Lr: 0.00100000000000000002 |Train loss: 2.31197292|Test loss: 3.19905043\n","Epoch: 955 | Lr: 0.00100000000000000002 |Train loss: 2.30066590|Test loss: 3.25214585\n","Epoch: 956 | Lr: 0.00100000000000000002 |Train loss: 2.29212983|Test loss: 3.24847539\n","Epoch: 957 | Lr: 0.00100000000000000002 |Train loss: 2.31359673|Test loss: 3.30084554\n","Epoch: 958 | Lr: 0.00100000000000000002 |Train loss: 2.30981332|Test loss: 3.31124282\n","Epoch: 959 | Lr: 0.00100000000000000002 |Train loss: 2.30204372|Test loss: 3.21062922\n","Epoch: 960 | Lr: 0.00100000000000000002 |Train loss: 2.47313329|Test loss: 3.19270309\n","Epoch: 961 | Lr: 0.00100000000000000002 |Train loss: 2.48979517|Test loss: 3.24264924\n","Epoch: 962 | Lr: 0.00100000000000000002 |Train loss: 2.43752267|Test loss: 3.32411170\n","Epoch: 963 | Lr: 0.00100000000000000002 |Train loss: 2.41145418|Test loss: 3.36410459\n","Epoch: 964 | Lr: 0.00100000000000000002 |Train loss: 2.37982963|Test loss: 3.20480752\n","Epoch: 965 | Lr: 0.00100000000000000002 |Train loss: 2.32070959|Test loss: 3.28741431\n","Epoch: 966 | Lr: 0.00100000000000000002 |Train loss: 2.32917414|Test loss: 3.20155112\n","Epoch: 967 | Lr: 0.00100000000000000002 |Train loss: 2.37331585|Test loss: 3.18508355\n","Epoch: 968 | Lr: 0.00100000000000000002 |Train loss: 2.31350150|Test loss: 3.24875847\n","Epoch: 969 | Lr: 0.00100000000000000002 |Train loss: 2.35925436|Test loss: 3.23722569\n","Epoch: 970 | Lr: 0.00100000000000000002 |Train loss: 2.36028411|Test loss: 3.22917072\n","Epoch: 971 | Lr: 0.00100000000000000002 |Train loss: 2.33502078|Test loss: 3.39109516\n","Epoch: 972 | Lr: 0.00100000000000000002 |Train loss: 2.31539619|Test loss: 3.31416035\n","Epoch: 973 | Lr: 0.00100000000000000002 |Train loss: 2.31383085|Test loss: 3.28980184\n","Epoch: 974 | Lr: 0.00100000000000000002 |Train loss: 2.30038196|Test loss: 3.24613746\n","Epoch: 975 | Lr: 0.00100000000000000002 |Train loss: 2.33002371|Test loss: 3.26150966\n","Epoch: 976 | Lr: 0.00100000000000000002 |Train loss: 2.34597683|Test loss: 3.25694187\n","Epoch: 977 | Lr: 0.00100000000000000002 |Train loss: 2.39544185|Test loss: 3.23008466\n","Epoch: 978 | Lr: 0.00100000000000000002 |Train loss: 2.40305211|Test loss: 3.23707922\n","Epoch: 979 | Lr: 0.00100000000000000002 |Train loss: 2.36936903|Test loss: 3.22443740\n","Epoch: 980 | Lr: 0.00100000000000000002 |Train loss: 2.34956437|Test loss: 3.25315921\n","Epoch: 981 | Lr: 0.00100000000000000002 |Train loss: 2.33288191|Test loss: 3.24179395\n","Epoch: 982 | Lr: 0.00100000000000000002 |Train loss: 2.32767979|Test loss: 3.25621025\n","Epoch: 983 | Lr: 0.00100000000000000002 |Train loss: 2.30415569|Test loss: 3.24590286\n","Epoch: 984 | Lr: 0.00100000000000000002 |Train loss: 2.27028994|Test loss: 3.23195926\n","Epoch: 985 | Lr: 0.00100000000000000002 |Train loss: 2.26937129|Test loss: 3.19152300\n","Epoch: 986 | Lr: 0.00100000000000000002 |Train loss: 2.29170901|Test loss: 3.30599268\n","Epoch: 987 | Lr: 0.00100000000000000002 |Train loss: 2.28738314|Test loss: 3.25129660\n","Epoch: 988 | Lr: 0.00100000000000000002 |Train loss: 2.32886302|Test loss: 3.27044026\n","Epoch: 989 | Lr: 0.00100000000000000002 |Train loss: 2.31862535|Test loss: 3.19993297\n","Epoch: 990 | Lr: 0.00100000000000000002 |Train loss: 2.34638842|Test loss: 3.27114058\n","Epoch: 991 | Lr: 0.00100000000000000002 |Train loss: 2.34203390|Test loss: 3.32109682\n","Epoch: 992 | Lr: 0.00100000000000000002 |Train loss: 2.34420957|Test loss: 3.23905762\n","Epoch: 993 | Lr: 0.00100000000000000002 |Train loss: 2.32447567|Test loss: 3.28058028\n","Epoch: 994 | Lr: 0.00100000000000000002 |Train loss: 2.30847389|Test loss: 3.20516467\n","Epoch: 995 | Lr: 0.00100000000000000002 |Train loss: 2.27082731|Test loss: 3.21577231\n","Epoch: 996 | Lr: 0.00100000000000000002 |Train loss: 2.24944649|Test loss: 3.20828867\n","Epoch: 997 | Lr: 0.00100000000000000002 |Train loss: 2.24696452|Test loss: 3.27279766\n","Epoch: 998 | Lr: 0.00100000000000000002 |Train loss: 2.26614520|Test loss: 3.14767861\n","Epoch: 999 | Lr: 0.00100000000000000002 |Train loss: 2.26995725|Test loss: 3.23404662\n","Epoch: 1000 | Lr: 0.00100000000000000002 |Train loss: 2.26897234|Test loss: 3.24237331\n","\n","Training finished.\n","\n"]}]}]}